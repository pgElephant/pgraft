{"config":{"lang":["en"],"separator":"[\\s\\-,:!=\\[\\]()\"/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"pgraft \u2014 PostgreSQL Raft Consensus Extension (pgElephant Suite)","text":"[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-17+-blue.svg)](https://postgresql.org/) [![Go](https://img.shields.io/badge/Go-1.21+-00ADD8.svg)](https://golang.org/) [![Build Status](https://img.shields.io/badge/Build-Passing-brightgreen.svg)]()  **Distributed consensus for PostgreSQL using the Raft algorithm**  [Get Started](getting-started/installation.md){ .md-button .md-button--primary } [View on GitHub](https://github.com/pgelephant/pgraft){ .md-button }"},{"location":"#unified-high-availability-suite","title":"Unified High-Availability Suite","text":"<p>pgraft is part of the unified pgElephant high-availability suite, alongside RAM, RALE, and FauxDB. All product pages and documentation share a consistent, professional template and feature matrix.</p>"},{"location":"#overview","title":"Overview","text":"<p>pgraft is a PostgreSQL extension that implements the Raft consensus algorithm for distributed PostgreSQL clusters. It provides:</p> <ul> <li>Automatic leader election</li> <li>Crash-safe log replication</li> <li>100% split-brain prevention</li> <li>Zero-downtime failover</li> <li>Unified configuration and monitoring</li> </ul>"},{"location":"#detailed-features-list","title":"Detailed Features List","text":"<ul> <li>Raft Consensus Engine: Embedded etcd-io/raft for proven, production-grade consensus</li> <li>Automatic Leader Election: Quorum-based, deterministic, and fully automated</li> <li>Crash-Safe Log Replication: All state changes are replicated and persisted across nodes</li> <li>100% Split-Brain Prevention: Mathematical guarantee\u2014never more than one leader per term</li> <li>Zero-Downtime Failover: Seamless failover with sub-second detection and recovery</li> <li>Leader-Driven Cluster Management: Node addition/removal and configuration changes are always performed by the elected leader and automatically replicated</li> <li>Background Worker Architecture: PostgreSQL C background worker drives Raft ticks and state transitions</li> <li>Persistent Storage: HardState, log entries, and snapshots survive crashes and restarts</li> <li>Production-Ready Quality: 0 compilation errors/warnings, 100% PostgreSQL C standards compliant, and comprehensive test coverage</li> <li>Observability: Built-in monitoring functions, Prometheus metrics, and detailed logging</li> <li>Secure by Design: Follows PostgreSQL security best practices; supports SSL/TLS and role-based access</li> <li>Unified UI &amp; Documentation: Consistent, professional product pages and documentation across the pgElephant suite</li> </ul>"},{"location":"#quick-example","title":"Quick Example","text":"<pre><code>-- Create extension\nCREATE EXTENSION pgraft;\n\n-- Initialize node\nSELECT pgraft_init();\n\n-- Check if current node is leader\nSELECT pgraft_is_leader();\n\n-- If leader, add other nodes\nSELECT pgraft_add_node(2, '127.0.0.1', 7002);\nSELECT pgraft_add_node(3, '127.0.0.1', 7003);\n\n-- Get cluster status\nSELECT * FROM pgraft_get_cluster_status();\n</code></pre>"},{"location":"#architecture-at-a-glance","title":"Architecture at a Glance","text":"<pre><code>PostgreSQL Background Worker (C)\n    \u2193 Every 100ms\npgraft_go_tick() [C\u2192Go]\n    \u2193\nraftNode.Tick() [etcd-io/raft]\n    \u2193\nReady() messages\n    \u2193\nraftProcessingLoop() [Goroutine]\n    \u2193\nPersist \u2192 Send \u2192 Apply \u2192 Advance\n</code></pre>"},{"location":"#why-pgraft","title":"Why pgraft?","text":""},{"location":"#split-brain-protection","title":"Split-Brain Protection","text":"<p>pgraft provides 100% split-brain protection through:</p> <ul> <li>Quorum Requirement: Leader needs majority votes (N/2 + 1)</li> <li>Term Monotonicity: Higher term always wins</li> <li>Log Completeness: Only up-to-date nodes can be elected</li> <li>Single Leader Per Term: Mathematical guarantee from Raft algorithm</li> </ul>"},{"location":"#automatic-replication","title":"Automatic Replication","text":"<p>When you add a node to the leader, it automatically appears on ALL other nodes. You only need to run ONE command on the leader. The Raft consensus protocol handles everything else.</p>"},{"location":"#production-quality","title":"Production Quality","text":"<ul> <li>0 compilation errors/warnings</li> <li>PostgreSQL C coding standards compliant</li> <li>All variables at function start (C89/C90)</li> <li>C-style comments only</li> <li>Tab indentation</li> <li>Production-ready error handling</li> </ul>"},{"location":"#performance","title":"Performance","text":"<ul> <li>Tick Interval: 100ms (worker-driven)</li> <li>Election Timeout: 1000ms (default, configurable)</li> <li>Heartbeat: 100ms (default, configurable)</li> <li>Memory: ~50MB per node</li> <li>CPU: &lt;1% idle, &lt;5% during elections</li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li> <p>Installation</p> <p>Get pgraft installed and running</p> <p>Install pgraft</p> </li> <li> <p>Quick Start</p> <p>Set up your first cluster in minutes</p> <p>Quick Start Guide</p> </li> <li> <p>Tutorial</p> <p>Complete setup and usage guide</p> <p>Read Tutorial</p> </li> <li> <p>Architecture</p> <p>Understand how pgraft works</p> <p>Learn More</p> </li> </ul>"},{"location":"#related-projects","title":"Related Projects","text":"<ul> <li>RAM \u2014 PostgreSQL clustering and failover manager</li> <li>RALE \u2014 Distributed consensus and key-value store</li> <li>FauxDB \u2014 MongoDB-compatible query proxy for PostgreSQL</li> </ul>"},{"location":"#license","title":"License","text":"<p>MIT License - see LICENSE file for details.</p>"},{"location":"tags/","title":"Tags","text":"<p>Browse documentation by tags.</p> <p>[TAGS]</p>"},{"location":"concepts/","title":"Core Concepts","text":"<p>Understand the fundamental concepts behind pgraft.</p>"},{"location":"concepts/#overview","title":"Overview","text":"<p>This section explains the core concepts and algorithms that make pgraft work. Understanding these concepts will help you operate pgraft clusters effectively and troubleshoot issues.</p>"},{"location":"concepts/#key-concepts","title":"Key Concepts","text":""},{"location":"concepts/#architecture","title":"Architecture","text":"<p>Learn how pgraft integrates with PostgreSQL and how the Raft consensus algorithm works.</p> <p>Read Architecture Guide</p>"},{"location":"concepts/#automatic-replication","title":"Automatic Replication","text":"<p>Understand how configuration changes automatically replicate across the cluster.</p> <p>Learn About Replication</p>"},{"location":"concepts/#split-brain-protection","title":"Split-Brain Protection","text":"<p>Discover how pgraft provides 100% guaranteed split-brain protection.</p> <p>Split-Brain Protection</p>"},{"location":"concepts/#the-raft-consensus-algorithm","title":"The Raft Consensus Algorithm","text":"<p>pgraft uses the Raft consensus algorithm to ensure all nodes agree on the cluster state. Raft provides:</p>"},{"location":"concepts/#leader-election","title":"Leader Election","text":"<ul> <li>One node is elected as leader</li> <li>Leader must have majority votes (N/2 + 1)</li> <li>Elections occur when leader fails or times out</li> <li>Higher term always wins</li> </ul>"},{"location":"concepts/#log-replication","title":"Log Replication","text":"<ul> <li>Leader accepts all writes</li> <li>Leader replicates entries to followers</li> <li>Entries committed when replicated to majority</li> <li>All nodes eventually have same log</li> </ul>"},{"location":"concepts/#safety-guarantees","title":"Safety Guarantees","text":"<p>Election Safety: At most one leader per term</p> <p>Leader Append-Only: Leaders never overwrite entries</p> <p>Log Matching: If logs contain same entry, all previous entries match</p> <p>Leader Completeness: Committed entries present in all future leaders</p> <p>State Machine Safety: All nodes apply same commands in same order</p>"},{"location":"concepts/#how-pgraft-works","title":"How pgraft Works","text":""},{"location":"concepts/#component-architecture","title":"Component Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         PostgreSQL Process              \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  SQL Interface (C)                      \u2502\n\u2502  \u251c\u2500 pgraft_init()                       \u2502\n\u2502  \u251c\u2500 pgraft_add_node()                   \u2502\n\u2502  \u2514\u2500 pgraft_get_cluster_status()         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Background Worker (C)                  \u2502\n\u2502  \u2514\u2500 Drives Raft ticks every 100ms       \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Go Raft Engine (Go)                    \u2502\n\u2502  \u2514\u2500 etcd-io/raft implementation         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Persistent Storage                     \u2502\n\u2502  \u251c\u2500 HardState (term, vote, commit)      \u2502\n\u2502  \u251c\u2500 Log Entries                         \u2502\n\u2502  \u2514\u2500 Snapshots                           \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/#message-flow","title":"Message Flow","text":"<ol> <li>SQL function called (e.g., <code>pgraft_add_node()</code>)</li> <li>Command queued in shared memory</li> <li>Background worker processes queue</li> <li>Go layer proposes to Raft</li> <li>Leader replicates to followers</li> <li>Majority commits the entry</li> <li>All nodes apply the change</li> </ol>"},{"location":"concepts/#key-properties","title":"Key Properties","text":""},{"location":"concepts/#consistency","title":"Consistency","text":"<p>All nodes see the same data in the same order. If a write is acknowledged, it's guaranteed to be present on all surviving nodes.</p>"},{"location":"concepts/#availability","title":"Availability","text":"<p>The cluster remains available as long as a majority of nodes are operational. For a 5-node cluster, up to 2 nodes can fail.</p>"},{"location":"concepts/#partition-tolerance","title":"Partition Tolerance","text":"<p>During network partitions, only the majority partition can elect a leader and accept writes. Minority partitions become read-only.</p>"},{"location":"concepts/#durability","title":"Durability","text":"<p>All committed data survives node crashes and restarts. HardState, log entries, and snapshots are persisted to disk.</p>"},{"location":"concepts/#fault-tolerance","title":"Fault Tolerance","text":"Cluster Size Nodes Required for Quorum Tolerated Failures 1 node 1 0 3 nodes 2 1 5 nodes 3 2 7 nodes 4 3 <p>Note: Even numbers waste resources. A 4-node cluster still only tolerates 1 failure (same as 3 nodes).</p>"},{"location":"concepts/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"concepts/#latency","title":"Latency","text":"<ul> <li>Leader election: ~1 second (configurable)</li> <li>Write latency: ~1 RTT to majority + disk fsync</li> <li>Read latency: Local (no consensus required)</li> </ul>"},{"location":"concepts/#throughput","title":"Throughput","text":"<ul> <li>Bottleneck: Leader's disk write speed</li> <li>Optimization: Batch multiple entries per disk write</li> <li>Typical: Thousands of writes per second</li> </ul>"},{"location":"concepts/#resource-usage","title":"Resource Usage","text":"<ul> <li>CPU: &lt;1% idle, &lt;5% during elections</li> <li>Memory: ~50MB per node</li> <li>Disk I/O: Proportional to write rate</li> <li>Network: Heartbeats every 100ms + replication traffic</li> </ul>"},{"location":"concepts/#common-patterns","title":"Common Patterns","text":""},{"location":"concepts/#configuration-changes","title":"Configuration Changes","text":"<p>All configuration changes (adding/removing nodes) go through Raft consensus:</p> <ol> <li>Leader receives request</li> <li>Leader proposes ConfChange</li> <li>ConfChange replicated to majority</li> <li>All nodes apply configuration</li> <li>Cluster now uses new configuration</li> </ol>"},{"location":"concepts/#automatic-failover","title":"Automatic Failover","text":"<p>When leader fails:</p> <ol> <li>Followers stop receiving heartbeats</li> <li>After election timeout, followers start election</li> <li>Candidate with up-to-date log wins</li> <li>New leader begins sending heartbeats</li> <li>Cluster resumes normal operation</li> </ol> <p>Total downtime: ~1-2 seconds (configurable)</p>"},{"location":"concepts/#learn-more","title":"Learn More","text":"<ul> <li>Deep dive: Architecture</li> <li>How replication works: Automatic Replication</li> <li>Safety guarantees: Split-Brain Protection</li> <li>Operating clusters: Operations Guide</li> </ul>"},{"location":"concepts/architecture/","title":"pgraft System Architecture","text":""},{"location":"concepts/architecture/#overview","title":"Overview","text":"<p>pgraft implements a distributed consensus system using the Raft algorithm integrated with PostgreSQL. This document describes the overall system architecture, component interactions, and operational flows.</p>"},{"location":"concepts/architecture/#system-components","title":"System Components","text":""},{"location":"concepts/architecture/#1-postgresql-cluster-nodes","title":"1. PostgreSQL Cluster Nodes","text":"<p>Each PostgreSQL instance in the cluster runs the pgraft extension and participates in the Raft consensus protocol.</p>"},{"location":"concepts/architecture/#2-raft-consensus-layer","title":"2. Raft Consensus Layer","text":"<p>The core consensus engine implemented in Go, providing: - Leader election - Log replication - Cluster membership management - Failure detection and recovery</p>"},{"location":"concepts/architecture/#3-network-communication","title":"3. Network Communication","text":"<p>TCP-based peer-to-peer communication between cluster nodes for: - Raft protocol messages - Heartbeat signals - Log replication - Configuration changes</p>"},{"location":"concepts/architecture/#4-shared-memory-interface","title":"4. Shared Memory Interface","text":"<p>PostgreSQL shared memory used for: - Command queue between SQL and background worker - Cluster state persistence - Worker status tracking - Command status monitoring</p>"},{"location":"concepts/architecture/#high-level-architecture","title":"High-Level Architecture","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    PostgreSQL Cluster                          \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502   Node 1        \u2502   Node 2        \u2502   Node 3                    \u2502\n\u2502                 \u2502                 \u2502                             \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510             \u2502\n\u2502 \u2502 PostgreSQL  \u2502 \u2502 \u2502 PostgreSQL  \u2502 \u2502 \u2502 PostgreSQL  \u2502             \u2502\n\u2502 \u2502   Server    \u2502 \u2502 \u2502   Server    \u2502 \u2502 \u2502   Server    \u2502             \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518             \u2502\n\u2502         \u2502       \u2502         \u2502       \u2502         \u2502                   \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\n\u2502 \u2502   pgraft      \u2502 \u2502   pgraft      \u2502 \u2502   pgraft      \u2502           \u2502\n\u2502 \u2502   Extension   \u2502 \u2502   Extension   \u2502 \u2502   Extension   \u2502           \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2502         \u2502       \u2502         \u2502       \u2502         \u2502                   \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\n\u2502 \u2502 Background    \u2502 \u2502 Background    \u2502 \u2502 Background    \u2502           \u2502\n\u2502 \u2502   Worker      \u2502 \u2502   Worker      \u2502 \u2502   Worker      \u2502           \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2502         \u2502       \u2502         \u2502       \u2502         \u2502                   \u2502\n\u2502 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510           \u2502\n\u2502 \u2502 Go Raft       \u2502 \u2502 Go Raft       \u2502 \u2502 Go Raft       \u2502           \u2502\n\u2502 \u2502   Library     \u2502 \u2502   Library     \u2502 \u2502   Library     \u2502           \u2502\n\u2502 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2502\n\u2502         \u2502       \u2502         \u2502       \u2502         \u2502                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n          \u2502       \u2502         \u2502       \u2502         \u2502\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                  \u2502         \u2502       \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u2502        Network Layer            \u2502\n          \u2502    (TCP Peer Communication)     \u2502\n          \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/architecture/#component-interaction-flow","title":"Component Interaction Flow","text":""},{"location":"concepts/architecture/#1-cluster-initialization","title":"1. Cluster Initialization","text":"<pre><code>sequenceDiagram\n    participant U as User\n    participant N1 as Node 1\n    participant N2 as Node 2\n    participant N3 as Node 3\n\n    U-&gt;&gt;N1: SELECT pgraft_init()\n    N1-&gt;&gt;N1: Start background worker\n    N1-&gt;&gt;N1: Initialize Raft node\n    N1-&gt;&gt;N1: Start network server\n\n    U-&gt;&gt;N2: SELECT pgraft_add_node('node2:5433')\n    N1-&gt;&gt;N2: Connect to node 2\n    N2-&gt;&gt;N2: Start background worker\n    N2-&gt;&gt;N2: Join cluster\n\n    U-&gt;&gt;N3: SELECT pgraft_add_node('node3:5433')\n    N1-&gt;&gt;N3: Connect to node 3\n    N3-&gt;&gt;N3: Start background worker\n    N3-&gt;&gt;N3: Join cluster\n\n    Note over N1,N3: Cluster formed with 3 nodes</code></pre>"},{"location":"concepts/architecture/#2-leader-election-process","title":"2. Leader Election Process","text":"<pre><code>sequenceDiagram\n    participant N1 as Node 1 (Leader)\n    participant N2 as Node 2 (Follower)\n    participant N3 as Node 3 (Follower)\n\n    loop Heartbeat\n        N1-&gt;&gt;N2: AppendEntries (heartbeat)\n        N1-&gt;&gt;N3: AppendEntries (heartbeat)\n        N2-&gt;&gt;N1: AppendEntries Response\n        N3-&gt;&gt;N1: AppendEntries Response\n    end\n\n    Note over N1: Leader fails\n    N2-&gt;&gt;N2: Election timeout\n    N2-&gt;&gt;N3: RequestVote\n    N3-&gt;&gt;N2: Vote granted\n    N2-&gt;&gt;N2: Become leader\n    N2-&gt;&gt;N3: AppendEntries (heartbeat)</code></pre>"},{"location":"concepts/architecture/#3-log-replication","title":"3. Log Replication","text":"<pre><code>sequenceDiagram\n    participant U as User\n    participant L as Leader\n    participant F1 as Follower 1\n    participant F2 as Follower 2\n\n    U-&gt;&gt;L: INSERT/UPDATE/DELETE\n    L-&gt;&gt;L: Append to log\n    L-&gt;&gt;F1: AppendEntries (log entry)\n    L-&gt;&gt;F2: AppendEntries (log entry)\n    F1-&gt;&gt;L: AppendEntries Response\n    F2-&gt;&gt;L: AppendEntries Response\n    L-&gt;&gt;L: Commit entry\n    L-&gt;&gt;F1: AppendEntries (commit)\n    L-&gt;&gt;F2: AppendEntries (commit)\n    L-&gt;&gt;U: Transaction committed</code></pre>"},{"location":"concepts/architecture/#data-flow-architecture","title":"Data Flow Architecture","text":""},{"location":"concepts/architecture/#1-command-processing-flow","title":"1. Command Processing Flow","text":"<pre><code>SQL Function \u2192 Command Queue \u2192 Background Worker \u2192 Go Raft Library \u2192 Network\n     \u2191                                                                    \u2193\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 Command Status \u2190 Shared Memory \u2190 Raft State \u2190\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/architecture/#2-shared-memory-layout","title":"2. Shared Memory Layout","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                    Shared Memory                            \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Worker State                                               \u2502\n\u2502  \u251c\u2500 Status (IDLE/INIT/RUNNING/STOPPING/STOPPED)           \u2502\n\u2502  \u251c\u2500 Node ID, Address, Port                                 \u2502\n\u2502  \u251c\u2500 Cluster Name                                           \u2502\n\u2502  \u2514\u2500 Initialization Flags                                   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Command Queue (Circular Buffer)                           \u2502\n\u2502  \u251c\u2500 Command Type (INIT/ADD_NODE/REMOVE_NODE/LOG_APPEND)   \u2502\n\u2502  \u251c\u2500 Command Data                                           \u2502\n\u2502  \u251c\u2500 Timestamp                                              \u2502\n\u2502  \u2514\u2500 Queue Head/Tail Pointers                               \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Command Status FIFO                                       \u2502\n\u2502  \u251c\u2500 Command ID                                             \u2502\n\u2502  \u251c\u2500 Status (PENDING/PROCESSING/COMPLETED/FAILED)          \u2502\n\u2502  \u251c\u2500 Error Message                                          \u2502\n\u2502  \u2514\u2500 Completion Time                                        \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  Cluster State                                             \u2502\n\u2502  \u251c\u2500 Current Leader ID                                      \u2502\n\u2502  \u251c\u2500 Current Term                                           \u2502\n\u2502  \u251c\u2500 Node Membership                                        \u2502\n\u2502  \u2514\u2500 Log Statistics                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/architecture/#network-architecture","title":"Network Architecture","text":""},{"location":"concepts/architecture/#1-peer-to-peer-communication","title":"1. Peer-to-Peer Communication","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    TCP    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    TCP    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Node 1    \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502   Node 2    \u2502\u25c4\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25ba\u2502   Node 3    \u2502\n\u2502             \u2502           \u2502             \u2502           \u2502             \u2502\n\u2502 Port: 5433  \u2502           \u2502 Port: 5434  \u2502           \u2502 Port: 5435  \u2502\n\u2502 Raft Port:  \u2502           \u2502 Raft Port:  \u2502           \u2502 Raft Port:  \u2502\n\u2502    8001     \u2502           \u2502    8002     \u2502           \u2502    8003     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518           \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/architecture/#2-message-types","title":"2. Message Types","text":"<ul> <li>RequestVote: Candidate requesting votes during elections</li> <li>AppendEntries: Leader sending log entries and heartbeats</li> <li>InstallSnapshot: Leader sending snapshot to catch up slow followers</li> <li>Heartbeat: Regular leader-to-follower communication</li> </ul>"},{"location":"concepts/architecture/#failure-scenarios-and-recovery","title":"Failure Scenarios and Recovery","text":""},{"location":"concepts/architecture/#1-leader-failure","title":"1. Leader Failure","text":"<pre><code>Normal Operation \u2192 Leader Fails \u2192 Election Timeout \u2192 New Election \u2192 New Leader\n</code></pre>"},{"location":"concepts/architecture/#2-network-partition","title":"2. Network Partition","text":"<pre><code>Full Connectivity \u2192 Network Split \u2192 Partition A (majority) \u2192 Partition B (minority)\n                                          \u2193                        \u2193\n                                   Continues Operation      Stops Accepting Writes\n</code></pre>"},{"location":"concepts/architecture/#3-node-recovery","title":"3. Node Recovery","text":"<pre><code>Node Down \u2192 Node Restarts \u2192 Joins Cluster \u2192 Catches Up Log \u2192 Active Participant\n</code></pre>"},{"location":"concepts/architecture/#security-considerations","title":"Security Considerations","text":""},{"location":"concepts/architecture/#1-network-security","title":"1. Network Security","text":"<ul> <li>TCP connections between peers</li> <li>Configurable IP addresses and ports</li> <li>No built-in encryption (relies on network-level security)</li> </ul>"},{"location":"concepts/architecture/#2-access-control","title":"2. Access Control","text":"<ul> <li>PostgreSQL's native authentication</li> <li>Extension functions require appropriate privileges</li> <li>Shared memory access controlled by PostgreSQL</li> </ul>"},{"location":"concepts/architecture/#performance-characteristics","title":"Performance Characteristics","text":""},{"location":"concepts/architecture/#1-latency","title":"1. Latency","text":"<ul> <li>Leader election: ~1-5 seconds (configurable)</li> <li>Log replication: Network RTT + disk I/O</li> <li>Heartbeat interval: 1 second (configurable)</li> </ul>"},{"location":"concepts/architecture/#2-throughput","title":"2. Throughput","text":"<ul> <li>Single leader handles all writes</li> <li>Followers can serve read-only queries</li> <li>Log replication limited by network bandwidth</li> </ul>"},{"location":"concepts/architecture/#3-scalability","title":"3. Scalability","text":"<ul> <li>Optimal with 3-5 nodes</li> <li>More nodes increase election time</li> <li>Network partitions affect availability</li> </ul>"},{"location":"concepts/architecture/#configuration-parameters","title":"Configuration Parameters","text":""},{"location":"concepts/architecture/#1-network-settings","title":"1. Network Settings","text":"<ul> <li><code>pgraft.listen_address</code>: IP address to bind</li> <li><code>pgraft.listen_port</code>: Port for Raft communication</li> <li><code>pgraft.peer_timeout</code>: Network timeout for peer connections</li> </ul>"},{"location":"concepts/architecture/#2-raft-parameters","title":"2. Raft Parameters","text":"<ul> <li><code>pgraft.heartbeat_interval</code>: Heartbeat frequency (ms)</li> <li><code>pgraft.election_timeout</code>: Election timeout range (ms)</li> <li><code>pgraft.max_log_entries</code>: Maximum log entries per batch</li> </ul>"},{"location":"concepts/architecture/#3-operational-settings","title":"3. Operational Settings","text":"<ul> <li><code>pgraft.cluster_name</code>: Unique cluster identifier</li> <li><code>pgraft.debug_enabled</code>: Enable debug logging</li> <li><code>pgraft.health_period_ms</code>: Health check frequency</li> </ul>"},{"location":"concepts/architecture/#monitoring-and-observability","title":"Monitoring and Observability","text":""},{"location":"concepts/architecture/#1-cluster-health","title":"1. Cluster Health","text":"<ul> <li>Leader election status</li> <li>Node membership status</li> <li>Network connectivity</li> <li>Log replication lag</li> </ul>"},{"location":"concepts/architecture/#2-performance-metrics","title":"2. Performance Metrics","text":"<ul> <li>Command processing latency</li> <li>Network message rates</li> <li>Memory usage</li> <li>Background worker status</li> </ul>"},{"location":"concepts/architecture/#3-logging","title":"3. Logging","text":"<ul> <li>Raft protocol events</li> <li>Network communication</li> <li>Error conditions</li> <li>Performance statistics</li> </ul>"},{"location":"concepts/architecture/#deployment-considerations","title":"Deployment Considerations","text":""},{"location":"concepts/architecture/#1-hardware-requirements","title":"1. Hardware Requirements","text":"<ul> <li>Sufficient RAM for shared memory</li> <li>Network bandwidth for replication</li> <li>Disk I/O for log persistence</li> <li>CPU for consensus processing</li> </ul>"},{"location":"concepts/architecture/#2-network-requirements","title":"2. Network Requirements","text":"<ul> <li>Low-latency network between nodes</li> <li>Reliable network connectivity</li> <li>Sufficient bandwidth for replication</li> <li>Firewall configuration for peer ports</li> </ul>"},{"location":"concepts/architecture/#3-postgresql-configuration","title":"3. PostgreSQL Configuration","text":"<ul> <li>Shared memory allocation</li> <li>Background worker limits</li> <li>Connection limits</li> <li>Logging configuration</li> </ul> <p>This architecture provides a robust foundation for distributed PostgreSQL clusters with automatic failover, consistent replication, and high availability.</p>"},{"location":"concepts/automatic-replication/","title":"Automatic Node Replication in pgraft","text":""},{"location":"concepts/automatic-replication/#quick-answer","title":"Quick Answer","text":"<p>YES! When you add a node to the leader, it automatically appears on ALL other nodes.</p> <p>You only need to run ONE command on the leader. The Raft consensus protocol handles everything else automatically.</p>"},{"location":"concepts/automatic-replication/#how-it-works","title":"How It Works","text":""},{"location":"concepts/automatic-replication/#the-process","title":"The Process","text":"<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502                                                              \u2502\n\u2502  1. User runs ONE command on leader                          \u2502\n\u2502     Leader$ SELECT pgraft_add_node(4, '192.168.1.14', 7004);\u2502\n\u2502                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  2. Leader creates ConfChange entry                          \u2502\n\u2502     Entry{Type: AddNode, NodeID: 4, Addr: \"192.168.1.14\"}  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  3. Leader appends to Raft log                               \u2502\n\u2502     log[42] = ConfChange entry                              \u2502\n\u2502     Leader persists to disk                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  4. Leader replicates to ALL followers (AUTOMATIC)           \u2502\n\u2502                                                              \u2502\n\u2502     Leader \u2192 Follower1: AppendEntries(log[42])              \u2502\n\u2502     Leader \u2192 Follower2: AppendEntries(log[42])              \u2502\n\u2502     Leader \u2192 Follower3: AppendEntries(log[42])              \u2502\n\u2502                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  5. Followers persist entry and acknowledge                  \u2502\n\u2502                                                              \u2502\n\u2502     Follower1: Writes log[42] \u2192 ACK                         \u2502\n\u2502     Follower2: Writes log[42] \u2192 ACK                         \u2502\n\u2502     Follower3: Writes log[42] \u2192 ACK                         \u2502\n\u2502                                                              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  6. Leader commits (majority achieved)                       \u2502\n\u2502     commitIndex = 42                                        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  7. ALL nodes apply configuration change (AUTOMATIC)         \u2502\n\u2502                                                              \u2502\n\u2502     Leader:    nodes[4] = \"192.168.1.14:7004\" \u2713            \u2502\n\u2502     Follower1: nodes[4] = \"192.168.1.14:7004\" \u2713            \u2502\n\u2502     Follower2: nodes[4] = \"192.168.1.14:7004\" \u2713            \u2502\n\u2502     Follower3: nodes[4] = \"192.168.1.14:7004\" \u2713            \u2502\n\u2502                                                              \u2502\n\u2502     ALL NODES UPDATED! NO MANUAL STEPS!                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/automatic-replication/#example","title":"Example","text":""},{"location":"concepts/automatic-replication/#initial-state","title":"Initial State","text":"<pre><code>Cluster: 3 nodes\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Node 1  \u2502  \u2502 Node 2  \u2502  \u2502 Node 3  \u2502\n\u2502 Leader  \u2502  \u2502Follower \u2502  \u2502Follower \u2502\n\u2502 :7001   \u2502  \u2502 :7002   \u2502  \u2502 :7003   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nMembership on ALL nodes: {1, 2, 3}\n</code></pre>"},{"location":"concepts/automatic-replication/#user-action-only-on-leader","title":"User Action (Only on Leader!)","text":"<pre><code>-- Run on Node 1 (leader) ONLY\nSELECT pgraft_add_node(4, '192.168.1.14', 7004);\n\n-- Result\n pgraft_add_node \n-----------------\n t\n(1 row)\n\n-- Do NOT run on Node 2\n-- Do NOT run on Node 3\n-- That's it! One command!\n</code></pre>"},{"location":"concepts/automatic-replication/#result-automatic","title":"Result (Automatic)","text":"<pre><code>Cluster: 4 nodes\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Node 1  \u2502  \u2502 Node 2  \u2502  \u2502 Node 3  \u2502  \u2502 Node 4  \u2502\n\u2502 Leader  \u2502  \u2502Follower \u2502  \u2502Follower \u2502  \u2502Follower \u2502\n\u2502 :7001   \u2502  \u2502 :7002   \u2502  \u2502 :7003   \u2502  \u2502 :7004   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nMembership on ALL nodes: {1, 2, 3, 4}  \u2190 AUTOMATIC!\n</code></pre>"},{"location":"concepts/automatic-replication/#verification","title":"Verification","text":"<p>Check membership on ANY node:</p> <pre><code>-- On Node 1 (leader)\nnode1$ SELECT * FROM pgraft_get_nodes();\n node_id |   address    | port \n---------+--------------+------\n       1 | 127.0.0.1    | 7001\n       2 | 127.0.0.1    | 7002\n       3 | 127.0.0.1    | 7003\n       4 | 192.168.1.14 | 7004  \u2190 New node!\n\n-- On Node 2 (follower - was NOT manually updated)\nnode2$ SELECT * FROM pgraft_get_nodes();\n node_id |   address    | port \n---------+--------------+------\n       1 | 127.0.0.1    | 7001\n       2 | 127.0.0.1    | 7002\n       3 | 127.0.0.1    | 7003\n       4 | 192.168.1.14 | 7004  \u2190 SAME! Automatic!\n\n-- On Node 3 (follower - was NOT manually updated)\nnode3$ SELECT * FROM pgraft_get_nodes();\n node_id |   address    | port \n---------+--------------+------\n       1 | 127.0.0.1    | 7001\n       2 | 127.0.0.1    | 7002\n       3 | 127.0.0.1    | 7003\n       4 | 192.168.1.14 | 7004  \u2190 SAME! Automatic!\n</code></pre> <p>All nodes have identical membership! \u2713</p>"},{"location":"concepts/automatic-replication/#what-you-do-vs-what-the-system-does","title":"What You Do vs. What the System Does","text":""},{"location":"concepts/automatic-replication/#what-you-do","title":"What YOU Do","text":"<pre><code>-- Step 1: Find the leader\nSELECT pgraft_get_leader();\n-- Returns: 1\n\n-- Step 2: Connect to the leader (Node 1)\npsql -h node1 -p 5432\n\n-- Step 3: Add the new node\nSELECT pgraft_add_node(4, '192.168.1.14', 7004);\n-- Returns: t\n\n-- DONE! That's all!\n</code></pre>"},{"location":"concepts/automatic-replication/#what-the-system-does-automatically","title":"What the SYSTEM Does (Automatically)","text":"<ol> <li>\u2713 Creates ConfChange entry</li> <li>\u2713 Appends to Raft log</li> <li>\u2713 Replicates to ALL followers</li> <li>\u2713 Waits for majority acknowledgment</li> <li>\u2713 Commits the entry</li> <li>\u2713 Applies on ALL nodes</li> <li>\u2713 Updates membership everywhere</li> <li>\u2713 Establishes connections to new node</li> <li>\u2713 Starts replicating to new node</li> <li>\u2713 Persists configuration to disk</li> </ol> <p>All automatic. No manual steps.</p>"},{"location":"concepts/automatic-replication/#what-you-dont-need-to-do","title":"What You DON'T Need to Do","text":""},{"location":"concepts/automatic-replication/#do-not-ssh-to-each-node","title":"\u2717 Do NOT SSH to Each Node","text":"<pre><code># DON'T DO THIS (old, manual way):\nssh node1 \"echo 'node4: 192.168.1.14:7004' &gt;&gt; config.conf\"\nssh node2 \"echo 'node4: 192.168.1.14:7004' &gt;&gt; config.conf\"\nssh node3 \"echo 'node4: 192.168.1.14:7004' &gt;&gt; config.conf\"\n# WRONG! Don't do this!\n</code></pre>"},{"location":"concepts/automatic-replication/#do-not-edit-config-files-manually","title":"\u2717 Do NOT Edit Config Files Manually","text":"<pre><code># DON'T DO THIS:\nvi /etc/pgraft/nodes.conf  # Add node4\n# WRONG! pgraft doesn't use config files for membership\n</code></pre>"},{"location":"concepts/automatic-replication/#do-not-restart-any-processes","title":"\u2717 Do NOT Restart Any Processes","text":"<pre><code># DON'T DO THIS:\nsystemctl restart postgresql@node1\nsystemctl restart postgresql@node2\nsystemctl restart postgresql@node3\n# WRONG! No restart needed!\n</code></pre>"},{"location":"concepts/automatic-replication/#do-not-run-the-command-on-each-node","title":"\u2717 Do NOT Run the Command on Each Node","text":"<pre><code>-- DON'T DO THIS:\nnode1$ SELECT pgraft_add_node(4, ...);  -- OK (on leader)\nnode2$ SELECT pgraft_add_node(4, ...);  -- WRONG! Don't do this!\nnode3$ SELECT pgraft_add_node(4, ...);  -- WRONG! Don't do this!\n</code></pre>"},{"location":"concepts/automatic-replication/#why-this-is-safe","title":"Why This is Safe","text":""},{"location":"concepts/automatic-replication/#1-raft-log-guarantees","title":"1. Raft Log Guarantees","text":"<p>Guarantee: Once an entry is committed to the Raft log, it's guaranteed to be on all current and future leaders.</p> <pre><code>Committed entry = Majority have it in persistent storage\n                = Cannot be lost\n                = Will be on all future leaders\n                = Will be applied on all nodes\n</code></pre>"},{"location":"concepts/automatic-replication/#2-sequential-consistency","title":"2. Sequential Consistency","text":"<p>Guarantee: All nodes apply log entries in the same order.</p> <pre><code>All nodes see:\n  log[42]: Add node 4\n  log[43]: Add node 5\n  log[44]: Remove node 3\n\nAll nodes apply in same order:\n  1. Add node 4\n  2. Add node 5\n  3. Remove node 3\n\nResult: All nodes have identical membership\n</code></pre>"},{"location":"concepts/automatic-replication/#3-majority-agreement-required","title":"3. Majority Agreement Required","text":"<p>Guarantee: Configuration changes only committed when majority agrees.</p> <pre><code>5-node cluster:\n  - Leader proposes: Add node 6\n  - Leader + 2 followers ACK = 3 nodes\n  - 3 \u2265 \u2308(5+1)/2\u2309 = 3 \u2192 Majority! \u2713\n  - Entry committed\n  - Safe to apply\n</code></pre> <p>If network partition: <pre><code>5-node partition into [A,B] | [C,D,E]:\n  - [A,B]: Only 2 nodes, cannot commit (need 3)\n  - [C,D,E]: 3 nodes, can commit \u2713\n\n  Only majority partition can add nodes\n  Minority partition safe (read-only)\n</code></pre></p>"},{"location":"concepts/automatic-replication/#4-automatic-recovery","title":"4. Automatic Recovery","text":"<p>Guarantee: If a node was down, it catches up automatically.</p> <pre><code>Scenario:\n  T+0s: Node 3 crashes\n  T+10s: Leader adds node 4 (log[42])\n  T+20s: Leader adds node 5 (log[43])\n  T+30s: Node 3 restarts\n\nNode 3 recovery:\n  1. Contacts leader\n  2. Leader sees: Node 3 at log[41], I'm at log[43]\n  3. Leader sends: log[42] (add node 4), log[43] (add node 5)\n  4. Node 3 applies both entries\n  5. Node 3 now knows about nodes 4 and 5\n\n  AUTOMATIC! No manual steps!\n</code></pre>"},{"location":"concepts/automatic-replication/#implementation-code","title":"Implementation Code","text":""},{"location":"concepts/automatic-replication/#how-its-enforced","title":"How It's Enforced","text":"<pre><code>// File: src/pgraft_sql.c\nDatum pgraft_add_node(PG_FUNCTION_ARGS) {\n    int node_id = PG_GETARG_INT32(0);\n    char *address = text_to_cstring(PG_GETARG_TEXT_PP(1));\n    int port = PG_GETARG_INT32(2);\n\n    // Check if this node is the leader\n    int leader_status = pgraft_go_is_leader();\n    if (leader_status != 1) {\n        elog(ERROR, \"Cannot add node - this node is not the leader. \"\n                    \"Node addition must be performed on the leader.\");\n        return false;\n    }\n\n    // Call Go library to add peer (creates ConfChange)\n    result = pgraft_go_add_peer(node_id, address, port);\n\n    // Raft log replication happens automatically\n    // All nodes will apply this change\n    return true;\n}\n</code></pre>"},{"location":"concepts/automatic-replication/#what-happens-in-go","title":"What Happens in Go","text":"<pre><code>// File: src/pgraft_go.go\nfunc pgraft_go_add_peer(nodeID, address, port) {\n    // Add to local map\n    nodeAddr := fmt.Sprintf(\"%s:%d\", address, port)\n    nodes[nodeID] = nodeAddr\n\n    // Create ConfChange entry\n    cc := raftpb.ConfChange{\n        Type:    raftpb.ConfChangeAddNode,\n        NodeID:  uint64(nodeID),\n        Context: []byte(nodeAddr),\n    }\n\n    // Propose to Raft (this adds to log)\n    raftNode.ProposeConfChange(ctx, cc)\n\n    // Raft handles the rest:\n    // - Replicates to followers\n    // - Gets majority acknowledgment\n    // - Commits the entry\n    // - All nodes apply the change\n    // AUTOMATIC!\n\n    return 0\n}\n</code></pre>"},{"location":"concepts/automatic-replication/#comparison-manual-vs-automatic","title":"Comparison: Manual vs. Automatic","text":""},{"location":"concepts/automatic-replication/#manual-configuration-traditional-systems","title":"Manual Configuration (Traditional Systems)","text":"<p>Steps Required: 1. SSH to node1: <code>vi /etc/cluster.conf</code>, add node4 2. SSH to node2: <code>vi /etc/cluster.conf</code>, add node4 3. SSH to node3: <code>vi /etc/cluster.conf</code>, add node4 4. Restart node1: <code>systemctl restart service</code> 5. Restart node2: <code>systemctl restart service</code> 6. Restart node3: <code>systemctl restart service</code> 7. Hope all configs match exactly 8. Debug if configs don't match</p> <p>Problems: - \u2717 Human error likely (typos, wrong IPs) - \u2717 Race conditions during restarts - \u2717 Downtime during restarts - \u2717 Configs can diverge - \u2717 Split-brain possible - \u2717 Complex rollback if error</p>"},{"location":"concepts/automatic-replication/#automatic-replication-pgraft","title":"Automatic Replication (pgraft)","text":"<p>Steps Required: 1. <code>SELECT pgraft_add_node(4, '192.168.1.14', 7004);</code></p> <p>That's it!</p> <p>Advantages: - \u2713 No human error (single command) - \u2713 No race conditions (Raft serializes) - \u2713 No downtime (hot reconfiguration) - \u2713 Configs cannot diverge (Raft guarantees consistency) - \u2713 Split-brain impossible (quorum required) - \u2713 Automatic rollback on failure</p>"},{"location":"concepts/automatic-replication/#real-world-example","title":"Real-World Example","text":""},{"location":"concepts/automatic-replication/#scenario-add-new-node-to-production-cluster","title":"Scenario: Add New Node to Production Cluster","text":"<p>Initial Cluster: <pre><code>Production: 5 nodes\n  node1 (leader):   192.168.1.11:7001\n  node2 (follower): 192.168.1.12:7002\n  node3 (follower): 192.168.1.13:7003\n  node4 (follower): 192.168.1.14:7004\n  node5 (follower): 192.168.1.15:7005\n</code></pre></p> <p>Task: Add node6 at 192.168.1.16:7006</p> <p>Old Way (Manual): <pre><code># 1. Update config on ALL 5 nodes\nfor node in node1 node2 node3 node4 node5; do\n  ssh $node \"echo 'node6: 192.168.1.16:7006' &gt;&gt; /etc/pgraft/nodes.conf\"\ndone\n\n# 2. Restart ALL nodes (risky!)\nfor node in node1 node2 node3 node4 node5; do\n  ssh $node \"systemctl restart postgresql\"\ndone\n\n# 3. Hope nothing breaks\n# 4. Debug if it does\n\nTime: 30+ minutes\nRisk: HIGH (cluster downtime, split-brain possible)\n</code></pre></p> <p>pgraft Way (Automatic): <pre><code>-- 1. Connect to leader\npsql -h 192.168.1.11 -p 5432\n\n-- 2. Add node\nSELECT pgraft_add_node(6, '192.168.1.16', 7006);\n\n-- Done!\n\nTime: 5 seconds\nRisk: ZERO (no downtime, split-brain impossible)\n</code></pre></p> <p>Verification: <pre><code>-- Check on ANY node\nSELECT * FROM pgraft_get_nodes();\n node_id |   address    | port \n---------+--------------+------\n       1 | 192.168.1.11 | 7001\n       2 | 192.168.1.12 | 7002\n       3 | 192.168.1.13 | 7003\n       4 | 192.168.1.14 | 7004\n       5 | 192.168.1.15 | 7005\n       6 | 192.168.1.16 | 7006  \u2190 NEW! On ALL nodes!\n</code></pre></p>"},{"location":"concepts/automatic-replication/#summary","title":"Summary","text":""},{"location":"concepts/automatic-replication/#the-answer-yes-100-automatic","title":"The Answer: YES! 100% Automatic","text":"<p>When you add a node to the leader: 1. \u2713 Leader creates ConfChange entry 2. \u2713 Leader replicates via Raft log to ALL followers 3. \u2713 Majority acknowledges 4. \u2713 Entry commits 5. \u2713 ALL nodes apply the change 6. \u2713 New node appears on ALL nodes</p> <p>No manual steps. No SSH. No config files. No restarts.</p>"},{"location":"concepts/automatic-replication/#what-makes-this-possible","title":"What Makes This Possible","text":"<p>Raft Consensus Protocol: - Log replication guarantees - Majority agreement required - Sequential consistency - Automatic recovery</p>"},{"location":"concepts/automatic-replication/#benefits","title":"Benefits","text":"<ol> <li>Safety: Split-brain impossible</li> <li>Simplicity: One SQL command</li> <li>Reliability: No human error</li> <li>Availability: No downtime</li> <li>Consistency: All nodes identical</li> </ol>"},{"location":"concepts/automatic-replication/#faq","title":"FAQ","text":"<p>Q: Do I need to run the command on each node? A: NO! Only on the leader. The rest is automatic.</p> <p>Q: What if a follower was down when I added a node? A: It catches up automatically when it restarts. It will read the ConfChange from the Raft log.</p> <p>Q: What if the leader crashes during the add? A: If the entry was committed (majority persisted it), the new leader will have it and will apply it. If it wasn't committed, it's as if the add never happened.</p> <p>Q: Can I add multiple nodes at once? A: Yes, but add them one at a time. Each becomes a separate Raft log entry.</p> <p>Q: How long does it take for the node to appear on all nodes? A: ~5ms (time for majority acknowledgment). Essentially instant.</p> <p>Q: Do I need to configure anything on the follower nodes? A: NO! Raft handles everything automatically.</p> <p>BOTTOM LINE: ONE COMMAND ON LEADER = AUTOMATIC UPDATE ON ALL NODES \u2713</p>"},{"location":"concepts/split-brain/","title":"Split-Brain Protection","text":"<p>pgraft provides 100% split-brain protection through the Raft consensus algorithm. This page explains how it works and why you can trust it.</p>"},{"location":"concepts/split-brain/#what-is-split-brain","title":"What is Split-Brain?","text":"<p>Split-brain is a dangerous condition in distributed systems where:</p> <ul> <li>Network partition divides the cluster</li> <li>Multiple nodes believe they are the leader</li> <li>Different leaders accept conflicting writes</li> <li>Data corruption and inconsistency result</li> </ul> <p>Without Protection</p> <p>In traditional PostgreSQL replication, network partitions can lead to split-brain scenarios where multiple nodes accept writes, causing permanent data inconsistencies.</p>"},{"location":"concepts/split-brain/#how-pgraft-prevents-split-brain","title":"How pgraft Prevents Split-Brain","text":"<p>pgraft uses the Raft consensus algorithm which provides mathematical guarantees against split-brain through four key mechanisms:</p>"},{"location":"concepts/split-brain/#1-quorum-requirement","title":"1. Quorum Requirement","text":"<p>Leader election requires a majority of votes (N/2 + 1):</p> <ul> <li>3-node cluster: Needs 2 votes</li> <li>5-node cluster: Needs 3 votes</li> <li>7-node cluster: Needs 4 votes</li> </ul> <p>Why this prevents split-brain:</p> <pre><code>Network Partition Example (3-node cluster):\n\nPartition 1: Node 1, Node 2\nPartition 2: Node 3\n\nPartition 1 (2 nodes):\n   - Has majority (2 out of 3)\n   - Can elect leader\n   - Can accept writes\n\nPartition 2 (1 node):\n   - No majority (1 out of 3)\n   - Cannot elect leader\n   - Cannot accept writes (read-only)\n</code></pre> <p>Mathematical guarantee: Only one partition can have a majority, therefore only one leader can be elected.</p>"},{"location":"concepts/split-brain/#2-term-monotonicity","title":"2. Term Monotonicity","text":"<p>Each leader election increments the term number:</p> <ul> <li>Terms are strictly increasing</li> <li>Higher term always wins</li> <li>Old leaders automatically step down when they see a higher term</li> </ul> <p>Example: <pre><code>Time T0:\n  Node 1 is leader in term 5\n\nNetwork partition occurs\n\nTime T1:\n  Partition A: Node 1 (term 5)\n  Partition B: Node 2, 3 elect new leader (term 6)\n\nNetwork heals\n\nTime T2:\n  Node 1 sees messages from term 6\n  Node 1 automatically steps down\n  Only one leader remains (term 6)\n</code></pre></p>"},{"location":"concepts/split-brain/#3-log-completeness","title":"3. Log Completeness","text":"<p>Only nodes with up-to-date logs can be elected:</p> <ul> <li>Candidates with incomplete logs lose elections</li> <li>New leader always has all committed entries</li> <li>Prevents data loss during leadership transitions</li> </ul> <p>Election Rules: <pre><code>Candidate A: Last log index = 100, Last log term = 5\nCandidate B: Last log index = 95,  Last log term = 5\n\nResult: A wins (more up-to-date log)\n\nCandidate C: Last log index = 100, Last log term = 4\nCandidate D: Last log index = 95,  Last log term = 5\n\nResult: D wins (higher term in last entry)\n</code></pre></p>"},{"location":"concepts/split-brain/#4-single-leader-per-term","title":"4. Single Leader Per Term","text":"<p>Raft's fundamental guarantee:</p> <p>At most one leader can be elected in a given term.</p> <p>Why?</p> <ul> <li>Leader needs majority of votes</li> <li>Each node votes for at most one candidate per term</li> <li>Two candidates cannot both get majority votes (mathematical impossibility)</li> </ul> <pre><code>Example (5-node cluster):\n\nCandidate A gets votes from: Node 1, 2, 3 (majority \u2705)\nCandidate B can only get: Node 4, 5 (not majority \u274c)\n\nImpossible for both A and B to get 3+ votes!\n</code></pre>"},{"location":"concepts/split-brain/#network-partition-scenarios","title":"Network Partition Scenarios","text":""},{"location":"concepts/split-brain/#scenario-1-minority-partition","title":"Scenario 1: Minority Partition","text":"<p>Setup: 3-node cluster (Node 1, 2, 3), Node 1 is leader</p> <p>Event: Node 3 is isolated</p> <pre><code>Before:\n  [Node 1 (Leader)] \u2190\u2192 [Node 2] \u2190\u2192 [Node 3]\n\nAfter Partition:\n  [Node 1 (Leader)] \u2190\u2192 [Node 2]   |   [Node 3 (isolated)]\n</code></pre> <p>Result:</p> <ul> <li>Node 1 remains leader (still has majority with Node 2)</li> <li>Cluster continues operating normally</li> <li>Node 3 becomes follower, cannot accept writes</li> <li>No split-brain - only one leader</li> </ul>"},{"location":"concepts/split-brain/#scenario-2-equal-partition-3-nodes","title":"Scenario 2: Equal Partition (3 nodes)","text":"<p>Setup: 3-node cluster, network splits 1-2 vs 3</p> <p>Event: Network partition</p> <pre><code>Before:\n  [Node 1 (Leader)] \u2190\u2192 [Node 2] \u2190\u2192 [Node 3]\n\nAfter Partition:\n  [Node 1] \u2190\u2192 [Node 2]   |   [Node 3]\n</code></pre> <p>Result:</p> <ul> <li>Partition with nodes 1, 2 keeps leader (has majority)</li> <li>Node 3 cannot elect new leader (no majority)</li> <li>No split-brain - only one leader</li> </ul>"},{"location":"concepts/split-brain/#scenario-3-leader-in-minority","title":"Scenario 3: Leader in Minority","text":"<p>Setup: 5-node cluster, Node 1 is leader</p> <p>Event: Node 1 and 2 isolated from 3, 4, 5</p> <pre><code>Before:\n  [Node 1 (Leader)] \u2190\u2192 [Node 2] \u2190\u2192 [Node 3] \u2190\u2192 [Node 4] \u2190\u2192 [Node 5]\n\nAfter Partition:\n  [Node 1] \u2190\u2192 [Node 2]   |   [Node 3] \u2190\u2192 [Node 4] \u2190\u2192 [Node 5]\n</code></pre> <p>Result:</p> <ul> <li>Node 1 loses leadership (no majority - only 2 of 5)</li> <li>Nodes 3, 4, 5 elect new leader (have majority - 3 of 5)</li> <li>Node 1 steps down after election timeout</li> <li>No split-brain - old leader steps down, new leader elected</li> </ul>"},{"location":"concepts/split-brain/#verification","title":"Verification","text":"<p>You can verify split-brain protection yourself:</p>"},{"location":"concepts/split-brain/#test-1-isolate-minority","title":"Test 1: Isolate Minority","text":"<pre><code># 3-node cluster\n# Block Node 3's network\n\n# On Node 1 or 2 (majority partition):\npsql -c \"SELECT pgraft_is_leader();\"  # One returns true\npsql -c \"SELECT pgraft_add_node(4, '127.0.0.1', 7004);\"  # Works!\n\n# On Node 3 (minority):\npsql -c \"SELECT pgraft_is_leader();\"  # Returns false\npsql -c \"SELECT pgraft_add_node(4, '127.0.0.1', 7004);\"  # Fails!\n</code></pre>"},{"location":"concepts/split-brain/#test-2-leader-in-minority","title":"Test 2: Leader in Minority","text":"<pre><code># 5-node cluster, Node 1 is leader\n# Isolate Node 1 and 2\n\n# Majority partition (3, 4, 5) will elect new leader after ~1 second\n# Minority partition (1, 2) cannot elect leader\n# When network heals, Node 1 sees higher term and steps down\n</code></pre>"},{"location":"concepts/split-brain/#mathematical-proof-sketch","title":"Mathematical Proof Sketch","text":"<p>Theorem: At most one leader per term.</p> <p>Proof:</p> <ol> <li>Leader requires majority votes: N/2 + 1</li> <li>Each node votes once per term</li> <li>Two majorities must overlap (Pigeonhole Principle)</li> <li>Overlapping node cannot vote for both candidates</li> <li>Therefore, at most one candidate can get majority</li> <li>QED: At most one leader per term</li> </ol>"},{"location":"concepts/split-brain/#comparison-with-other-systems","title":"Comparison with Other Systems","text":"System Split-Brain Protection Method pgraft 100% Raft consensus PostgreSQL streaming replication No Manual failover MySQL replication No Manual failover Patroni/Stolon Partial Requires external consensus (etcd/Zookeeper) PostgreSQL with Pacemaker Partial STONITH fencing <p>pgraft Advantage</p> <p>pgraft provides split-brain protection natively without requiring external consensus systems or STONITH devices.</p>"},{"location":"concepts/split-brain/#best-practices","title":"Best Practices","text":""},{"location":"concepts/split-brain/#1-use-odd-number-of-nodes","title":"1. Use Odd Number of Nodes","text":"<p>Odd numbers provide better fault tolerance:</p> <ul> <li>3 nodes: Tolerates 1 failure</li> <li>5 nodes: Tolerates 2 failures</li> <li>7 nodes: Tolerates 3 failures</li> </ul> <p>Even numbers waste resources:</p> <ul> <li>4 nodes: Still tolerates only 1 failure (same as 3)</li> <li>6 nodes: Still tolerates only 2 failures (same as 5)</li> </ul>"},{"location":"concepts/split-brain/#2-geographic-distribution","title":"2. Geographic Distribution","text":"<p>For disaster recovery, distribute nodes across:</p> <ul> <li>Different availability zones</li> <li>Different data centers</li> <li>Different geographic regions</li> </ul> <p>Example (5-node cluster): <pre><code>Region A (2 nodes): Primary data center\nRegion B (2 nodes): Secondary data center\nRegion C (1 node): Tiebreaker\n</code></pre></p>"},{"location":"concepts/split-brain/#3-monitor-term-changes","title":"3. Monitor Term Changes","text":"<p>Frequent term changes indicate problems:</p> <pre><code>-- Monitor term changes\nSELECT pgraft_get_term();\n\n-- If term increases rapidly:\n-- - Network instability\n-- - Node failures\n-- - Election timeout too low\n</code></pre>"},{"location":"concepts/split-brain/#summary","title":"Summary","text":"<p>pgraft provides guaranteed split-brain protection through:</p> <ul> <li>Quorum-based elections - Only majority can elect leader  </li> <li>Term monotonicity - Higher term always wins  </li> <li>Log completeness - Only up-to-date nodes elected  </li> <li>Mathematical guarantees - Proven by Raft algorithm</li> </ul> <p>You can trust pgraft to never allow split-brain scenarios.</p>"},{"location":"development/","title":"Development Guide","text":"<p>Resources for developing, testing, and contributing to pgraft.</p>"},{"location":"development/#overview","title":"Overview","text":"<p>This section is for developers who want to build pgraft from source, contribute code, or understand the internals.</p>"},{"location":"development/#contents","title":"Contents","text":""},{"location":"development/#building-from-source","title":"Building from Source","text":"<p>Complete guide to building pgraft on your development machine.</p> <p>Building Guide</p>"},{"location":"development/#testing","title":"Testing","text":"<p>How to test pgraft, including the test harness and creating test scenarios.</p> <p>Testing Guide</p>"},{"location":"development/#contributing","title":"Contributing","text":"<p>Guidelines for contributing code, documentation, and bug reports.</p> <p>Contributing Guide</p>"},{"location":"development/#quick-start-for-developers","title":"Quick Start for Developers","text":""},{"location":"development/#clone-and-build","title":"Clone and Build","text":"<pre><code># Clone repository\ngit clone https://github.com/pgelephant/pgraft.git\ncd pgraft\n\n# Build\nmake clean &amp;&amp; make\n\n# Install\nmake install\n\n# Test\ncd examples\n./run.sh --destroy\n./run.sh --init\n./run.sh --status\n</code></pre>"},{"location":"development/#development-environment","title":"Development Environment","text":"<p>Prerequisites: - PostgreSQL 17+ with development headers - Go 1.21+ - GCC or Clang - Make</p> <p>Recommended Tools: - Git - Text editor with C and Go support - gdb or lldb for debugging - Valgrind for memory leak detection (Linux)</p>"},{"location":"development/#code-structure","title":"Code Structure","text":""},{"location":"development/#repository-layout","title":"Repository Layout","text":"<pre><code>pgraft/\n\u251c\u2500\u2500 src/                    # Source code\n\u2502   \u251c\u2500\u2500 pgraft.c           # Main extension entry\n\u2502   \u251c\u2500\u2500 pgraft_core.c      # Core Raft interface\n\u2502   \u251c\u2500\u2500 pgraft_sql.c       # SQL functions\n\u2502   \u251c\u2500\u2500 pgraft_guc.c       # Configuration\n\u2502   \u251c\u2500\u2500 pgraft_state.c     # State management\n\u2502   \u251c\u2500\u2500 pgraft_log.c       # Log replication\n\u2502   \u251c\u2500\u2500 pgraft_kv.c        # Key-value store\n\u2502   \u251c\u2500\u2500 pgraft_util.c      # Utilities\n\u2502   \u2514\u2500\u2500 pgraft_go.go       # Go Raft implementation\n\u251c\u2500\u2500 include/               # Header files\n\u2502   \u251c\u2500\u2500 pgraft_core.h\n\u2502   \u251c\u2500\u2500 pgraft_go.h\n\u2502   \u251c\u2500\u2500 pgraft_guc.h\n\u2502   \u251c\u2500\u2500 pgraft_sql.h\n\u2502   \u251c\u2500\u2500 pgraft_state.h\n\u2502   \u251c\u2500\u2500 pgraft_log.h\n\u2502   \u2514\u2500\u2500 pgraft_kv.h\n\u251c\u2500\u2500 examples/              # Test harness\n\u251c\u2500\u2500 docs/                  # Documentation\n\u251c\u2500\u2500 Makefile              # Build system\n\u251c\u2500\u2500 pgraft.control        # Extension control file\n\u2514\u2500\u2500 pgraft--1.0.sql       # SQL definitions\n</code></pre>"},{"location":"development/#component-layers","title":"Component Layers","text":"<p>C Layer: - PostgreSQL integration - Background worker - SQL function interface - Shared memory management</p> <p>Go Layer: - Raft consensus engine (etcd-io/raft) - Network communication - Log persistence - Snapshot management</p> <p>Storage Layer: - HardState persistence - Log entry storage - Snapshot files</p>"},{"location":"development/#development-workflow","title":"Development Workflow","text":""},{"location":"development/#1-make-changes","title":"1. Make Changes","text":"<pre><code># Edit source files\nvim src/pgraft_core.c\n</code></pre>"},{"location":"development/#2-build","title":"2. Build","text":"<pre><code># Clean build\nmake clean &amp;&amp; make\n\n# Check for errors\nmake 2&gt;&amp;1 | grep -i error\n\n# Check for warnings\nmake 2&gt;&amp;1 | grep -i warning\n</code></pre>"},{"location":"development/#3-install","title":"3. Install","text":"<pre><code>make install\n\n# Or manual install\ncp pgraft.dylib /usr/local/pgsql.17/lib/\ncp src/pgraft_go.dylib /usr/local/pgsql.17/lib/\n</code></pre>"},{"location":"development/#4-test","title":"4. Test","text":"<pre><code># Restart PostgreSQL\npg_ctl restart -D /path/to/data\n\n# Run tests\ncd examples\n./run.sh --destroy &amp;&amp; ./run.sh --init\n</code></pre>"},{"location":"development/#5-debug","title":"5. Debug","text":"<pre><code># Enable debug logging\npsql -c \"SELECT pgraft_set_debug(true);\"\n\n# Check logs\ntail -f $PGDATA/log/postgresql-*.log | grep pgraft:\n</code></pre>"},{"location":"development/#coding-standards","title":"Coding Standards","text":""},{"location":"development/#c-code","title":"C Code","text":"<p>PostgreSQL C Standards: - C89/C90 compliance - All variables at function start - C-style comments only (<code>/* */</code>) - Tab indentation (4 spaces) - No warnings, no errors</p> <p>Example: <pre><code>void my_function(void)\n{\n    int result;\n    char *message;\n\n    /* Initialize variables */\n    result = 0;\n    message = NULL;\n\n    /* Function logic */\n    elog(LOG, \"pgraft: Function called\");\n}\n</code></pre></p>"},{"location":"development/#go-code","title":"Go Code","text":"<p>Standard Go conventions: - Use <code>gofmt</code> for formatting - Add comments for exported functions - Handle errors explicitly - Follow Go idioms</p> <p>Example: <pre><code>// ProcessRaftMessage handles incoming Raft protocol messages\nfunc ProcessRaftMessage(msg raftpb.Message) error {\n    if err := raftNode.Step(msg); err != nil {\n        return fmt.Errorf(\"failed to process message: %w\", err)\n    }\n    return nil\n}\n</code></pre></p>"},{"location":"development/#testing-guidelines","title":"Testing Guidelines","text":""},{"location":"development/#unit-tests","title":"Unit Tests","text":"<p>Write tests for new functionality:</p> <pre><code>-- Test new feature\nSELECT new_function() = expected_result;\n</code></pre>"},{"location":"development/#integration-tests","title":"Integration Tests","text":"<p>Test with the test harness:</p> <pre><code>cd examples\n./run.sh --destroy\n./run.sh --init\n# Test your feature\n</code></pre>"},{"location":"development/#regression-tests","title":"Regression Tests","text":"<p>Ensure existing functionality still works:</p> <pre><code># Run full test suite\ncd examples\n./run.sh --destroy\n./run.sh --init\n./run.sh --status\n# Check all nodes are healthy\n</code></pre>"},{"location":"development/#debugging-tools","title":"Debugging Tools","text":""},{"location":"development/#gdb","title":"GDB","text":"<pre><code># Start with debugger\ngdb --args postgres -D /path/to/data\n\n# Set breakpoints\n(gdb) break pgraft_init\n(gdb) run\n\n# Debug\n(gdb) backtrace\n(gdb) print variable\n(gdb) next\n</code></pre>"},{"location":"development/#logging","title":"Logging","text":"<pre><code>/* Add debug logging */\nelog(LOG, \"pgraft: Debug info: %d\", value);\nelog(WARNING, \"pgraft: Warning: %s\", message);\nelog(ERROR, \"pgraft: Error: %s\", error);\n</code></pre>"},{"location":"development/#memory-debugging","title":"Memory Debugging","text":"<pre><code># Valgrind (Linux)\nvalgrind --leak-check=full postgres -D /path/to/data\n\n# macOS Instruments\ninstruments -t \"Leaks\" postgres\n</code></pre>"},{"location":"development/#contributing_1","title":"Contributing","text":""},{"location":"development/#before-submitting","title":"Before Submitting","text":"<ul> <li> Code compiles without errors or warnings</li> <li> All tests pass</li> <li> Code follows style guidelines</li> <li> Documentation updated if needed</li> <li> Commit messages are clear</li> </ul>"},{"location":"development/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Make your changes</li> <li>Test thoroughly</li> <li>Submit pull request</li> <li>Respond to review feedback</li> </ol> <p>See Contributing Guide for details.</p>"},{"location":"development/#resources","title":"Resources","text":"<ul> <li>Build instructions: Building from Source</li> <li>Test procedures: Testing Guide</li> <li>Contribution guidelines: Contributing Guide</li> <li>Architecture details: Architecture</li> </ul>"},{"location":"development/#getting-help","title":"Getting Help","text":"<ul> <li>Documentation: This site</li> <li>Issues: GitHub Issues</li> <li>Source: GitHub Repository</li> </ul>"},{"location":"development/building/","title":"Building from Source","text":"<p>This guide covers building pgraft from source for development and contributing.</p>"},{"location":"development/building/#prerequisites","title":"Prerequisites","text":"<p>Ensure you have all required dependencies:</p> <ul> <li>PostgreSQL 17+: With development headers</li> <li>Go 1.21+: For Raft implementation</li> <li>GCC: C compiler</li> <li>Make: Build system</li> </ul> <p>See Installation for system-specific installation instructions.</p>"},{"location":"development/building/#build-process","title":"Build Process","text":""},{"location":"development/building/#1-clone-repository","title":"1. Clone Repository","text":"<pre><code>git clone https://github.com/pgelephant/pgraft.git\ncd pgraft\n</code></pre>"},{"location":"development/building/#2-build","title":"2. Build","text":"<pre><code>make clean\nmake\n</code></pre> <p>The build process:</p> <ol> <li>Compiles C sources (<code>src/*.c</code>) to object files</li> <li>Builds Go library (<code>src/pgraft_go.go</code>) to shared library</li> <li>Links everything into final <code>pgraft.dylib</code> (or <code>.so</code> on Linux)</li> <li>Creates extension SQL from <code>pgraft--1.0.sql</code></li> </ol>"},{"location":"development/building/#3-install","title":"3. Install","text":"<pre><code># Find PostgreSQL paths\nPG_LIB=$(pg_config --libdir)\nPG_SHARE=$(pg_config --sharedir)\n\n# Install files\ncp pgraft.dylib $PG_LIB/\ncp src/pgraft_go.dylib $PG_LIB/\ncp pgraft.control $PG_SHARE/extension/\ncp pgraft--1.0.sql $PG_SHARE/extension/\n</code></pre>"},{"location":"development/building/#build-targets","title":"Build Targets","text":""},{"location":"development/building/#clean-build","title":"Clean Build","text":"<pre><code>make clean\nmake\n</code></pre>"},{"location":"development/building/#install-after-build","title":"Install After Build","text":"<pre><code>make install\n</code></pre>"},{"location":"development/building/#build-with-debugging","title":"Build with Debugging","text":"<pre><code>make clean\nCFLAGS=\"-g -O0\" make\n</code></pre> <p>This builds with: - <code>-g</code>: Debug symbols - <code>-O0</code>: No optimization</p>"},{"location":"development/building/#verifying-build","title":"Verifying Build","text":""},{"location":"development/building/#check-for-errors","title":"Check for Errors","text":"<pre><code># Should have no errors\nmake 2&gt;&amp;1 | grep -i error\n\n# Should have no warnings\nmake 2&gt;&amp;1 | grep -i warning\n</code></pre>"},{"location":"development/building/#check-binary","title":"Check Binary","text":"<pre><code># macOS\notool -L pgraft.dylib\n\n# Linux\nldd pgraft.so\n\n# Should show dependencies on libpq, PostgreSQL, etc.\n</code></pre>"},{"location":"development/building/#test-extension","title":"Test Extension","text":"<pre><code># Start PostgreSQL with extension\npsql -c \"CREATE EXTENSION pgraft;\"\npsql -c \"SELECT pgraft_test();\"\n</code></pre>"},{"location":"development/building/#development-workflow","title":"Development Workflow","text":""},{"location":"development/building/#edit-compile-test-cycle","title":"Edit-Compile-Test Cycle","text":"<pre><code># 1. Edit source files\nvim src/pgraft_core.c\n\n# 2. Rebuild\nmake clean &amp;&amp; make\n\n# 3. Reinstall\nmake install\n\n# 4. Restart PostgreSQL\npg_ctl restart -D /path/to/data\n\n# 5. Test\npsql -c \"SELECT pgraft_test();\"\n</code></pre>"},{"location":"development/building/#incremental-builds","title":"Incremental Builds","text":"<p>For faster development, you can rebuild only changed files:</p> <pre><code># Rebuild only C files (if Go unchanged)\nmake pgraft.dylib\n\n# Rebuild only Go (if C unchanged)\ncd src\ngo build -buildmode=c-shared -o pgraft_go.dylib pgraft_go.go\n</code></pre>"},{"location":"development/building/#code-organization","title":"Code Organization","text":""},{"location":"development/building/#c-source-files-src","title":"C Source Files (<code>src/</code>)","text":"File Purpose <code>pgraft.c</code> Main extension entry point, background worker <code>pgraft_core.c</code> Core Raft interface to Go layer <code>pgraft_sql.c</code> SQL function implementations <code>pgraft_guc.c</code> GUC (configuration) parameters <code>pgraft_state.c</code> State management, shared memory <code>pgraft_log.c</code> Log replication functions <code>pgraft_kv.c</code> Key-value store implementation <code>pgraft_kv_sql.c</code> KV SQL interface <code>pgraft_util.c</code> Utility functions <code>pgraft_go.c</code> CGO wrapper for Go library"},{"location":"development/building/#header-files-include","title":"Header Files (<code>include/</code>)","text":"File Purpose <code>pgraft_core.h</code> Core function declarations <code>pgraft_go.h</code> Go library interface <code>pgraft_guc.h</code> GUC declarations <code>pgraft_sql.h</code> SQL function declarations <code>pgraft_state.h</code> State structures <code>pgraft_log.h</code> Log function declarations <code>pgraft_kv.h</code> KV store declarations"},{"location":"development/building/#go-implementation","title":"Go Implementation","text":"<ul> <li><code>src/pgraft_go.go</code> - Complete Raft implementation (2900+ lines)</li> </ul>"},{"location":"development/building/#coding-standards","title":"Coding Standards","text":"<p>pgraft follows PostgreSQL C coding standards:</p>"},{"location":"development/building/#c89c90-compliance","title":"C89/C90 Compliance","text":"<pre><code>/* Correct: Variables at function start */\nvoid my_function(void)\n{\n    int result;\n    char *message;\n\n    result = 0;\n    message = \"Hello\";\n    /* ... function code ... */\n}\n\n/* Wrong: Variables declared in middle */\nvoid bad_function(void)\n{\n    int result = 0;\n    /* some code */\n    char *message = \"Hello\";  /* NOT at start */\n}\n</code></pre>"},{"location":"development/building/#comments","title":"Comments","text":"<pre><code>/* Correct: C-style comments */\n/* This is a proper comment */\n\n// Wrong: C++ style comments\n// This is not allowed\n</code></pre>"},{"location":"development/building/#indentation","title":"Indentation","text":"<ul> <li>Tabs only (not spaces)</li> <li>Tab width: 4 spaces</li> <li>Opening brace on same line:</li> </ul> <pre><code>/* Correct */\nif (condition)\n{\n    /* code */\n}\n\n/* Wrong */\nif (condition) {\n    /* code */\n}\n</code></pre>"},{"location":"development/building/#testing","title":"Testing","text":""},{"location":"development/building/#unit-tests","title":"Unit Tests","text":"<pre><code>cd examples\n./run.sh --destroy\n./run.sh --init\n./run.sh --status\n</code></pre>"},{"location":"development/building/#manual-testing","title":"Manual Testing","text":"<pre><code>-- Test basic functionality\nSELECT pgraft_test();\nSELECT pgraft_init();\nSELECT pgraft_is_leader();\n\n-- Test cluster operations\nSELECT pgraft_add_node(2, '127.0.0.1', 7002);\nSELECT * FROM pgraft_get_cluster_status();\n</code></pre>"},{"location":"development/building/#debugging","title":"Debugging","text":""},{"location":"development/building/#enable-debug-output","title":"Enable Debug Output","text":"<pre><code>SELECT pgraft_set_debug(true);\n</code></pre>"},{"location":"development/building/#check-logs","title":"Check Logs","text":"<pre><code>tail -f $PGDATA/log/postgresql-*.log | grep pgraft\n</code></pre>"},{"location":"development/building/#use-gdb","title":"Use GDB","text":"<pre><code># Start PostgreSQL with gdb\ngdb --args postgres -D /path/to/data\n\n# Set breakpoints\n(gdb) break pgraft_init\n(gdb) run\n\n# When breakpoint hit\n(gdb) backtrace\n(gdb) print variable_name\n</code></pre>"},{"location":"development/building/#common-debug-points","title":"Common Debug Points","text":"<pre><code>/* Add logging in C code */\nelog(LOG, \"pgraft: Debug point reached, value=%d\", value);\n\n/* Add error logging */\nelog(ERROR, \"pgraft: Error occurred: %s\", error_message);\n</code></pre>"},{"location":"development/building/#contributing","title":"Contributing","text":"<p>See Contributing for guidelines on: - Code style - Pull request process - Testing requirements - Documentation</p>"},{"location":"development/building/#performance-profiling","title":"Performance Profiling","text":""},{"location":"development/building/#cpu-profiling","title":"CPU Profiling","text":"<pre><code># Use perf on Linux\nperf record -g postgres\nperf report\n\n# Use Instruments on macOS\ninstruments -t \"Time Profiler\" postgres\n</code></pre>"},{"location":"development/building/#memory-profiling","title":"Memory Profiling","text":"<pre><code># Valgrind\nvalgrind --leak-check=full postgres -D /path/to/data\n\n# macOS Instruments\ninstruments -t \"Leaks\" postgres\n</code></pre>"},{"location":"development/building/#troubleshooting-build-issues","title":"Troubleshooting Build Issues","text":""},{"location":"development/building/#postgresql-headers-not-found","title":"PostgreSQL Headers Not Found","text":"<pre><code># Set PG_CONFIG explicitly\nexport PG_CONFIG=/usr/local/pgsql/bin/pg_config\nmake clean &amp;&amp; make\n</code></pre>"},{"location":"development/building/#go-build-fails","title":"Go Build Fails","text":"<pre><code># Ensure Go modules are downloaded\ncd src\ngo mod download\ngo mod tidy\n</code></pre>"},{"location":"development/building/#link-errors","title":"Link Errors","text":"<pre><code># Check library paths\nexport DYLD_LIBRARY_PATH=/usr/local/pgsql/lib  # macOS\nexport LD_LIBRARY_PATH=/usr/local/pgsql/lib    # Linux\n</code></pre>"},{"location":"development/building/#build-system-details","title":"Build System Details","text":"<p>The <code>Makefile</code> uses PostgreSQL's PGXS build system:</p> <pre><code>PG_CONFIG = pg_config\nPGXS := $(shell $(PG_CONFIG) --pgxs)\ninclude $(PGXS)\n</code></pre> <p>This automatically handles: - Finding PostgreSQL headers - Setting correct compiler flags - Linking with PostgreSQL libraries - Installing to correct directories</p>"},{"location":"development/contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to pgraft! This guide will help you get started.</p>"},{"location":"development/contributing/#getting-started","title":"Getting Started","text":"<ol> <li>Fork the repository on GitHub</li> <li>Clone your fork: <pre><code>git clone https://github.com/YOUR_USERNAME/pgraft.git\ncd pgraft\n</code></pre></li> <li>Create a feature branch: <pre><code>git checkout -b feature/my-new-feature\n</code></pre></li> </ol>"},{"location":"development/contributing/#development-environment","title":"Development Environment","text":""},{"location":"development/contributing/#setup","title":"Setup","text":"<p>Follow the Building from Source guide to set up your development environment.</p>"},{"location":"development/contributing/#prerequisites","title":"Prerequisites","text":"<ul> <li>PostgreSQL 17+</li> <li>Go 1.21+</li> <li>GCC/Clang</li> <li>Make</li> </ul>"},{"location":"development/contributing/#coding-standards","title":"Coding Standards","text":""},{"location":"development/contributing/#c-code-standards","title":"C Code Standards","text":"<p>pgraft follows strict PostgreSQL C coding standards:</p>"},{"location":"development/contributing/#c89c90-compliance","title":"C89/C90 Compliance","text":"<pre><code>/* All variables at function start */\nvoid my_function(void)\n{\n    int result;\n    char *message;\n    bool success;\n\n    /* Initialize variables */\n    result = 0;\n    message = NULL;\n    success = false;\n\n    /* Function code */\n}\n</code></pre>"},{"location":"development/contributing/#comments","title":"Comments","text":"<pre><code>/*\n * Use C-style comments only\n * Multi-line comments like this\n */\n\n/* Single line comments */\n\n/* NO C++ style comments */\n// Don't use these\n</code></pre>"},{"location":"development/contributing/#indentation","title":"Indentation","text":"<ul> <li>Tabs only (no spaces)</li> <li>Tab width: 4 spaces equivalent</li> <li>Opening brace on same line (usually):</li> </ul> <pre><code>if (condition)\n{\n    /* code */\n}\n</code></pre>"},{"location":"development/contributing/#naming-conventions","title":"Naming Conventions","text":"<pre><code>/* Functions: snake_case with pgraft_ prefix */\nvoid pgraft_do_something(void);\n\n/* Variables: snake_case */\nint node_count;\nchar *cluster_id;\n\n/* Macros: UPPER_CASE */\n#define PGRAFT_MAX_NODES 7\n</code></pre>"},{"location":"development/contributing/#go-code-standards","title":"Go Code Standards","text":"<p>Follow standard Go conventions:</p> <pre><code>// Use gofmt\ngofmt -w src/pgraft_go.go\n\n// Use golint\ngolint src/pgraft_go.go\n\n// Keep functions focused\n// Add comments for exported functions\n// Handle errors explicitly\n</code></pre>"},{"location":"development/contributing/#code-quality","title":"Code Quality","text":""},{"location":"development/contributing/#before-submitting","title":"Before Submitting","text":"<p>1. No compilation errors or warnings: <pre><code>make clean &amp;&amp; make 2&gt;&amp;1 | grep -E \"(error|warning)\"\n# Should be empty\n</code></pre></p> <p>2. Format code: <pre><code># C code: Follow PostgreSQL style\n# Go code:\ngofmt -w src/pgraft_go.go\n</code></pre></p> <p>3. Test thoroughly: <pre><code>cd examples\n./run.sh --destroy\n./run.sh --init\n./run.sh --status\n</code></pre></p> <p>4. Check for memory leaks (optional but recommended): <pre><code>valgrind --leak-check=full postgres -D /path/to/data\n</code></pre></p>"},{"location":"development/contributing/#testing-requirements","title":"Testing Requirements","text":""},{"location":"development/contributing/#minimum-testing","title":"Minimum Testing","text":"<p>Before submitting a pull request:</p> <ol> <li>Build successfully with no errors or warnings</li> <li>Initialize test cluster successfully</li> <li>All existing tests pass</li> <li>New feature works as documented</li> </ol>"},{"location":"development/contributing/#testing-your-changes","title":"Testing Your Changes","text":"<pre><code># 1. Clean build\nmake clean &amp;&amp; make\n\n# 2. Install\nmake install\n\n# 3. Test cluster\ncd examples\n./run.sh --destroy\n./run.sh --init\n./run.sh --status\n\n# 4. Run manual tests\npsql -p 5432 -c \"SELECT pgraft_test();\"\n# ... test your feature ...\n\n# 5. Check logs for errors\ntail -100 examples/logs/primary1/postgresql.log | grep -i error\n</code></pre>"},{"location":"development/contributing/#pull-request-process","title":"Pull Request Process","text":""},{"location":"development/contributing/#1-prepare-your-changes","title":"1. Prepare Your Changes","text":"<pre><code># Make your changes\nvim src/pgraft_core.c\n\n# Test thoroughly\nmake clean &amp;&amp; make\nmake install\n# Run tests\n\n# Commit with good message\ngit add src/pgraft_core.c\ngit commit -m \"Add feature: description of change\n\nDetailed explanation of:\n- What changed\n- Why it changed\n- How to use it\"\n</code></pre>"},{"location":"development/contributing/#2-push-to-your-fork","title":"2. Push to Your Fork","text":"<pre><code>git push origin feature/my-new-feature\n</code></pre>"},{"location":"development/contributing/#3-create-pull-request","title":"3. Create Pull Request","text":"<p>On GitHub:</p> <ol> <li>Navigate to your fork</li> <li>Click \"New Pull Request\"</li> <li>Select your feature branch</li> <li>Fill out the template:</li> </ol> <pre><code>## Description\nBrief description of the change\n\n## Motivation\nWhy is this change needed?\n\n## Changes\n- List of specific changes\n- Another change\n\n## Testing\nHow did you test this?\n\n## Checklist\n- [ ] Code compiles without errors\n- [ ] Code compiles without warnings\n- [ ] Tests pass\n- [ ] Documentation updated (if needed)\n- [ ] Follows coding standards\n</code></pre>"},{"location":"development/contributing/#4-code-review","title":"4. Code Review","text":"<p>Maintainers will review your PR:</p> <ul> <li>Respond to feedback</li> <li>Make requested changes</li> <li>Push updates to same branch (PR updates automatically)</li> </ul>"},{"location":"development/contributing/#5-merge","title":"5. Merge","text":"<p>Once approved, maintainers will merge your PR!</p>"},{"location":"development/contributing/#commit-message-guidelines","title":"Commit Message Guidelines","text":""},{"location":"development/contributing/#format","title":"Format","text":"<pre><code>Short summary (50 chars or less)\n\nLonger explanation if needed. Wrap at 72 characters.\nExplain what and why, not how.\n\n- Bullet points are fine\n- Use present tense: \"Add feature\" not \"Added feature\"\n</code></pre>"},{"location":"development/contributing/#good-examples","title":"Good Examples","text":"<pre><code>Add support for dynamic cluster membership\n\nAllows nodes to be added and removed from cluster at runtime\nwithout restarting. Uses Raft's joint consensus protocol.\n\nFix memory leak in log compaction\n\nFree allocated memory after snapshot creation.\n\nImprove error handling in network layer\n\nAdd retries for transient network failures and better\nerror messages for debugging.\n</code></pre>"},{"location":"development/contributing/#documentation","title":"Documentation","text":""},{"location":"development/contributing/#update-documentation","title":"Update Documentation","text":"<p>If your change affects:</p> <ul> <li>User-facing features: Update relevant <code>.md</code> files</li> <li>Configuration: Update GUC documentation</li> <li>SQL functions: Update function reference</li> <li>Architecture: Update architecture docs</li> </ul>"},{"location":"development/contributing/#documentation-style","title":"Documentation Style","text":"<pre><code># Use sentence case for headings\n\nWrite clear, concise sentences. Use active voice.\n\nProvide examples:\n\\`\\`\\`sql\nSELECT pgraft_example();\n\\`\\`\\`\n\nUse admonitions for important information:\n!!! warning\n    Important warning here\n</code></pre>"},{"location":"development/contributing/#areas-for-contribution","title":"Areas for Contribution","text":"<p>We welcome contributions in these areas:</p>"},{"location":"development/contributing/#high-priority","title":"High Priority","text":"<ul> <li>Testing: More test cases and scenarios</li> <li>Documentation: Examples, tutorials, guides</li> <li>Bug fixes: Check GitHub issues</li> <li>Performance: Optimization improvements</li> </ul>"},{"location":"development/contributing/#medium-priority","title":"Medium Priority","text":"<ul> <li>Monitoring: Better metrics and observability</li> <li>Security: TLS, authentication</li> <li>Platform support: Windows, BSD</li> </ul>"},{"location":"development/contributing/#nice-to-have","title":"Nice to Have","text":"<ul> <li>Tools: Cluster management utilities</li> <li>Examples: Real-world use cases</li> <li>Integrations: Connection poolers, HA tools</li> </ul>"},{"location":"development/contributing/#bug-reports","title":"Bug Reports","text":""},{"location":"development/contributing/#before-reporting","title":"Before Reporting","text":"<ol> <li>Search existing issues: Check if already reported</li> <li>Test latest version: Bug may be fixed</li> <li>Reproduce: Verify you can reproduce it</li> </ol>"},{"location":"development/contributing/#creating-good-bug-reports","title":"Creating Good Bug Reports","text":"<p>Use this template:</p> <pre><code>**Describe the bug**\nClear description of the bug\n\n**To Reproduce**\nSteps to reproduce:\n1. Do X\n2. Do Y\n3. See error\n\n**Expected behavior**\nWhat should happen\n\n**Actual behavior**\nWhat actually happens\n\n**Environment**\n- OS: [e.g. Ubuntu 22.04]\n- PostgreSQL version: [e.g. 17.2]\n- pgraft version: [e.g. 1.0.0]\n\n**Logs**\n\\`\\`\\`\nRelevant log output\n\\`\\`\\`\n\n**Configuration**\n\\`\\`\\`ini\npgraft.cluster_id = 'test'\n...\n\\`\\`\\`\n</code></pre>"},{"location":"development/contributing/#feature-requests","title":"Feature Requests","text":""},{"location":"development/contributing/#creating-feature-requests","title":"Creating Feature Requests","text":"<pre><code>**Feature Description**\nWhat feature do you want?\n\n**Use Case**\nWhy is this needed? What problem does it solve?\n\n**Proposed Solution**\nHow might this work?\n\n**Alternatives**\nOther solutions you've considered?\n\n**Additional Context**\nAny other information\n</code></pre>"},{"location":"development/contributing/#communication","title":"Communication","text":"<ul> <li>GitHub Issues: Bug reports, feature requests</li> <li>Pull Requests: Code contributions</li> <li>Discussions: Questions, ideas, help</li> </ul>"},{"location":"development/contributing/#license","title":"License","text":"<p>By contributing, you agree that your contributions will be licensed under the MIT License.</p>"},{"location":"development/contributing/#code-of-conduct","title":"Code of Conduct","text":""},{"location":"development/contributing/#our-standards","title":"Our Standards","text":"<ul> <li>Be respectful and inclusive</li> <li>Welcome newcomers</li> <li>Accept constructive criticism gracefully</li> <li>Focus on what's best for the project</li> </ul>"},{"location":"development/contributing/#unacceptable-behavior","title":"Unacceptable Behavior","text":"<ul> <li>Harassment or discrimination</li> <li>Trolling or insulting comments</li> <li>Publishing others' private information</li> <li>Other unprofessional conduct</li> </ul>"},{"location":"development/contributing/#recognition","title":"Recognition","text":"<p>Contributors will be recognized in:</p> <ul> <li>Release notes</li> <li>CONTRIBUTORS file</li> <li>Git history</li> </ul> <p>Thank you for contributing to pgraft!</p>"},{"location":"development/testing/","title":"Testing","text":"<p>This guide covers testing pgraft during development.</p>"},{"location":"development/testing/#test-harness","title":"Test Harness","text":"<p>pgraft includes a comprehensive test harness in the <code>examples/</code> directory.</p>"},{"location":"development/testing/#quick-start","title":"Quick Start","text":"<pre><code>cd examples\n\n# Destroy any existing test cluster\n./run.sh --destroy\n\n# Initialize new 3-node cluster\n./run.sh --init\n\n# Check cluster status\n./run.sh --status\n</code></pre>"},{"location":"development/testing/#test-harness-commands","title":"Test Harness Commands","text":"Command Description <code>--destroy</code> Destroy test cluster and clean up <code>--init</code> Initialize new 3-node cluster <code>--status</code> Check cluster status"},{"location":"development/testing/#test-cluster-configuration","title":"Test Cluster Configuration","text":"<p>The test harness creates a 3-node cluster:</p> <ul> <li>primary1: Node 1, PostgreSQL port 5432, Raft port 7001</li> <li>replica1: Node 2, PostgreSQL port 5433, Raft port 7002</li> <li>replica2: Node 3, PostgreSQL port 5434, Raft port 7003</li> </ul>"},{"location":"development/testing/#manual-testing","title":"Manual Testing","text":""},{"location":"development/testing/#basic-functionality","title":"Basic Functionality","text":"<pre><code>-- Test extension creation\nCREATE EXTENSION pgraft;\n\n-- Test initialization\nSELECT pgraft_init();\n-- Expected: t\n\n-- Test worker status\nSELECT pgraft_get_worker_state();\n-- Expected: RUNNING\n\n-- Test leader election (wait 10 seconds first)\nSELECT pgraft_get_leader();\n-- Expected: 1 (or another node ID)\n\n-- Test leadership check\nSELECT pgraft_is_leader();\n-- Expected: t or f\n</code></pre>"},{"location":"development/testing/#cluster-operations","title":"Cluster Operations","text":"<pre><code>-- Add node (must be on leader)\nSELECT pgraft_add_node(2, '127.0.0.1', 7002);\n-- Expected: t\n\n-- List nodes\nSELECT * FROM pgraft_get_nodes();\n-- Expected: Table with all nodes\n\n-- Cluster status\nSELECT * FROM pgraft_get_cluster_status();\n-- Expected: Status information\n\n-- Get current term\nSELECT pgraft_get_term();\n-- Expected: Integer term number\n</code></pre>"},{"location":"development/testing/#log-replication","title":"Log Replication","text":"<pre><code>-- Replicate entry\nSELECT pgraft_replicate_entry('{\"test\": \"data\"}');\n-- Expected: t (if quorum reached)\n\n-- Get log stats\nSELECT * FROM pgraft_log_get_stats();\n-- Expected: Table with statistics\n</code></pre>"},{"location":"development/testing/#failover-testing","title":"Failover Testing","text":""},{"location":"development/testing/#test-leader-failure","title":"Test Leader Failure","text":"<pre><code># 1. Identify leader\npsql -p 5432 -c \"SELECT pgraft_get_leader();\"\n\n# 2. Stop leader (e.g., if node 1 is leader)\npg_ctl stop -D examples/data/primary1 -m immediate\n\n# 3. Verify new leader elected (check on remaining nodes)\nsleep 2\npsql -p 5433 -c \"SELECT pgraft_get_leader();\"\npsql -p 5434 -c \"SELECT pgraft_get_leader();\"\n\n# 4. Restart failed node\npg_ctl start -D examples/data/primary1\n\n# 5. Verify it rejoins as follower\nsleep 2\npsql -p 5432 -c \"SELECT pgraft_is_leader();\"\n</code></pre>"},{"location":"development/testing/#test-network-partition","title":"Test Network Partition","text":"<p>Using <code>iptables</code> (Linux) or <code>pfctl</code> (macOS):</p> <pre><code># Simulate partition by blocking Raft port\n# On node 3, block communication with node 1 and 2\nsudo iptables -A INPUT -p tcp --sport 7001 -j DROP\nsudo iptables -A INPUT -p tcp --sport 7002 -j DROP\nsudo iptables -A OUTPUT -p tcp --dport 7001 -j DROP\nsudo iptables -A OUTPUT -p tcp --dport 7002 -j DROP\n\n# Verify node 3 cannot elect itself leader\npsql -p 5434 -c \"SELECT pgraft_is_leader();\"\n# Should return false\n\n# Verify nodes 1 and 2 continue with leader\npsql -p 5432 -c \"SELECT pgraft_get_leader();\"\npsql -p 5433 -c \"SELECT pgraft_get_leader();\"\n\n# Restore network\nsudo iptables -D INPUT -p tcp --sport 7001 -j DROP\nsudo iptables -D INPUT -p tcp --sport 7002 -j DROP\nsudo iptables -D OUTPUT -p tcp --dport 7001 -j DROP\nsudo iptables -D OUTPUT -p tcp --dport 7002 -j DROP\n\n# Verify node 3 rejoins\nsleep 2\npsql -p 5434 -c \"SELECT * FROM pgraft_get_cluster_status();\"\n</code></pre>"},{"location":"development/testing/#performance-testing","title":"Performance Testing","text":""},{"location":"development/testing/#throughput-test","title":"Throughput Test","text":"<pre><code>-- Test log entry replication rate\nDO $$\nDECLARE\n    start_time timestamp;\n    end_time timestamp;\n    i integer;\nBEGIN\n    start_time := clock_timestamp();\n\n    FOR i IN 1..1000 LOOP\n        PERFORM pgraft_replicate_entry('{\"test\": \"data\"}');\n    END LOOP;\n\n    end_time := clock_timestamp();\n\n    RAISE NOTICE 'Time: %', end_time - start_time;\n    RAISE NOTICE 'Entries/sec: %', 1000.0 / extract(epoch from (end_time - start_time));\nEND $$;\n</code></pre>"},{"location":"development/testing/#latency-test","title":"Latency Test","text":"<pre><code>-- Measure single entry replication latency\n\\timing on\nSELECT pgraft_replicate_entry('{\"test\": \"data\"}');\n\\timing off\n</code></pre>"},{"location":"development/testing/#stress-testing","title":"Stress Testing","text":""},{"location":"development/testing/#continuous-operations","title":"Continuous Operations","text":"<pre><code># Terminal 1: Continuous writes on leader\nwhile true; do\n    psql -p 5432 -c \"SELECT pgraft_replicate_entry(now()::text);\" 2&gt;&amp;1 | grep -v \"replicate\"\n    sleep 0.1\ndone\n\n# Terminal 2: Monitor cluster status\nwatch -n 1 \"psql -p 5432 -c 'SELECT * FROM pgraft_get_cluster_status();'\"\n\n# Terminal 3: Simulate failures\n# Stop/start nodes randomly\n</code></pre>"},{"location":"development/testing/#sustained-load","title":"Sustained Load","text":"<pre><code># Generate sustained load\nfor i in {1..10000}; do\n    psql -p 5432 -c \"SELECT pgraft_replicate_entry('entry_$i');\" &amp;\n    if [ $((i % 100)) -eq 0 ]; then\n        wait  # Wait every 100 to avoid overwhelming\n    fi\ndone\nwait\n</code></pre>"},{"location":"development/testing/#integration-testing","title":"Integration Testing","text":""},{"location":"development/testing/#multi-node-test-script","title":"Multi-Node Test Script","text":"<p>Create <code>test_cluster.sh</code>:</p> <pre><code>#!/bin/bash\n\necho \"Testing cluster operations...\"\n\n# Test on all nodes\nfor PORT in 5432 5433 5434; do\n    echo \"Node on port $PORT:\"\n    psql -p $PORT -c \"SELECT pgraft_is_leader(), pgraft_get_term();\" -t\ndone\n\n# Get leader\nLEADER_PORT=$(psql -p 5432 -c \"SELECT pgraft_get_leader();\" -t | tr -d ' ')\nLEADER_PORT=$((5431 + LEADER_PORT))\n\necho \"Leader is on port $LEADER_PORT\"\n\n# Add and remove node on leader\necho \"Testing add/remove node on leader...\"\npsql -p $LEADER_PORT -c \"SELECT pgraft_add_node(4, '127.0.0.1', 7004);\"\nsleep 1\npsql -p $LEADER_PORT -c \"SELECT * FROM pgraft_get_nodes();\"\npsql -p $LEADER_PORT -c \"SELECT pgraft_remove_node(4);\"\nsleep 1\npsql -p $LEADER_PORT -c \"SELECT * FROM pgraft_get_nodes();\"\n\necho \"Test completed!\"\n</code></pre>"},{"location":"development/testing/#regression-testing","title":"Regression Testing","text":""},{"location":"development/testing/#sql-test-suite","title":"SQL Test Suite","text":"<p>Create <code>regression_tests.sql</code>:</p> <pre><code>-- Test 1: Extension creation\nCREATE EXTENSION IF NOT EXISTS pgraft;\n\n-- Test 2: Initialization\nSELECT pgraft_init();\n\n-- Wait for leader election\nSELECT pg_sleep(2);\n\n-- Test 3: Worker running\nSELECT pgraft_get_worker_state() = 'RUNNING' AS worker_ok;\n\n-- Test 4: Leader elected\nSELECT pgraft_get_leader() &gt; 0 AS leader_elected;\n\n-- Test 5: Get term\nSELECT pgraft_get_term() &gt; 0 AS term_ok;\n\n-- Test 6: Cluster status\nSELECT node_id, term, state FROM pgraft_get_cluster_status();\n\n-- Test 7: Log operations (on leader only)\nDO $$\nBEGIN\n    IF pgraft_is_leader() THEN\n        PERFORM pgraft_replicate_entry('test_entry');\n    END IF;\nEND $$;\n\n-- Test 8: Log statistics\nSELECT * FROM pgraft_log_get_stats();\n\n-- Test 9: Version\nSELECT pgraft_get_version();\n\n-- Test 10: Debug mode\nSELECT pgraft_set_debug(true);\nSELECT pgraft_set_debug(false);\n</code></pre> <p>Run tests: <pre><code>psql -f regression_tests.sql\n</code></pre></p>"},{"location":"development/testing/#automated-testing","title":"Automated Testing","text":""},{"location":"development/testing/#github-actions","title":"GitHub Actions","text":"<p>The repository includes GitHub Actions workflow for CI/CD (see <code>.github/workflows/test.yml</code>).</p>"},{"location":"development/testing/#local-automation","title":"Local Automation","text":"<pre><code>#!/bin/bash\n# automated_test.sh\n\nset -e  # Exit on error\n\necho \"Starting automated tests...\"\n\n# Clean slate\ncd examples\n./run.sh --destroy\n\n# Initialize\n./run.sh --init\nsleep 5  # Wait for cluster to stabilize\n\n# Run regression tests on all nodes\nfor PORT in 5432 5433 5434; do\n    echo \"Testing node on port $PORT...\"\n    psql -p $PORT -f ../tests/regression_tests.sql\ndone\n\n# Failover test\necho \"Testing failover...\"\nLEADER=$(psql -p 5432 -t -c \"SELECT pgraft_get_leader();\" | tr -d ' ')\nLEADER_PORT=$((5431 + LEADER))\n\npg_ctl stop -D data/node$LEADER -m immediate\nsleep 3\nNEW_LEADER=$(psql -p $((LEADER_PORT + 1)) -t -c \"SELECT pgraft_get_leader();\" | tr -d ' ')\n\nif [ \"$NEW_LEADER\" != \"$LEADER\" ]; then\n    echo \"\u2713 Failover successful\"\nelse\n    echo \"\u2717 Failover failed\"\n    exit 1\nfi\n\n# Cleanup\n./run.sh --destroy\n\necho \"All tests passed!\"\n</code></pre>"},{"location":"development/testing/#test-coverage","title":"Test Coverage","text":"<p>Key areas to test:</p> <ul> <li>Extension creation and initialization</li> <li>Background worker startup</li> <li>Leader election</li> <li>Node addition (on leader)</li> <li>Node addition (on follower - should fail)</li> <li>Node removal</li> <li>Log replication</li> <li>Cluster status queries</li> <li>Leader failure and recovery</li> <li>Network partition handling</li> <li>Concurrent operations</li> <li>Configuration changes</li> <li>Snapshot creation and recovery</li> </ul>"},{"location":"development/testing/#debugging-test-failures","title":"Debugging Test Failures","text":""},{"location":"development/testing/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code>SELECT pgraft_set_debug(true);\n</code></pre>"},{"location":"development/testing/#check-logs","title":"Check Logs","text":"<pre><code># View logs for all nodes\ntail -f examples/logs/primary1/postgresql.log &amp;\ntail -f examples/logs/replica1/postgresql.log &amp;\ntail -f examples/logs/replica2/postgresql.log &amp;\n</code></pre>"},{"location":"development/testing/#common-issues","title":"Common Issues","text":"<p>Leader not elected: - Check network connectivity - Verify clock synchronization - Increase election timeout</p> <p>Node won't join: - Verify configuration matches - Check firewall rules - Ensure node is initialized</p> <p>Replication lag: - Check disk I/O - Monitor network latency - Review snapshot settings</p>"},{"location":"development/testing/#reporting-issues","title":"Reporting Issues","text":"<p>When reporting test failures, include:</p> <ol> <li>Test scenario: What were you testing?</li> <li>Expected result: What should happen?</li> <li>Actual result: What actually happened?</li> <li>Logs: Relevant log excerpts (with debug enabled)</li> <li>Configuration: postgresql.conf settings</li> <li>Environment: OS, PostgreSQL version, pgraft version</li> </ol>"},{"location":"getting-started/","title":"Getting Started with pgraft (pgElephant Suite)","text":"<p>Welcome! This section will help you get up and running with pgraft, part of the unified pgElephant high-availability suite (see also: RAM, RALE, FauxDB).</p>"},{"location":"getting-started/#what-is-pgraft","title":"What is pgraft?","text":"<p>pgraft is a PostgreSQL extension that brings production-grade Raft consensus, automatic leader election, crash-safe log replication, and 100% split-brain prevention to distributed PostgreSQL clusters. All configuration and monitoring is unified with the rest of the pgElephant suite.</p>"},{"location":"getting-started/#quick-navigation","title":"Quick Navigation","text":"<ul> <li>Install pgraft</li> <li>Quick Start Guide</li> <li>Complete Tutorial</li> <li>Configuration Reference</li> <li>Cluster Operations</li> </ul>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<ul> <li>PostgreSQL 17+ with development headers</li> <li>Go 1.21+ for building</li> <li>GCC or compatible C compiler</li> <li>Basic knowledge of PostgreSQL and distributed systems</li> </ul>"},{"location":"getting-started/#learning-path","title":"Learning Path","text":"<ol> <li>Installation \u2014 Get pgraft installed on your system</li> <li>Quick Start \u2014 Create your first 3-node cluster</li> <li>Tutorial \u2014 Learn all features in depth</li> <li>Configuration \u2014 Understand all available settings</li> <li>Operations \u2014 Learn monitoring and maintenance</li> </ol>"},{"location":"getting-started/#system-requirements","title":"System Requirements","text":"<p>Minimum: - CPU: 2 cores per node - RAM: 4GB per node - Disk: 10GB free space per node - Network: Reliable connectivity between nodes</p> <p>Recommended for Production: - CPU: 4+ cores per node - RAM: 16GB+ per node - Disk: SSD or NVMe storage - Network: 1 Gbps with &lt;10ms latency between nodes</p>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li>New to pgraft? Start with Installation</li> <li>Want to test quickly? Jump to Quick Start</li> <li>Need detailed guidance? Check the Complete Tutorial</li> </ul>"},{"location":"getting-started/#support-community","title":"Support &amp; Community","text":"<ul> <li>Documentation: You're reading it!</li> <li>Issues: GitHub Issues</li> <li>Source Code: GitHub Repository</li> </ul>"},{"location":"getting-started/installation/","title":"Installation (pgElephant Suite)","text":"<p>This guide will walk you through installing pgraft, part of the unified pgElephant high-availability suite. All steps and troubleshooting are up to date for the latest release.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing pgraft, ensure you have the following:</p> <ul> <li>PostgreSQL: Version 17.6 or higher</li> <li>Go: Version 1.21 or higher</li> <li>GCC: C compiler</li> <li>PostgreSQL development headers</li> </ul>"},{"location":"getting-started/installation/#system-specific-prerequisites","title":"System-Specific Prerequisites","text":"Ubuntu/DebianCentOS/RHELmacOS <pre><code>sudo apt-get update\nsudo apt-get install postgresql-17 postgresql-server-dev-17 golang-go build-essential\n</code></pre> <pre><code>sudo yum install postgresql17 postgresql17-devel golang gcc make\n</code></pre> <pre><code>brew install postgresql@17 go\n</code></pre>"},{"location":"getting-started/installation/#build-from-source","title":"Build from Source","text":""},{"location":"getting-started/installation/#1-clone-the-repository","title":"1. Clone the Repository","text":"<pre><code>git clone https://github.com/pgelephant/pgraft.git\ncd pgraft\n</code></pre>"},{"location":"getting-started/installation/#2-build-the-extension","title":"2. Build the Extension","text":"<pre><code>make clean\nmake\n</code></pre> <p>Check for Errors</p> <p>You can verify the build completed without errors: <pre><code>make 2&gt;&amp;1 | grep -i error\nmake 2&gt;&amp;1 | grep -i warning\n</code></pre></p>"},{"location":"getting-started/installation/#3-install-the-extension","title":"3. Install the Extension","text":"<pre><code># Manual installation\ncp pgraft.dylib /usr/local/pgsql.17/lib/\ncp src/pgraft_go.dylib /usr/local/pgsql.17/lib/\ncp pgraft.control /usr/local/pgsql.17/share/extension/\ncp pgraft--1.0.sql /usr/local/pgsql.17/share/extension/\n</code></pre> <p>Path Configuration</p> <p>Adjust the paths above based on your PostgreSQL installation location. Common paths: - macOS (Homebrew): <code>/usr/local/opt/postgresql@17/</code> - Linux: <code>/usr/lib/postgresql/17/</code> - Custom: Use <code>pg_config --libdir</code> and <code>pg_config --sharedir</code></p>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>After installation, verify that pgraft is properly installed:</p> <pre><code># Check that the extension files exist\nls -l $(pg_config --libdir)/pgraft*.dylib\nls -l $(pg_config --sharedir)/extension/pgraft*\n</code></pre>"},{"location":"getting-started/installation/#next-steps","title":"Next Steps","text":"<p>Now that pgraft is installed, you can:</p> <ul> <li>Set up your first cluster</li> <li>Learn about configuration options</li> <li>Follow the complete tutorial</li> </ul>"},{"location":"getting-started/installation/#troubleshooting","title":"Troubleshooting","text":""},{"location":"getting-started/installation/#postgresql-development-headers-not-found","title":"PostgreSQL Development Headers Not Found","text":"<p>If you get errors about missing PostgreSQL headers during build:</p> <pre><code># Ubuntu/Debian\nsudo apt-get install postgresql-server-dev-17\n\n# CentOS/RHEL\nsudo yum install postgresql17-devel\n</code></pre>"},{"location":"getting-started/installation/#go-not-found","title":"Go Not Found","text":"<p>Ensure Go is installed and in your PATH:</p> <pre><code>go version  # Should show Go 1.21 or higher\n</code></pre>"},{"location":"getting-started/installation/#permission-denied","title":"Permission Denied","text":"<p>If you get permission errors during installation:</p> <pre><code># Use sudo for copying to system directories\nsudo cp pgraft.dylib /usr/local/pgsql.17/lib/\n</code></pre>"},{"location":"getting-started/quick-start/","title":"Quick Start (pgElephant Suite)","text":"<p>Get your first pgraft cluster up and running in minutes! All steps and health checks are up to date for the latest release and unified with the pgElephant suite.</p>"},{"location":"getting-started/quick-start/#step-1-configure-postgresql","title":"Step 1: Configure PostgreSQL","text":"<p>Add these settings to your <code>postgresql.conf</code>:</p> <pre><code>shared_preload_libraries = 'pgraft'\n\n# Core cluster configuration\npgraft.cluster_id = 'production-cluster'\npgraft.node_id = 1\npgraft.address = '127.0.0.1'\npgraft.port = 7001\npgraft.data_dir = '/var/lib/postgresql/pgraft'\n\n# Consensus settings (optional, these are defaults)\npgraft.election_timeout = 1000        # milliseconds\npgraft.heartbeat_interval = 100       # milliseconds\npgraft.snapshot_interval = 10000      # entries\npgraft.max_log_entries = 1000         # compaction threshold\n</code></pre> <p>Configuration Tips</p> <ul> <li><code>node_id</code> must be unique for each node (1, 2, 3, ...)</li> <li><code>cluster_id</code> must be the same for all nodes in the cluster</li> <li><code>port</code> is for Raft communication (not PostgreSQL port)</li> </ul>"},{"location":"getting-started/quick-start/#step-2-restart-postgresql","title":"Step 2: Restart PostgreSQL","text":"<pre><code># Restart PostgreSQL to load the extension\npg_ctl restart -D /path/to/data\n</code></pre>"},{"location":"getting-started/quick-start/#step-3-initialize-pgraft","title":"Step 3: Initialize pgraft","text":"<p>Connect to PostgreSQL and create the extension:</p> <pre><code>-- Create extension\nCREATE EXTENSION pgraft;\n\n-- Initialize node\nSELECT pgraft_init();\n</code></pre> Expected Output <pre><code> pgraft_init \n-------------\n t\n(1 row)\n</code></pre>"},{"location":"getting-started/quick-start/#step-4-set-up-additional-nodes","title":"Step 4: Set Up Additional Nodes","text":"<p>Repeat steps 1-3 on other nodes with different <code>node_id</code> values:</p> <p>Node 2 (<code>postgresql.conf</code>): <pre><code>pgraft.node_id = 2\npgraft.port = 7002\n</code></pre></p> <p>Node 3 (<code>postgresql.conf</code>): <pre><code>pgraft.node_id = 3\npgraft.port = 7003\n</code></pre></p>"},{"location":"getting-started/quick-start/#step-5-add-nodes-to-cluster","title":"Step 5: Add Nodes to Cluster","text":"<p>Leader Only</p> <p>Node addition must be performed only on the leader node.</p> <p>Wait 10 seconds for leader election, then check which node is the leader:</p> <pre><code>-- Check if current node is leader\nSELECT pgraft_is_leader();\n\n-- Get leader ID\nSELECT pgraft_get_leader();\n</code></pre> <p>On the leader node, add the other nodes:</p> <pre><code>SELECT pgraft_add_node(2, '127.0.0.1', 7002);\nSELECT pgraft_add_node(3, '127.0.0.1', 7003);\n</code></pre>"},{"location":"getting-started/quick-start/#step-6-verify-cluster-status","title":"Step 6: Verify Cluster Status","text":"<p>On any node, check the cluster status:</p> <pre><code>-- Get cluster status\nSELECT * FROM pgraft_get_cluster_status();\n\n-- Get all nodes\nSELECT * FROM pgraft_get_nodes();\n\n-- Check worker status\nSELECT pgraft_get_worker_state();\n</code></pre> Expected Output <pre><code>SELECT * FROM pgraft_get_nodes();\n\n node_id |   address   | port | is_leader \n---------+-------------+------+-----------\n       1 | 127.0.0.1   | 7001 | t\n       2 | 127.0.0.1   | 7002 | f\n       3 | 127.0.0.1   | 7003 | f\n(3 rows)\n</code></pre>"},{"location":"getting-started/quick-start/#quick-health-check","title":"Quick Health Check","text":"<p>Run this query to quickly verify your cluster is healthy:</p> <pre><code>SELECT \n    pgraft_is_leader() as is_leader,\n    pgraft_get_term() as term,\n    pgraft_get_leader() as leader_id,\n    pgraft_get_worker_state() as worker;\n</code></pre> <p>Success</p> <p>You now have a working pgraft cluster with automatic leader election and log replication!</p>"},{"location":"getting-started/quick-start/#next-steps","title":"Next Steps","text":"<ul> <li>Learn more about configuration options</li> <li>Follow the complete tutorial</li> <li>Understand the architecture</li> <li>Learn about automatic replication</li> </ul>"},{"location":"getting-started/quick-start/#using-the-test-harness","title":"Using the Test Harness","text":"<p>For testing and development, use the included test harness:</p> <pre><code>cd examples\n\n# Destroy existing cluster\n./run.sh --destroy\n\n# Initialize new cluster\n./run.sh --init\n\n# Check status\n./run.sh --status\n\n# View logs\ntail -f logs/primary1/postgresql.log\n</code></pre>"},{"location":"operations/","title":"Operations Guide","text":"<p>Production operations, monitoring, and maintenance for pgraft clusters.</p>"},{"location":"operations/#overview","title":"Overview","text":"<p>This section covers everything you need to know to operate pgraft clusters in production, from monitoring to troubleshooting to best practices.</p>"},{"location":"operations/#contents","title":"Contents","text":""},{"location":"operations/#monitoring","title":"Monitoring","text":"<p>Learn how to monitor cluster health, performance, and replication status.</p> <p>Monitoring Guide</p>"},{"location":"operations/#troubleshooting","title":"Troubleshooting","text":"<p>Solutions for common issues and debugging techniques.</p> <p>Troubleshooting Guide</p>"},{"location":"operations/#best-practices","title":"Best Practices","text":"<p>Production-tested recommendations for configuration, deployment, and maintenance.</p> <p>Best Practices</p>"},{"location":"operations/#quick-reference","title":"Quick Reference","text":""},{"location":"operations/#health-checks","title":"Health Checks","text":"<p>Quick health check: <pre><code>SELECT \n    pgraft_is_leader() as is_leader,\n    pgraft_get_term() as term,\n    pgraft_get_leader() as leader_id,\n    pgraft_get_worker_state() as worker;\n</code></pre></p> <p>Detailed status: <pre><code>SELECT * FROM pgraft_get_cluster_status();\nSELECT * FROM pgraft_get_nodes();\nSELECT * FROM pgraft_log_get_stats();\n</code></pre></p>"},{"location":"operations/#common-issues","title":"Common Issues","text":"Issue Quick Check Solution Worker not running <code>SELECT pgraft_get_worker_state();</code> Check <code>shared_preload_libraries</code>, restart PostgreSQL No leader elected <code>SELECT pgraft_get_leader();</code> Wait 10 seconds, check network connectivity Cannot add node <code>SELECT pgraft_is_leader();</code> Run on leader node only Frequent elections <code>SELECT pgraft_get_term();</code> Increase election timeout, check network"},{"location":"operations/#key-metrics-to-monitor","title":"Key Metrics to Monitor","text":"<p>Critical (alert if failing): - Leader exists: <code>pgraft_get_leader() &gt; 0</code> - Worker running: <code>pgraft_get_worker_state() = 'RUNNING'</code> - Node reachable: Network connectivity</p> <p>Important (monitor trends): - Term number (should be stable) - Log replication lag - Election frequency - Disk usage for log storage</p>"},{"location":"operations/#emergency-procedures","title":"Emergency Procedures","text":"<p>Lost quorum (majority of nodes failed): 1. Cluster becomes read-only 2. Restore failed nodes or add new ones 3. Once quorum restored, leader will be elected 4. Cluster resumes normal operation</p> <p>Complete cluster failure: 1. Restore nodes from backup 2. Start all PostgreSQL instances 3. Wait 10 seconds for election 4. Verify leader elected: <code>SELECT pgraft_get_leader();</code></p>"},{"location":"operations/#production-checklist","title":"Production Checklist","text":""},{"location":"operations/#before-deployment","title":"Before Deployment","text":"<ul> <li> Cluster size is odd (3, 5, or 7 nodes)</li> <li> Nodes distributed across availability zones</li> <li> Election timeout tuned for network latency</li> <li> Monitoring and alerting configured</li> <li> Backup strategy in place</li> <li> Disaster recovery plan documented</li> <li> Failover scenarios tested</li> <li> Network security configured</li> <li> Performance baselines established</li> <li> Team trained on operations</li> </ul>"},{"location":"operations/#daily-operations","title":"Daily Operations","text":"<ul> <li> Check cluster status</li> <li> Verify leader exists</li> <li> Check worker state on all nodes</li> <li> Review error logs</li> </ul>"},{"location":"operations/#weekly-maintenance","title":"Weekly Maintenance","text":"<ul> <li> Review monitoring metrics</li> <li> Check log file sizes and disk usage</li> <li> Verify backups are running</li> <li> Review and analyze any alerts</li> </ul>"},{"location":"operations/#monthly-tasks","title":"Monthly Tasks","text":"<ul> <li> Test disaster recovery procedures</li> <li> Review and optimize configuration</li> <li> Update documentation</li> <li> Performance review and tuning</li> </ul>"},{"location":"operations/#monitoring-tools","title":"Monitoring Tools","text":""},{"location":"operations/#built-in-functions","title":"Built-in Functions","text":"<p>pgraft provides SQL functions for monitoring:</p> <ul> <li><code>pgraft_get_cluster_status()</code> - Overall cluster state</li> <li><code>pgraft_get_nodes()</code> - All cluster members</li> <li><code>pgraft_log_get_stats()</code> - Log statistics</li> <li><code>pgraft_get_worker_state()</code> - Background worker status</li> <li><code>pgraft_is_leader()</code> - Leadership status</li> </ul>"},{"location":"operations/#external-monitoring","title":"External Monitoring","text":"<p>Prometheus (if enabled): <pre><code>pgraft.metrics_enabled = true\npgraft.metrics_port = 9100\n</code></pre></p> <p>Metrics available at <code>http://node:9100/metrics</code></p> <p>PostgreSQL Logs: <pre><code>tail -f $PGDATA/log/postgresql-*.log | grep pgraft:\n</code></pre></p> <p>Custom Monitoring Script: <pre><code>#!/bin/bash\n# Check cluster health every 60 seconds\nwhile true; do\n    psql -c \"SELECT * FROM pgraft_get_cluster_status();\"\n    sleep 60\ndone\n</code></pre></p>"},{"location":"operations/#performance-tuning","title":"Performance Tuning","text":""},{"location":"operations/#network-latency","title":"Network Latency","text":"<p>Low latency (&lt;10ms): <pre><code>pgraft.election_timeout = 1000  # 1 second\npgraft.heartbeat_interval = 100 # 100ms\n</code></pre></p> <p>Medium latency (10-50ms): <pre><code>pgraft.election_timeout = 2000  # 2 seconds\npgraft.heartbeat_interval = 200 # 200ms\n</code></pre></p> <p>High latency (&gt;50ms): <pre><code>pgraft.election_timeout = 5000  # 5 seconds\npgraft.heartbeat_interval = 500 # 500ms\n</code></pre></p>"},{"location":"operations/#throughput-optimization","title":"Throughput Optimization","text":"<pre><code># Larger batches for higher throughput\npgraft.batch_size = 200\npgraft.max_batch_delay = 20\n\n# More frequent snapshots for faster recovery\npgraft.snapshot_interval = 5000\npgraft.max_log_entries = 500\n</code></pre>"},{"location":"operations/#security","title":"Security","text":""},{"location":"operations/#network-security","title":"Network Security","text":"<ul> <li>Use private networks or VPN for inter-node communication</li> <li>Configure firewalls to allow only necessary ports</li> <li>Consider enabling TLS (when available)</li> </ul>"},{"location":"operations/#access-control","title":"Access Control","text":"<ul> <li>pgraft functions require superuser privileges</li> <li>Don't grant superuser to application users</li> <li>Use connection limits and pg_hba.conf appropriately</li> </ul>"},{"location":"operations/#audit-logging","title":"Audit Logging","text":"<p>Enable PostgreSQL logging for pgraft operations: <pre><code>log_statement = 'all'\nlog_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '\n</code></pre></p>"},{"location":"operations/#backup-and-recovery","title":"Backup and Recovery","text":""},{"location":"operations/#what-to-backup","title":"What to Backup","text":"<ol> <li>PostgreSQL data directory - All database data</li> <li>pgraft data directory - Raft state and logs</li> <li>Configuration files - postgresql.conf</li> </ol>"},{"location":"operations/#backup-strategy","title":"Backup Strategy","text":"<pre><code># PostgreSQL data\npg_basebackup -D /backup/pgdata -Ft -z -P\n\n# pgraft state\ntar -czf /backup/pgraft-$(date +%Y%m%d).tar.gz $PGRAFT_DATA_DIR\n\n# Configuration\ncp $PGDATA/postgresql.conf /backup/\n</code></pre>"},{"location":"operations/#recovery-procedure","title":"Recovery Procedure","text":"<ol> <li>Stop PostgreSQL</li> <li>Restore data from backup</li> <li>Restore pgraft state</li> <li>Restore configuration</li> <li>Start PostgreSQL</li> <li>Verify cluster rejoins</li> </ol>"},{"location":"operations/#resources","title":"Resources","text":"<ul> <li>Detailed monitoring: Monitoring Guide</li> <li>Problem solving: Troubleshooting Guide</li> <li>Production tips: Best Practices</li> <li>Understanding internals: Architecture</li> </ul>"},{"location":"operations/best-practices/","title":"Best Practices","text":"<p>Follow these best practices for running pgraft in production.</p>"},{"location":"operations/best-practices/#cluster-size","title":"Cluster Size","text":""},{"location":"operations/best-practices/#use-odd-number-of-nodes","title":"Use Odd Number of Nodes","text":"<p>Always use an odd number of nodes (3, 5, 7) for better fault tolerance:</p> Nodes Fault Tolerance Recommended For 3 1 node failure Development, small production 5 2 node failures Production (recommended) 7 3 node failures High-availability critical systems <p>Don't Use Even Numbers</p> <p>4 nodes tolerates only 1 failure (same as 3) 6 nodes tolerates only 2 failures (same as 5) Even numbers waste resources!</p>"},{"location":"operations/best-practices/#dont-go-too-large","title":"Don't Go Too Large","text":"<p>Avoid &gt;7 nodes: - More nodes = more replication overhead - Diminishing returns on availability - Slower consensus</p> <p>If you need more than 7 nodes, consider: - Multiple independent clusters - Read replicas (outside Raft cluster) - Sharding</p>"},{"location":"operations/best-practices/#geographic-distribution","title":"Geographic Distribution","text":""},{"location":"operations/best-practices/#multi-zone-deployment","title":"Multi-Zone Deployment","text":"<p>For disaster recovery, distribute nodes across zones:</p> <p>5-node example: <pre><code>Zone A (2 nodes): Primary data center\nZone B (2 nodes): Secondary data center  \nZone C (1 node): Tiebreaker/DR site\n</code></pre></p> <p>Benefits: - Survives zone failure - Tiebreaker prevents split votes - Geographic disaster recovery</p>"},{"location":"operations/best-practices/#network-considerations","title":"Network Considerations","text":"<ul> <li>Low latency required: &lt;50ms between nodes</li> <li>Stable network: Packet loss &lt;0.1%</li> <li>Sufficient bandwidth: For log replication</li> </ul> <p>High Latency</p> <p>If latency &gt;50ms between zones, increase election timeout: <pre><code>pgraft.election_timeout = 2000  # 2 seconds for WAN\n</code></pre></p>"},{"location":"operations/best-practices/#configuration","title":"Configuration","text":""},{"location":"operations/best-practices/#election-timeout","title":"Election Timeout","text":"<p>Rules of thumb:</p> <pre><code># LAN deployment (low latency &lt;10ms)\npgraft.election_timeout = 1000  # 1 second\n\n# WAN deployment (medium latency 10-50ms)\npgraft.election_timeout = 2000  # 2 seconds\n\n# High latency (&gt;50ms)\npgraft.election_timeout = 5000  # 5 seconds\n</code></pre> <p>Key relationship: <pre><code>election_timeout &gt;= 10 \u00d7 heartbeat_interval\n</code></pre></p>"},{"location":"operations/best-practices/#heartbeat-interval","title":"Heartbeat Interval","text":"<pre><code># Default (recommended)\npgraft.heartbeat_interval = 100  # 100ms\n\n# High-throughput systems\npgraft.heartbeat_interval = 50   # 50ms (more network traffic)\n\n# Low-priority systems\npgraft.heartbeat_interval = 200  # 200ms (less overhead)\n</code></pre>"},{"location":"operations/best-practices/#snapshot-configuration","title":"Snapshot Configuration","text":"<pre><code># Frequent snapshots (faster recovery, more I/O)\npgraft.snapshot_interval = 5000\npgraft.max_log_entries = 500\n\n# Infrequent snapshots (less I/O, slower recovery)\npgraft.snapshot_interval = 100000\npgraft.max_log_entries = 10000\n</code></pre> <p>Trade-offs: - Frequent snapshots: Faster crash recovery, more I/O - Infrequent snapshots: Better performance, slower recovery</p>"},{"location":"operations/best-practices/#operations","title":"Operations","text":""},{"location":"operations/best-practices/#adding-nodes","title":"Adding Nodes","text":"<p>Always add nodes on the leader:</p> <pre><code>-- 1. Check if leader\nSELECT pgraft_is_leader();\n\n-- 2. If not leader, find and connect to leader\nSELECT pgraft_get_leader();\n\n-- 3. Add node\nSELECT pgraft_add_node(4, '192.168.1.14', 7004);\n</code></pre> <p>Best practice: Add one node at a time, wait for it to catch up before adding next.</p>"},{"location":"operations/best-practices/#removing-nodes","title":"Removing Nodes","text":"<p>Graceful removal:</p> <pre><code>-- 1. Verify cluster health\nSELECT * FROM pgraft_get_cluster_status();\n\n-- 2. Remove node (on leader)\nSELECT pgraft_remove_node(4);\n\n-- 3. Shutdown removed node's PostgreSQL\n-- On node 4:\npg_ctl stop -D /data/node4\n</code></pre> <p>Never remove nodes during: - Active elections - Network partitions - While already removing another node</p>"},{"location":"operations/best-practices/#upgrading","title":"Upgrading","text":"<p>Rolling upgrade procedure:</p> <ol> <li> <p>Upgrade followers first: <pre><code># On follower node:\npg_ctl stop -D /data/node2\n# Install new pgraft version\nmake clean &amp;&amp; make &amp;&amp; make install\npg_ctl start -D /data/node2\n</code></pre></p> </li> <li> <p>Then upgrade leader: <pre><code># On leader, wait for followers to be healthy\n# Then upgrade leader last\npg_ctl stop -D /data/node1\n# Install new version\npg_ctl start -D /data/node1\n</code></pre></p> </li> </ol>"},{"location":"operations/best-practices/#monitoring","title":"Monitoring","text":""},{"location":"operations/best-practices/#critical-metrics","title":"Critical Metrics","text":"<p>Monitor these continuously:</p> <pre><code>-- Leader exists (should always be true)\nSELECT pgraft_get_leader() &gt; 0;\n\n-- Worker running (should always be RUNNING)\nSELECT pgraft_get_worker_state() = 'RUNNING';\n\n-- Term stable (should not increase frequently)\nSELECT pgraft_get_term();\n</code></pre>"},{"location":"operations/best-practices/#set-up-alerts","title":"Set Up Alerts","text":"<p>Critical alerts: - No leader for &gt;10 seconds - Worker not running - Node unreachable</p> <p>Warning alerts: - Term increased (election occurred) - Log lag &gt;1000 entries - Replication to follower slow</p> <p>See Monitoring for details.</p>"},{"location":"operations/best-practices/#backup-and-recovery","title":"Backup and Recovery","text":""},{"location":"operations/best-practices/#backup-strategy","title":"Backup Strategy","text":"<p>1. Backup PostgreSQL data: <pre><code>pg_basebackup -D /backup/node1 -Ft -z -P\n</code></pre></p> <p>2. Backup pgraft state: <pre><code># Backup pgraft data directory\ntar -czf pgraft-backup.tar.gz $PGRAFT_DATA_DIR\n</code></pre></p> <p>3. Backup configuration: <pre><code>cp $PGDATA/postgresql.conf /backup/\n</code></pre></p>"},{"location":"operations/best-practices/#disaster-recovery","title":"Disaster Recovery","text":"<p>Scenario: Total cluster loss</p> <ol> <li>Restore one node from backup</li> <li>Initialize new cluster: <pre><code>CREATE EXTENSION pgraft;\nSELECT pgraft_init();\n</code></pre></li> <li>Add other nodes: <pre><code>SELECT pgraft_add_node(2, '192.168.1.12', 7002);\nSELECT pgraft_add_node(3, '192.168.1.13', 7003);\n</code></pre></li> </ol>"},{"location":"operations/best-practices/#security","title":"Security","text":""},{"location":"operations/best-practices/#network-security","title":"Network Security","text":"<p>Firewall rules: <pre><code># Allow Raft communication between nodes\n# Node 1 \u2192 Node 2, 3\niptables -A INPUT -p tcp --dport 7002 -s node1_ip -j ACCEPT\niptables -A INPUT -p tcp --dport 7003 -s node1_ip -j ACCEPT\n\n# Node 2 \u2192 Node 1, 3\n# ... etc\n</code></pre></p> <p>Best practice: Use VPN or private network for inter-node communication.</p>"},{"location":"operations/best-practices/#access-control","title":"Access Control","text":"<p>Limit pgraft functions to superuser: <pre><code>-- pgraft functions already require superuser\n-- Don't grant superuser to application users\n</code></pre></p>"},{"location":"operations/best-practices/#performance","title":"Performance","text":""},{"location":"operations/best-practices/#hardware-recommendations","title":"Hardware Recommendations","text":"<p>Minimum (per node): - CPU: 2 cores - RAM: 4GB - Disk: SSD with &gt;100 IOPS - Network: 100 Mbps</p> <p>Production (per node): - CPU: 4+ cores - RAM: 16GB+ - Disk: NVMe SSD with &gt;1000 IOPS - Network: 1 Gbps+</p>"},{"location":"operations/best-practices/#disk-io","title":"Disk I/O","text":"<p>Recommendations: - Use SSD or NVMe for pgraft data directory - Separate disk from PostgreSQL data if possible - Monitor disk I/O wait time</p>"},{"location":"operations/best-practices/#network","title":"Network","text":"<p>Recommendations: - Dedicated network for Raft traffic (if possible) - Monitor network latency continuously - Use quality of service (QoS) for Raft ports</p>"},{"location":"operations/best-practices/#testing","title":"Testing","text":""},{"location":"operations/best-practices/#test-failover-scenarios","title":"Test Failover Scenarios","text":"<p>Test 1: Leader failure <pre><code># Kill leader process\npg_ctl stop -D /data/leader -m immediate\n\n# Verify new leader elected\npsql -h follower1 -c \"SELECT pgraft_get_leader();\"\n\n# Restart failed node\npg_ctl start -D /data/leader\n</code></pre></p> <p>Test 2: Network partition <pre><code># Simulate partition using iptables\niptables -A INPUT -s node2_ip -j DROP\niptables -A OUTPUT -d node2_ip -j DROP\n\n# Verify majority partition continues\n# Restore network\niptables -D INPUT -s node2_ip -j DROP\niptables -D OUTPUT -d node2_ip -j DROP\n</code></pre></p> <p>Test 3: Slow follower <pre><code># Simulate slow disk\n# On follower, use cgroup or tc to throttle I/O\ntc qdisc add dev sda root tbf rate 1mbit burst 32kbit latency 400ms\n\n# Verify leader continues operating\n# Remove throttle\ntc qdisc del dev sda root\n</code></pre></p>"},{"location":"operations/best-practices/#checklist","title":"Checklist","text":""},{"location":"operations/best-practices/#before-going-to-production","title":"Before Going to Production","text":"<ul> <li> Cluster size is odd (3, 5, or 7 nodes)</li> <li> Nodes distributed across availability zones</li> <li> Election timeout tuned for network latency</li> <li> Monitoring and alerting configured</li> <li> Backup strategy in place</li> <li> Disaster recovery plan documented</li> <li> Failover scenarios tested</li> <li> Network security configured</li> <li> Performance baselines established</li> <li> Team trained on operations</li> </ul>"},{"location":"operations/best-practices/#regular-maintenance","title":"Regular Maintenance","text":"<p>Daily: - [ ] Check cluster status - [ ] Verify leader exists - [ ] Check worker state</p> <p>Weekly: - [ ] Review monitoring metrics - [ ] Check log file sizes - [ ] Verify backups</p> <p>Monthly: - [ ] Test disaster recovery - [ ] Review and optimize configuration - [ ] Update documentation</p>"},{"location":"operations/best-practices/#common-pitfalls","title":"Common Pitfalls","text":""},{"location":"operations/best-practices/#dont","title":"Don't","text":"<ol> <li>Use even number of nodes - Waste of resources</li> <li>Add nodes during elections - Wait for stable leader</li> <li>Ignore monitoring - Set up alerts!</li> <li>Run on slow disks - Use SSD/NVMe</li> <li>Deploy across high-latency links without tuning timeouts</li> <li>Add multiple nodes simultaneously - Add one at a time</li> <li>Forget to backup pgraft state - Backup both PostgreSQL and pgraft data</li> </ol>"},{"location":"operations/best-practices/#do","title":"Do","text":"<ol> <li>Use 3, 5, or 7 nodes for optimal fault tolerance</li> <li>Monitor continuously - Leader, worker, term, logs</li> <li>Test failover scenarios regularly</li> <li>Use fast storage - SSD or better</li> <li>Distribute geographically for disaster recovery</li> <li>Tune for your network - Adjust timeouts based on latency</li> <li>Document your setup - Configuration, topology, procedures</li> <li>Train your team - Everyone should know how to operate pgraft</li> </ol>"},{"location":"operations/best-practices/#production-deployment-example","title":"Production Deployment Example","text":"<p>Here's a complete production configuration:</p> <pre><code># postgresql.conf - Production Node 1\n\n# PostgreSQL basics\nport = 5432\nmax_connections = 200\nshared_buffers = 4GB\n\n# pgraft extension\nshared_preload_libraries = 'pgraft'\n\n# Core cluster configuration\npgraft.cluster_id = 'production-cluster'\npgraft.node_id = 1\npgraft.address = '10.0.1.11'\npgraft.port = 7001\npgraft.data_dir = '/var/lib/postgresql/pgraft'\n\n# Consensus settings (tuned for datacenter LAN)\npgraft.election_timeout = 1000\npgraft.heartbeat_interval = 100\npgraft.snapshot_interval = 10000\npgraft.max_log_entries = 1000\n\n# Performance\npgraft.batch_size = 100\npgraft.max_batch_delay = 10\npgraft.compaction_threshold = 10000\n\n# Monitoring\npgraft.metrics_enabled = true\npgraft.metrics_port = 9100\n</code></pre> <p>Repeat for nodes 2, 3, 4, 5 with different <code>node_id</code>, <code>address</code>, and <code>port</code> values.</p>"},{"location":"operations/monitoring/","title":"Monitoring","text":"<p>This page describes how to monitor your pgraft cluster for health, performance, and troubleshooting.</p>"},{"location":"operations/monitoring/#quick-health-check","title":"Quick Health Check","text":"<p>Run this query on any node to get a quick overview:</p> <pre><code>SELECT \n    pgraft_is_leader() as is_leader,\n    pgraft_get_term() as term,\n    pgraft_get_leader() as leader_id,\n    pgraft_get_worker_state() as worker;\n</code></pre> <p>Expected output: <pre><code> is_leader | term | leader_id | worker  \n-----------+------+-----------+---------\n f         |   42 |         1 | RUNNING\n</code></pre></p>"},{"location":"operations/monitoring/#cluster-status","title":"Cluster Status","text":""},{"location":"operations/monitoring/#get-detailed-cluster-status","title":"Get Detailed Cluster Status","text":"<pre><code>SELECT * FROM pgraft_get_cluster_status();\n</code></pre> <p>Output includes: - Current term - Leader ID - Node state (Leader/Follower/Candidate) - Number of nodes in cluster</p>"},{"location":"operations/monitoring/#list-all-nodes","title":"List All Nodes","text":"<pre><code>SELECT * FROM pgraft_get_nodes();\n</code></pre> <p>Sample output: <pre><code> node_id |   address   | port | is_leader \n---------+-------------+------+-----------\n       1 | 127.0.0.1   | 7001 | t\n       2 | 127.0.0.1   | 7002 | f\n       3 | 127.0.0.1   | 7003 | f\n</code></pre></p>"},{"location":"operations/monitoring/#worker-status","title":"Worker Status","text":""},{"location":"operations/monitoring/#check-background-worker","title":"Check Background Worker","text":"<p>The background worker is responsible for driving the Raft consensus:</p> <pre><code>SELECT pgraft_get_worker_state();\n</code></pre> <p>Possible states: - <code>RUNNING</code>: Normal operation - <code>STOPPED</code>: Worker not running - <code>ERROR</code>: Worker encountered error</p>"},{"location":"operations/monitoring/#troubleshoot-worker-issues","title":"Troubleshoot Worker Issues","text":"<p>If worker is not running:</p> <pre><code>-- 1. Check if extension is loaded\nSELECT * FROM pg_extension WHERE extname = 'pgraft';\n\n-- 2. Check shared_preload_libraries\nSHOW shared_preload_libraries;\n\n-- Should include 'pgraft'\n</code></pre>"},{"location":"operations/monitoring/#log-monitoring","title":"Log Monitoring","text":""},{"location":"operations/monitoring/#get-log-statistics","title":"Get Log Statistics","text":"<pre><code>SELECT * FROM pgraft_log_get_stats();\n</code></pre> <p>Output: <pre><code> log_size | last_index | commit_index | last_applied \n----------+------------+--------------+--------------\n     1000 |       1000 |          995 |          995\n</code></pre></p> <p>What to monitor:</p> <ul> <li>log_size: Total number of log entries</li> <li>last_index: Index of last log entry</li> <li>commit_index: Last committed entry</li> <li>last_applied: Last applied entry</li> </ul> <p>Lag Detection</p> <p>If <code>commit_index</code> is significantly behind <code>last_index</code>, followers may be lagging.</p>"},{"location":"operations/monitoring/#check-replication-status","title":"Check Replication Status","text":"<p>On the leader:</p> <pre><code>SELECT * FROM pgraft_log_get_replication_status();\n</code></pre> <p>Shows replication progress for each follower.</p>"},{"location":"operations/monitoring/#performance-metrics","title":"Performance Metrics","text":""},{"location":"operations/monitoring/#key-metrics-to-monitor","title":"Key Metrics to Monitor","text":"Metric SQL Query Normal Range Alert If Term stability <code>SELECT pgraft_get_term();</code> Stable Frequent changes Leader stability <code>SELECT pgraft_get_leader();</code> Stable Frequent changes Worker state <code>SELECT pgraft_get_worker_state();</code> RUNNING Not RUNNING Log lag <code>SELECT * FROM pgraft_log_get_stats();</code> commit_index \u2248 last_index Large difference"},{"location":"operations/monitoring/#monitoring-script","title":"Monitoring Script","text":"<p>Create a monitoring script that runs periodically:</p> <pre><code>-- monitoring.sql\n\\set QUIET on\n\\pset format unaligned\n\\pset fieldsep ','\n\\pset tuples_only on\n\nSELECT \n    now() as timestamp,\n    pgraft_is_leader() as is_leader,\n    pgraft_get_term() as term,\n    pgraft_get_leader() as leader_id,\n    pgraft_get_worker_state() as worker_state;\n\n\\pset tuples_only off\n</code></pre> <p>Run it: <pre><code>psql -f monitoring.sql &gt;&gt; pgraft_metrics.csv\n</code></pre></p>"},{"location":"operations/monitoring/#prometheus-metrics","title":"Prometheus Metrics","text":"<p>Enable Prometheus metrics in <code>postgresql.conf</code>:</p> <pre><code>pgraft.metrics_enabled = true\npgraft.metrics_port = 9100\n</code></pre>"},{"location":"operations/monitoring/#available-metrics","title":"Available Metrics","text":"<p>Metrics are exposed at <code>http://node-address:9100/metrics</code>:</p> <ul> <li><code>pgraft_term</code>: Current Raft term</li> <li><code>pgraft_leader_id</code>: Current leader ID</li> <li><code>pgraft_is_leader</code>: 1 if leader, 0 if follower</li> <li><code>pgraft_log_size</code>: Number of log entries</li> <li><code>pgraft_commit_index</code>: Last committed index</li> <li><code>pgraft_applied_index</code>: Last applied index</li> </ul>"},{"location":"operations/monitoring/#grafana-dashboard","title":"Grafana Dashboard","text":"<p>Sample Prometheus queries for Grafana:</p> <pre><code># Leader election frequency\nrate(pgraft_term[5m])\n\n# Cluster has leader (should be 1)\nmax(pgraft_is_leader)\n\n# Log lag\npgraft_log_size - pgraft_commit_index\n</code></pre>"},{"location":"operations/monitoring/#log-files","title":"Log Files","text":""},{"location":"operations/monitoring/#postgresql-logs","title":"PostgreSQL Logs","text":"<p>pgraft logs to PostgreSQL's standard log:</p> <pre><code>tail -f /path/to/postgresql/log/postgresql-*.log | grep pgraft\n</code></pre>"},{"location":"operations/monitoring/#log-levels","title":"Log Levels","text":"<p>Enable debug logging:</p> <pre><code>SELECT pgraft_set_debug(true);\n</code></pre> <p>Disable debug logging:</p> <pre><code>SELECT pgraft_set_debug(false);\n</code></pre>"},{"location":"operations/monitoring/#important-log-messages","title":"Important Log Messages","text":"<p>Normal operation: <pre><code>pgraft: Background worker started\npgraft: Raft node initialized, node_id=1\npgraft: Elected as leader in term 5\npgraft: Heartbeat sent to node 2\n</code></pre></p> <p>Warning signs: <pre><code>pgraft: Election timeout, starting election\npgraft: Lost leadership, stepping down\npgraft: Failed to replicate to majority\n</code></pre></p> <p>Errors: <pre><code>pgraft: Cannot add node - this node is not the leader\npgraft: Failed to persist HardState\npgraft: Network connection failed to node 2\n</code></pre></p>"},{"location":"operations/monitoring/#alerting","title":"Alerting","text":""},{"location":"operations/monitoring/#critical-alerts","title":"Critical Alerts","text":"<p>Set up alerts for these conditions:</p> <p>No Leader: <pre><code>SELECT pgraft_get_leader() = 0;\n-- Alert if true for &gt; 10 seconds\n</code></pre></p> <p>Worker Not Running: <pre><code>SELECT pgraft_get_worker_state() != 'RUNNING';\n-- Alert immediately\n</code></pre></p> <p>Frequent Leader Changes: <pre><code>-- Monitor pgraft_get_term()\n-- Alert if changes &gt; 3 times per minute\n</code></pre></p>"},{"location":"operations/monitoring/#warning-alerts","title":"Warning Alerts","text":"<p>Log Lag: <pre><code>SELECT last_index - commit_index &gt; 100 \nFROM pgraft_log_get_stats();\n-- Alert if true\n</code></pre></p> <p>Term Increasing: <pre><code>-- Monitor pgraft_get_term()\n-- Warn if increases (indicates elections happening)\n</code></pre></p>"},{"location":"operations/monitoring/#health-check-endpoint","title":"Health Check Endpoint","text":"<p>Create a health check function for load balancers:</p> <pre><code>CREATE OR REPLACE FUNCTION pgraft_health_check()\nRETURNS json AS $$\nDECLARE\n    result json;\nBEGIN\n    SELECT json_build_object(\n        'healthy', pgraft_get_worker_state() = 'RUNNING',\n        'is_leader', pgraft_is_leader(),\n        'leader_id', pgraft_get_leader(),\n        'term', pgraft_get_term()\n    ) INTO result;\n\n    RETURN result;\nEND;\n$$ LANGUAGE plpgsql;\n\n-- Usage\nSELECT pgraft_health_check();\n</code></pre> <p>Output: <pre><code>{\n  \"healthy\": true,\n  \"is_leader\": false,\n  \"leader_id\": 1,\n  \"term\": 42\n}\n</code></pre></p>"},{"location":"operations/monitoring/#monitoring-checklist","title":"Monitoring Checklist","text":"<p>Daily: - [ ] Check worker state on all nodes - [ ] Verify leader is elected - [ ] Check for errors in logs</p> <p>Weekly: - [ ] Review term changes (should be stable) - [ ] Check log statistics - [ ] Verify all nodes are in cluster</p> <p>Monthly: - [ ] Review performance metrics - [ ] Check disk usage for log storage - [ ] Test failover scenarios</p>"},{"location":"operations/monitoring/#example-monitoring-dashboard","title":"Example Monitoring Dashboard","text":"<p>Here's a sample SQL script for a monitoring dashboard:</p> <pre><code>-- pgraft_dashboard.sql\n\n\\echo 'Cluster Overview'\n\\echo '================'\nSELECT \n    'Leader ID' as metric, \n    pgraft_get_leader()::text as value\nUNION ALL\nSELECT \n    'Current Term', \n    pgraft_get_term()::text\nUNION ALL\nSELECT \n    'Worker State', \n    pgraft_get_worker_state();\n\n\\echo ''\n\\echo 'Cluster Nodes'\n\\echo '============='\nSELECT * FROM pgraft_get_nodes();\n\n\\echo ''\n\\echo 'Log Statistics'\n\\echo '=============='\nSELECT * FROM pgraft_log_get_stats();\n\n\\echo ''\n\\echo 'Node Status'\n\\echo '==========='\nSELECT \n    CASE WHEN pgraft_is_leader() THEN 'LEADER' ELSE 'FOLLOWER' END as role,\n    pgraft_get_worker_state() as worker;\n</code></pre> <p>Run it: <pre><code>psql -f pgraft_dashboard.sql\n</code></pre></p>"},{"location":"operations/troubleshooting/","title":"Troubleshooting","text":"<p>This page covers common issues and their solutions.</p>"},{"location":"operations/troubleshooting/#worker-not-running","title":"Worker Not Running","text":""},{"location":"operations/troubleshooting/#symptom","title":"Symptom","text":"<pre><code>SELECT pgraft_get_worker_state();\n-- Returns: STOPPED or ERROR\n</code></pre>"},{"location":"operations/troubleshooting/#diagnosis","title":"Diagnosis","text":"<p>Check if pgraft is in <code>shared_preload_libraries</code>:</p> <pre><code>SHOW shared_preload_libraries;\n</code></pre>"},{"location":"operations/troubleshooting/#solution","title":"Solution","text":"<ol> <li> <p>Add pgraft to <code>postgresql.conf</code>: <pre><code>shared_preload_libraries = 'pgraft'\n</code></pre></p> </li> <li> <p>Restart PostgreSQL: <pre><code>pg_ctl restart -D /path/to/data\n</code></pre></p> </li> <li> <p>Verify: <pre><code>SELECT pgraft_get_worker_state();\n-- Should return: RUNNING\n</code></pre></p> </li> </ol>"},{"location":"operations/troubleshooting/#cannot-add-node","title":"Cannot Add Node","text":""},{"location":"operations/troubleshooting/#symptom_1","title":"Symptom","text":"<pre><code>SELECT pgraft_add_node(2, '127.0.0.1', 7002);\n-- Error: \"Cannot add node - this node is not the leader\"\n</code></pre>"},{"location":"operations/troubleshooting/#diagnosis_1","title":"Diagnosis","text":"<p>You're trying to add a node on a follower. Only the leader can add nodes.</p>"},{"location":"operations/troubleshooting/#solution_1","title":"Solution","text":"<ol> <li> <p>Find the leader: <pre><code>SELECT pgraft_get_leader();  -- Returns leader node ID\n</code></pre></p> </li> <li> <p>Connect to the leader node and run the command there: <pre><code># If node 1 is leader, connect to its PostgreSQL port\npsql -h 127.0.0.1 -p 5432 -c \"SELECT pgraft_add_node(2, '127.0.0.1', 7002);\"\n</code></pre></p> </li> </ol>"},{"location":"operations/troubleshooting/#no-leader-elected","title":"No Leader Elected","text":""},{"location":"operations/troubleshooting/#symptom_2","title":"Symptom","text":"<pre><code>SELECT pgraft_get_leader();\n-- Returns: 0 (no leader)\n\nSELECT * FROM pgraft_get_cluster_status();\n-- Shows term 0 or very low term\n</code></pre>"},{"location":"operations/troubleshooting/#possible-causes","title":"Possible Causes","text":"<ol> <li>Cluster just started: Leader election takes ~1 second</li> <li>Network issues: Nodes cannot communicate</li> <li>No quorum: Insufficient nodes for majority</li> <li>Configuration mismatch: Nodes have different cluster_ids</li> </ol>"},{"location":"operations/troubleshooting/#solution_2","title":"Solution","text":""},{"location":"operations/troubleshooting/#1-wait-for-election","title":"1. Wait for Election","text":"<pre><code># Wait 10 seconds and check again\nsleep 10\npsql -c \"SELECT pgraft_get_leader();\"\n</code></pre>"},{"location":"operations/troubleshooting/#2-check-network-connectivity","title":"2. Check Network Connectivity","text":"<pre><code># From Node 1, test connection to Node 2's Raft port\nnc -zv 127.0.0.1 7002\n\n# Or use telnet\ntelnet 127.0.0.1 7002\n</code></pre>"},{"location":"operations/troubleshooting/#3-verify-cluster-configuration","title":"3. Verify Cluster Configuration","text":"<pre><code>-- On each node, check configuration\nSHOW pgraft.cluster_id;  -- Must be same on all nodes\nSHOW pgraft.node_id;     -- Must be unique per node\nSHOW pgraft.address;     -- Node's own address\nSHOW pgraft.port;        -- Raft port (not PostgreSQL port)\n</code></pre>"},{"location":"operations/troubleshooting/#4-check-logs","title":"4. Check Logs","text":"<pre><code>tail -100 /path/to/postgresql/log/postgresql-*.log | grep pgraft\n</code></pre> <p>Look for errors like: - \"Connection refused\" - \"Network unreachable\" - \"Failed to send message\"</p>"},{"location":"operations/troubleshooting/#frequent-leader-changes","title":"Frequent Leader Changes","text":""},{"location":"operations/troubleshooting/#symptom_3","title":"Symptom","text":"<pre><code>-- Term keeps increasing rapidly\nSELECT pgraft_get_term();\n-- Returns: 156 (very high)\n\n-- Different leader each time you check\nSELECT pgraft_get_leader();\n</code></pre>"},{"location":"operations/troubleshooting/#possible-causes_1","title":"Possible Causes","text":"<ol> <li>Network instability: Packet loss or high latency</li> <li>Election timeout too low: Nodes timeout before receiving heartbeats</li> <li>Node overload: Nodes too busy to respond in time</li> </ol>"},{"location":"operations/troubleshooting/#solution_3","title":"Solution","text":""},{"location":"operations/troubleshooting/#1-increase-election-timeout","title":"1. Increase Election Timeout","text":"<p>Edit <code>postgresql.conf</code>: <pre><code># Increase from 1000ms to 2000ms or higher\npgraft.election_timeout = 2000\n</code></pre></p> <p>Restart PostgreSQL on all nodes.</p>"},{"location":"operations/troubleshooting/#2-check-network-latency","title":"2. Check Network Latency","text":"<pre><code># Measure latency between nodes\nping -c 10 node2_address\n\n# Check packet loss\nping -c 100 node2_address | grep loss\n</code></pre>"},{"location":"operations/troubleshooting/#3-monitor-system-load","title":"3. Monitor System Load","text":"<pre><code># Check CPU usage\ntop\n\n# Check if PostgreSQL is swapping\nvmstat 1 10\n</code></pre>"},{"location":"operations/troubleshooting/#node-cannot-join-cluster","title":"Node Cannot Join Cluster","text":""},{"location":"operations/troubleshooting/#symptom_4","title":"Symptom","text":"<p>Added node using <code>pgraft_add_node()</code> but node doesn't appear in cluster:</p> <pre><code>SELECT * FROM pgraft_get_nodes();\n-- New node not listed\n</code></pre>"},{"location":"operations/troubleshooting/#diagnosis_2","title":"Diagnosis","text":""},{"location":"operations/troubleshooting/#1-check-if-node-is-running","title":"1. Check if Node is Running","text":"<pre><code># On the new node\npsql -c \"SELECT pgraft_get_worker_state();\"\n# Should be RUNNING\n</code></pre>"},{"location":"operations/troubleshooting/#2-check-node-configuration","title":"2. Check Node Configuration","text":"<pre><code>-- On the new node\nSHOW pgraft.cluster_id;  -- Must match existing cluster\nSHOW pgraft.node_id;     -- Must match ID used in pgraft_add_node()\nSHOW pgraft.address;     -- Must match address used in pgraft_add_node()\nSHOW pgraft.port;        -- Must match port used in pgraft_add_node()\n</code></pre>"},{"location":"operations/troubleshooting/#solution_4","title":"Solution","text":"<ol> <li> <p>Ensure node is initialized: <pre><code>-- On the new node\nCREATE EXTENSION IF NOT EXISTS pgraft;\nSELECT pgraft_init();\n</code></pre></p> </li> <li> <p>Verify network connectivity: <pre><code># From existing node to new node\nnc -zv new_node_address new_node_port\n\n# From new node to existing nodes\nnc -zv existing_node_address existing_node_port\n</code></pre></p> </li> <li> <p>Check firewall rules: <pre><code># Ensure Raft ports are open\nsudo firewall-cmd --list-all  # CentOS/RHEL\nsudo ufw status               # Ubuntu\n</code></pre></p> </li> </ol>"},{"location":"operations/troubleshooting/#data-directory-errors","title":"Data Directory Errors","text":""},{"location":"operations/troubleshooting/#symptom_5","title":"Symptom","text":"<pre><code>ERROR: pgraft: Failed to persist HardState\nERROR: pgraft: Cannot create directory\n</code></pre>"},{"location":"operations/troubleshooting/#solution_5","title":"Solution","text":"<ol> <li> <p>Check directory permissions: <pre><code># Ensure PostgreSQL can write to data_dir\nls -ld /var/lib/postgresql/pgraft\n# Should be owned by postgres user\n\n# If not, fix permissions:\nsudo chown -R postgres:postgres /var/lib/postgresql/pgraft\nsudo chmod 700 /var/lib/postgresql/pgraft\n</code></pre></p> </li> <li> <p>Check disk space: <pre><code>df -h /var/lib/postgresql/pgraft\n</code></pre></p> </li> <li> <p>Verify configuration: <pre><code>SHOW pgraft.data_dir;\n</code></pre></p> </li> </ol>"},{"location":"operations/troubleshooting/#extension-wont-load","title":"Extension Won't Load","text":""},{"location":"operations/troubleshooting/#symptom_6","title":"Symptom","text":"<pre><code>CREATE EXTENSION pgraft;\n-- ERROR: could not load library \"pgraft\"\n</code></pre>"},{"location":"operations/troubleshooting/#solution_6","title":"Solution","text":"<ol> <li> <p>Verify extension files are installed: <pre><code># Check library files\nls -l $(pg_config --libdir)/pgraft*.dylib\nls -l $(pg_config --libdir)/pgraft_go.dylib\n\n# Check SQL files\nls -l $(pg_config --sharedir)/extension/pgraft*\n</code></pre></p> </li> <li> <p>Check file permissions: <pre><code>chmod 755 $(pg_config --libdir)/pgraft*.dylib\n</code></pre></p> </li> <li> <p>Verify architecture compatibility: <pre><code># Check if library is for correct architecture\nfile $(pg_config --libdir)/pgraft.dylib\n\n# Should match your system architecture\nuname -m\n</code></pre></p> </li> <li> <p>Check for missing dependencies: <pre><code># macOS\notool -L $(pg_config --libdir)/pgraft.dylib\n\n# Linux\nldd $(pg_config --libdir)/pgraft.so\n</code></pre></p> </li> </ol>"},{"location":"operations/troubleshooting/#compilation-errors","title":"Compilation Errors","text":""},{"location":"operations/troubleshooting/#symptom_7","title":"Symptom","text":"<pre><code>make\n-- Errors during compilation\n</code></pre>"},{"location":"operations/troubleshooting/#solution_7","title":"Solution","text":""},{"location":"operations/troubleshooting/#1-postgresql-development-headers-missing","title":"1. PostgreSQL Development Headers Missing","text":"<pre><code># Ubuntu/Debian\nsudo apt-get install postgresql-server-dev-17\n\n# CentOS/RHEL\nsudo yum install postgresql17-devel\n\n# macOS\nbrew install postgresql@17\n</code></pre>"},{"location":"operations/troubleshooting/#2-go-not-found","title":"2. Go Not Found","text":"<pre><code># Check Go installation\ngo version\n\n# If not installed:\n# Ubuntu/Debian\nsudo apt-get install golang-go\n\n# macOS\nbrew install go\n</code></pre>"},{"location":"operations/troubleshooting/#3-pg_config-not-in-path","title":"3. pg_config Not in PATH","text":"<pre><code># Find pg_config\nwhich pg_config\n\n# If not found, add to PATH:\nexport PATH=\"/usr/local/pgsql/bin:$PATH\"\n\n# Or set PG_CONFIG in Makefile\nmake PG_CONFIG=/path/to/pg_config\n</code></pre>"},{"location":"operations/troubleshooting/#performance-issues","title":"Performance Issues","text":""},{"location":"operations/troubleshooting/#symptom_8","title":"Symptom","text":"<ul> <li>High CPU usage</li> <li>Slow replication</li> <li>Queries taking too long</li> </ul>"},{"location":"operations/troubleshooting/#diagnosis_3","title":"Diagnosis","text":"<pre><code>-- Check log lag\nSELECT * FROM pgraft_log_get_stats();\n\n-- Monitor replication\nSELECT * FROM pgraft_log_get_replication_status();\n</code></pre>"},{"location":"operations/troubleshooting/#solution_8","title":"Solution","text":""},{"location":"operations/troubleshooting/#1-tune-batch-settings","title":"1. Tune Batch Settings","text":"<pre><code># Increase batch size for better throughput\npgraft.batch_size = 200\npgraft.max_batch_delay = 20\n</code></pre>"},{"location":"operations/troubleshooting/#2-adjust-snapshot-frequency","title":"2. Adjust Snapshot Frequency","text":"<pre><code># More frequent snapshots reduce log size\npgraft.snapshot_interval = 5000\npgraft.max_log_entries = 500\n</code></pre>"},{"location":"operations/troubleshooting/#3-check-system-resources","title":"3. Check System Resources","text":"<pre><code># CPU usage\ntop -p $(pidof postgres)\n\n# Memory usage\nfree -h\n\n# I/O wait\niostat -x 1 10\n</code></pre>"},{"location":"operations/troubleshooting/#split-brain-concerns","title":"Split-Brain Concerns","text":""},{"location":"operations/troubleshooting/#symptom_9","title":"Symptom","text":"<p>\"I'm worried about split-brain. How do I verify protection?\"</p>"},{"location":"operations/troubleshooting/#verification","title":"Verification","text":"<ol> <li> <p>Test minority partition: <pre><code># In a 3-node cluster, isolate one node\n# On isolated node:\npsql -c \"SELECT pgraft_is_leader();\"  # Should be false\npsql -c \"SELECT pgraft_add_node(4, '127.0.0.1', 7004);\"  # Should fail\n\n# On majority partition (2 nodes):\npsql -c \"SELECT pgraft_is_leader();\"  # One should be true\npsql -c \"SELECT pgraft_add_node(4, '127.0.0.1', 7004);\"  # Should succeed\n</code></pre></p> </li> <li> <p>Monitor term numbers: <pre><code>-- Term should be stable during normal operation\nSELECT pgraft_get_term();\n</code></pre></p> </li> </ol> <p>See Split-Brain Protection for detailed explanation.</p>"},{"location":"operations/troubleshooting/#debug-mode","title":"Debug Mode","text":""},{"location":"operations/troubleshooting/#enable-debug-logging","title":"Enable Debug Logging","text":"<pre><code>SELECT pgraft_set_debug(true);\n</code></pre> <p>This will log detailed information about: - Raft messages - State transitions - Log replication - Network events</p>"},{"location":"operations/troubleshooting/#view-debug-logs","title":"View Debug Logs","text":"<pre><code>tail -f /path/to/postgresql/log/postgresql-*.log | grep \"pgraft:\"\n</code></pre>"},{"location":"operations/troubleshooting/#disable-debug-logging","title":"Disable Debug Logging","text":"<pre><code>SELECT pgraft_set_debug(false);\n</code></pre>"},{"location":"operations/troubleshooting/#getting-help","title":"Getting Help","text":"<p>If you're still experiencing issues:</p> <ol> <li> <p>Check logs: <pre><code>tail -100 /path/to/postgresql/log/postgresql-*.log | grep pgraft\n</code></pre></p> </li> <li> <p>Gather diagnostic information: <pre><code>SELECT pgraft_get_version();\nSELECT * FROM pgraft_get_cluster_status();\nSELECT * FROM pgraft_get_nodes();\nSELECT * FROM pgraft_log_get_stats();\nSELECT pgraft_get_worker_state();\n</code></pre></p> </li> <li> <p>Enable debug mode and reproduce the issue: <pre><code>SELECT pgraft_set_debug(true);\n-- Reproduce the problem\n-- Copy relevant logs\nSELECT pgraft_set_debug(false);\n</code></pre></p> </li> <li> <p>Report the issue on the GitHub repository with:</p> </li> <li>pgraft version</li> <li>PostgreSQL version</li> <li>Operating system</li> <li>Configuration (postgresql.conf relevant sections)</li> <li>Error messages and logs</li> <li>Steps to reproduce</li> </ol>"},{"location":"user-guide/","title":"User Guide (pgElephant Suite)","text":"<p>Comprehensive guides for using pgraft in production, as part of the unified pgElephant high-availability suite. All documentation and product pages share a consistent, professional template and feature matrix.</p>"},{"location":"user-guide/#overview","title":"Overview","text":"<p>This section contains detailed documentation for operating pgraft clusters, from basic configuration to advanced cluster operations. For related products, see RAM, RALE, and FauxDB.</p>"},{"location":"user-guide/#contents","title":"Contents","text":"<ul> <li>Complete Tutorial \u2014 Step-by-step guide covering installation, configuration, and advanced usage scenarios</li> <li>Configuration Guide \u2014 Complete reference of all configuration parameters and tuning guidelines</li> <li>SQL Functions \u2014 Comprehensive reference for all SQL functions provided by pgraft</li> <li>Cluster Operations \u2014 Learn how to add/remove nodes, handle elections, and perform maintenance</li> </ul>"},{"location":"user-guide/#quick-links","title":"Quick Links","text":"<p>Common Tasks: - Initialize a node: <code>SELECT pgraft_init();</code> - Check if leader: <code>SELECT pgraft_is_leader();</code> - Add a node: <code>SELECT pgraft_add_node(node_id, address, port);</code> - Get cluster status: <code>SELECT * FROM pgraft_get_cluster_status();</code> - View all nodes: <code>SELECT * FROM pgraft_get_nodes();</code></p> <p>Key Configuration Parameters: - <code>pgraft.cluster_id</code> \u2014 Cluster identifier (must match on all nodes) - <code>pgraft.node_id</code> \u2014 Unique node identifier - <code>pgraft.address</code> \u2014 Node listen address - <code>pgraft.port</code> \u2014 Raft communication port - <code>pgraft.election_timeout</code> \u2014 Election timeout in milliseconds</p> <p>Common Patterns:</p> <p>Three-node cluster setup: <pre><code>-- On each node\nCREATE EXTENSION pgraft;\nSELECT pgraft_init();\n\n-- On leader (after 10 seconds)\nSELECT pgraft_add_node(2, '192.168.1.12', 7002);\nSELECT pgraft_add_node(3, '192.168.1.13', 7003);\n</code></pre></p> <p>Health check: <pre><code>SELECT \n    pgraft_is_leader() as is_leader,\n    pgraft_get_term() as term,\n    pgraft_get_leader() as leader_id,\n    pgraft_get_worker_state() as worker;\n</code></pre></p>"},{"location":"user-guide/#best-practices","title":"Best Practices","text":"<ol> <li>Use odd number of nodes (3, 5, or 7) for optimal fault tolerance</li> <li>Always add nodes from the leader \u2014 Configuration replicates automatically</li> <li>Monitor continuously \u2014 Track leader, term, and worker status</li> <li>Test failover scenarios before going to production</li> <li>Use fast storage \u2014 SSD or NVMe recommended</li> </ol>"},{"location":"user-guide/#next-steps","title":"Next Steps","text":"<ul> <li>New users: Start with the Complete Tutorial</li> <li>Configuring pgraft: See Configuration Reference</li> <li>Need SQL reference: Check SQL Functions</li> <li>Managing clusters: Read Cluster Operations</li> </ul>"},{"location":"user-guide/cluster-operations/","title":"Cluster Operations (pgElephant Suite)","text":"<p>This guide covers common cluster operations and management tasks for pgraft, part of the unified pgElephant high-availability suite. All steps and best practices are up to date and consistent with the latest release.</p>"},{"location":"user-guide/cluster-operations/#adding-nodes","title":"Adding Nodes","text":""},{"location":"user-guide/cluster-operations/#prerequisites","title":"Prerequisites","text":"<p>Before adding a node:</p> <ol> <li>Node is configured with matching <code>cluster_id</code></li> <li>PostgreSQL is running on the new node</li> <li>pgraft extension is created and initialized</li> <li>Network connectivity exists between nodes</li> <li>You are on the leader node</li> </ol>"},{"location":"user-guide/cluster-operations/#step-by-step","title":"Step-by-Step","text":"<p>1. Prepare the new node:</p> <pre><code># On the new node (e.g., Node 4)\n# Edit postgresql.conf\ncat &gt;&gt; $PGDATA/postgresql.conf &lt;&lt;EOF\nshared_preload_libraries = 'pgraft'\npgraft.cluster_id = 'production-cluster'  # Must match existing cluster\npgraft.node_id = 4                        # Unique ID\npgraft.address = '192.168.1.14'\npgraft.port = 7004\npgraft.data_dir = '/var/lib/postgresql/pgraft'\nEOF\n\n# Restart PostgreSQL\npg_ctl restart -D $PGDATA\n\n# Initialize pgraft\npsql -c \"CREATE EXTENSION pgraft;\"\npsql -c \"SELECT pgraft_init();\"\n</code></pre> <p>2. Add node from leader:</p> <pre><code>-- On the current leader\n-- First, verify you are the leader\nSELECT pgraft_is_leader();\n-- Should return: t\n\n-- Add the new node\nSELECT pgraft_add_node(4, '192.168.1.14', 7004);\n-- Should return: t\n\n-- Verify node was added\nSELECT * FROM pgraft_get_nodes();\n</code></pre> <p>3. Verify on all nodes:</p> <pre><code># Check on all nodes that they see the new node\nfor port in 5432 5433 5434; do\n    echo \"Node on port $port:\"\n    psql -p $port -c \"SELECT * FROM pgraft_get_nodes();\"\ndone\n</code></pre>"},{"location":"user-guide/cluster-operations/#important-notes","title":"Important Notes","text":"<p>Leader Only</p> <p>Nodes can ONLY be added from the leader. Attempting to add from a follower will fail with: \"Cannot add node - this node is not the leader\"</p> <p>Automatic Replication</p> <p>When you add a node on the leader, the configuration change automatically replicates to ALL nodes in the cluster. You do not need to run the command on each node.</p>"},{"location":"user-guide/cluster-operations/#removing-nodes","title":"Removing Nodes","text":""},{"location":"user-guide/cluster-operations/#when-to-remove","title":"When to Remove","text":"<ul> <li>Node is permanently decommissioned</li> <li>Downsizing cluster</li> <li>Replacing failed hardware</li> </ul>"},{"location":"user-guide/cluster-operations/#step-by-step_1","title":"Step-by-Step","text":"<p>1. Identify the node to remove:</p> <pre><code>SELECT * FROM pgraft_get_nodes();\n</code></pre> <p>2. Remove from cluster (on leader):</p> <pre><code>-- Verify you are the leader\nSELECT pgraft_is_leader();\n\n-- Remove the node\nSELECT pgraft_remove_node(4);\n-- Should return: t\n</code></pre> <p>3. Shutdown the removed node:</p> <pre><code># On the removed node\npg_ctl stop -D $PGDATA\n</code></pre> <p>4. Verify removal:</p> <pre><code>-- On any remaining node\nSELECT * FROM pgraft_get_nodes();\n-- Node 4 should not appear\n</code></pre>"},{"location":"user-guide/cluster-operations/#important-notes_1","title":"Important Notes","text":"<p>Quorum Impact</p> <p>Removing nodes reduces fault tolerance. A 5-node cluster tolerates 2 failures, but after removing 2 nodes, the 3-node cluster only tolerates 1 failure.</p>"},{"location":"user-guide/cluster-operations/#leader-election","title":"Leader Election","text":""},{"location":"user-guide/cluster-operations/#understanding-elections","title":"Understanding Elections","text":"<p>Elections occur when:</p> <ul> <li>Cluster starts (initial election)</li> <li>Current leader fails</li> <li>Network partition isolates leader</li> <li>Leader explicitly steps down (future feature)</li> </ul>"},{"location":"user-guide/cluster-operations/#monitoring-elections","title":"Monitoring Elections","text":"<pre><code>-- Check current term (increases on each election)\nSELECT pgraft_get_term();\n\n-- Check who is leader\nSELECT pgraft_get_leader();\n\n-- Check if this node is leader\nSELECT pgraft_is_leader();\n</code></pre>"},{"location":"user-guide/cluster-operations/#election-timeline","title":"Election Timeline","text":"<p>Typical election after leader failure:</p> <pre><code>T+0s:   Leader fails\nT+1s:   Followers notice missing heartbeats\nT+1.5s: Election timeout triggers\nT+2s:   New leader elected\nT+2.5s: New leader sends first heartbeat\n</code></pre>"},{"location":"user-guide/cluster-operations/#troubleshooting-elections","title":"Troubleshooting Elections","text":"<p>Problem: No leader elected</p> <pre><code>-- Check worker status on all nodes\nSELECT pgraft_get_worker_state();\n\n-- Check network connectivity\n-- Ensure majority of nodes can communicate\n</code></pre> <p>Problem: Frequent elections</p> <pre><code>-- Check term (if increasing rapidly)\nSELECT pgraft_get_term();\n\n-- Possible causes:\n-- 1. Network instability\n-- 2. Election timeout too low\n-- 3. System overload\n</code></pre>"},{"location":"user-guide/cluster-operations/#configuration-changes","title":"Configuration Changes","text":""},{"location":"user-guide/cluster-operations/#updating-guc-parameters","title":"Updating GUC Parameters","text":"<p>Most pgraft parameters require a PostgreSQL restart:</p> <pre><code># Edit postgresql.conf\nvim $PGDATA/postgresql.conf\n\n# Change parameters (e.g., election timeout)\npgraft.election_timeout = 2000\n\n# Restart PostgreSQL\npg_ctl restart -D $PGDATA\n</code></pre>"},{"location":"user-guide/cluster-operations/#dynamic-parameters","title":"Dynamic Parameters","text":"<p>Some parameters can be changed without restart (if supported):</p> <pre><code># Reload configuration\npg_ctl reload -D $PGDATA\n</code></pre> <p>Restart Required</p> <p>Currently, most pgraft parameters require a full restart because the extension is loaded via <code>shared_preload_libraries</code>.</p>"},{"location":"user-guide/cluster-operations/#cluster-maintenance","title":"Cluster Maintenance","text":""},{"location":"user-guide/cluster-operations/#planned-downtime","title":"Planned Downtime","text":"<p>For maintenance requiring node restarts:</p> <p>1. Start with followers:</p> <pre><code># Identify followers\npsql -c \"SELECT node_id, pgraft_is_leader() FROM pgraft_get_nodes();\"\n\n# Restart followers one at a time\n# Wait for each to rejoin before restarting next\n</code></pre> <p>2. Finally restart leader:</p> <pre><code># Last, restart the leader\n# A new leader will be elected automatically\npg_ctl restart -D $PGDATA\n\n# Verify new leader elected\npsql -c \"SELECT pgraft_get_leader();\"\n</code></pre>"},{"location":"user-guide/cluster-operations/#backup-and-restore","title":"Backup and Restore","text":"<p>Backup:</p> <pre><code># 1. Backup PostgreSQL data\npg_basebackup -D /backup/pgdata\n\n# 2. Backup pgraft state\ntar -czf /backup/pgraft.tar.gz $PGRAFT_DATA_DIR\n\n# 3. Backup configuration\ncp $PGDATA/postgresql.conf /backup/\n</code></pre> <p>Restore:</p> <pre><code># 1. Stop PostgreSQL\npg_ctl stop -D $PGDATA\n\n# 2. Restore PostgreSQL data\nrm -rf $PGDATA\ntar -xzf /backup/pgdata.tar.gz -C $PGDATA\n\n# 3. Restore pgraft state\nrm -rf $PGRAFT_DATA_DIR\ntar -xzf /backup/pgraft.tar.gz -C /\n\n# 4. Restore configuration\ncp /backup/postgresql.conf $PGDATA/\n\n# 5. Start PostgreSQL\npg_ctl start -D $PGDATA\n</code></pre>"},{"location":"user-guide/cluster-operations/#cluster-expansion","title":"Cluster Expansion","text":""},{"location":"user-guide/cluster-operations/#growing-from-3-to-5-nodes","title":"Growing from 3 to 5 nodes","text":"<p>Current: 3 nodes (tolerates 1 failure) Target: 5 nodes (tolerates 2 failures)</p> <p>Steps:</p> <pre><code># 1. Prepare nodes 4 and 5\n# Configure and start them (see \"Adding Nodes\" above)\n\n# 2. From leader, add node 4\npsql -c \"SELECT pgraft_add_node(4, '192.168.1.14', 7004);\"\n\n# 3. Wait for node 4 to sync\nsleep 5\n\n# 4. Add node 5\npsql -c \"SELECT pgraft_add_node(5, '192.168.1.15', 7005);\"\n\n# 5. Verify all 5 nodes\npsql -c \"SELECT * FROM pgraft_get_nodes();\"\n</code></pre>"},{"location":"user-guide/cluster-operations/#cluster-reduction","title":"Cluster Reduction","text":""},{"location":"user-guide/cluster-operations/#shrinking-from-5-to-3-nodes","title":"Shrinking from 5 to 3 nodes","text":"<p>Current: 5 nodes (tolerates 2 failures) Target: 3 nodes (tolerates 1 failure)</p> <p>Steps:</p> <pre><code># 1. From leader, remove node 5\npsql -c \"SELECT pgraft_remove_node(5);\"\n\n# 2. Shutdown node 5\nssh node5 \"pg_ctl stop -D $PGDATA\"\n\n# 3. Remove node 4\npsql -c \"SELECT pgraft_remove_node(4);\"\n\n# 4. Shutdown node 4\nssh node4 \"pg_ctl stop -D $PGDATA\"\n\n# 5. Verify 3 nodes remain\npsql -c \"SELECT * FROM pgraft_get_nodes();\"\n</code></pre>"},{"location":"user-guide/cluster-operations/#log-management","title":"Log Management","text":""},{"location":"user-guide/cluster-operations/#log-compaction","title":"Log Compaction","text":"<p>pgraft automatically compacts logs based on configuration:</p> <pre><code>pgraft.snapshot_interval = 10000      # Create snapshot every 10k entries\npgraft.max_log_entries = 1000         # Compact when exceeds threshold\n</code></pre>"},{"location":"user-guide/cluster-operations/#manual-snapshot","title":"Manual Snapshot","text":"<p>Currently automatic only. Future versions may support manual snapshots.</p>"},{"location":"user-guide/cluster-operations/#viewing-log-statistics","title":"Viewing Log Statistics","text":"<pre><code>SELECT * FROM pgraft_log_get_stats();\n</code></pre> <p>Output: <pre><code> log_size | last_index | commit_index | last_applied \n----------+------------+--------------+--------------\n     5432 |       5432 |         5432 |         5432\n</code></pre></p>"},{"location":"user-guide/cluster-operations/#monitoring-during-operations","title":"Monitoring During Operations","text":""},{"location":"user-guide/cluster-operations/#during-node-addition","title":"During Node Addition","text":"<pre><code>-- Monitor replication to new node\nSELECT * FROM pgraft_log_get_replication_status();\n\n-- Check if new node caught up\nSELECT * FROM pgraft_log_get_stats();\n</code></pre>"},{"location":"user-guide/cluster-operations/#during-maintenance","title":"During Maintenance","text":"<pre><code>-- Monitor cluster health\nSELECT \n    pgraft_get_leader() as leader,\n    pgraft_get_term() as term,\n    COUNT(*) as num_nodes\nFROM pgraft_get_nodes();\n</code></pre>"},{"location":"user-guide/cluster-operations/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/cluster-operations/#adding-nodes_1","title":"Adding Nodes","text":"<ol> <li>Add one node at a time</li> <li>Wait for node to sync before adding next</li> <li>Verify node appears on all members</li> <li>Monitor replication status</li> </ol>"},{"location":"user-guide/cluster-operations/#removing-nodes_1","title":"Removing Nodes","text":"<ol> <li>Ensure cluster will still have quorum after removal</li> <li>Remove from cluster first, then shutdown</li> <li>Verify removal propagated to all nodes</li> <li>Update external documentation/configs</li> </ol>"},{"location":"user-guide/cluster-operations/#during-maintenance_1","title":"During Maintenance","text":"<ol> <li>Start with followers, end with leader</li> <li>Wait for each node to rejoin before proceeding</li> <li>Monitor term changes (should be minimal)</li> <li>Keep majority online at all times</li> </ol>"},{"location":"user-guide/cluster-operations/#emergency-procedures","title":"Emergency Procedures","text":""},{"location":"user-guide/cluster-operations/#lost-quorum","title":"Lost Quorum","text":"<p>If majority of nodes fail:</p> <ol> <li>Do not panic - remaining nodes are read-only</li> <li>Restore failed nodes or add new nodes</li> <li>Once quorum restored, leader will be elected</li> <li>Cluster resumes normal operations</li> </ol>"},{"location":"user-guide/cluster-operations/#split-brain-verification","title":"Split Brain Verification","text":"<p>pgraft prevents split-brain, but you can verify:</p> <pre><code># During partition, check both sides\n# Only one side will have a leader\npsql -h partition1_node -c \"SELECT pgraft_is_leader();\"\npsql -h partition2_node -c \"SELECT pgraft_is_leader();\"\n\n# Only one will return 't'\n</code></pre>"},{"location":"user-guide/cluster-operations/#complete-cluster-failure","title":"Complete Cluster Failure","text":"<p>If all nodes crash:</p> <ol> <li>Restore nodes from backup</li> <li>Start all nodes</li> <li>Wait for election (10 seconds)</li> <li>Verify leader elected</li> </ol> <pre><code>SELECT pgraft_get_leader();\n</code></pre>"},{"location":"user-guide/cluster-operations/#summary","title":"Summary","text":"<p>Key operations:</p> <ul> <li>Add node: <code>pgraft_add_node()</code> on leader</li> <li>Remove node: <code>pgraft_remove_node()</code> on leader</li> <li>Monitor: <code>pgraft_get_cluster_status()</code>, <code>pgraft_get_nodes()</code></li> <li>Verify leader: <code>pgraft_is_leader()</code>, <code>pgraft_get_leader()</code></li> </ul> <p>Remember: All configuration changes happen on the leader and automatically replicate to followers!</p>"},{"location":"user-guide/configuration/","title":"Configuration (pgElephant Suite)","text":"<p>This page describes all available configuration parameters for pgraft, part of the unified pgElephant high-availability suite. All configuration and monitoring is unified with the rest of the suite.</p>"},{"location":"user-guide/configuration/#postgresql-configuration","title":"PostgreSQL Configuration","text":"<p>All pgraft configuration parameters are set in <code>postgresql.conf</code>. The extension must be added to <code>shared_preload_libraries</code> and PostgreSQL must be restarted for changes to take effect.</p> <pre><code>shared_preload_libraries = 'pgraft'\n</code></pre>"},{"location":"user-guide/configuration/#core-cluster-configuration","title":"Core Cluster Configuration","text":"<p>These parameters define the basic cluster identity and network settings.</p> Parameter Type Default Description <code>pgraft.cluster_id</code> string \"pgraft-cluster\" Cluster identifier - must be same for all nodes <code>pgraft.node_id</code> int 1 Unique node ID (1-based) - must be unique per node <code>pgraft.address</code> string \"127.0.0.1\" Node listen address for Raft communication <code>pgraft.port</code> int 7001 Raft communication port (not PostgreSQL port) <code>pgraft.data_dir</code> string \"/tmp/pgraft/${node_id}\" Persistent storage directory"},{"location":"user-guide/configuration/#example","title":"Example","text":"<pre><code>pgraft.cluster_id = 'production-cluster'\npgraft.node_id = 1\npgraft.address = '127.0.0.1'\npgraft.port = 7001\npgraft.data_dir = '/var/lib/postgresql/pgraft'\n</code></pre> <p>Important</p> <ul> <li><code>cluster_id</code> must be identical on all nodes in the cluster</li> <li><code>node_id</code> must be unique for each node (1, 2, 3, ...)</li> <li><code>port</code> is for Raft protocol, not PostgreSQL connections</li> </ul>"},{"location":"user-guide/configuration/#consensus-settings","title":"Consensus Settings","text":"<p>These parameters control the Raft consensus algorithm behavior.</p> Parameter Type Default Description <code>pgraft.election_timeout</code> int 1000 Election timeout in milliseconds <code>pgraft.heartbeat_interval</code> int 100 Heartbeat interval in milliseconds <code>pgraft.snapshot_interval</code> int 10000 Snapshot frequency (entries) <code>pgraft.max_log_entries</code> int 1000 Log compaction threshold"},{"location":"user-guide/configuration/#example_1","title":"Example","text":"<pre><code>pgraft.election_timeout = 1000        # milliseconds\npgraft.heartbeat_interval = 100       # milliseconds\npgraft.snapshot_interval = 10000      # entries\npgraft.max_log_entries = 1000         # compaction threshold\n</code></pre>"},{"location":"user-guide/configuration/#tuning-guidelines","title":"Tuning Guidelines","text":"<p>Election Timeout</p> <ul> <li>Typical range: 500-5000ms</li> <li>Higher values: More stable but slower failover</li> <li>Lower values: Faster failover but more prone to spurious elections</li> <li>Should be at least 10x the heartbeat interval</li> </ul> <p>Heartbeat Interval</p> <ul> <li>Typical range: 50-200ms</li> <li>Determines how often leader sends heartbeats</li> <li>Lower values: Better detection of failures, more network traffic</li> <li>Higher values: Less network traffic, slower failure detection</li> </ul> <p>Snapshot Interval</p> <ul> <li>How many log entries before creating a snapshot</li> <li>Affects recovery time and disk usage</li> <li>Typical range: 1000-100000 entries</li> </ul> <p>Max Log Entries</p> <ul> <li>Threshold for log compaction</li> <li>Prevents unbounded log growth</li> <li>Should be larger than snapshot_interval</li> </ul>"},{"location":"user-guide/configuration/#performance-settings","title":"Performance Settings","text":"<p>These parameters control batching and compaction behavior.</p> Parameter Type Default Description <code>pgraft.batch_size</code> int 100 Entry batch size for replication <code>pgraft.max_batch_delay</code> int 10 Max batching delay in milliseconds <code>pgraft.compaction_threshold</code> int 10000 Compaction trigger threshold"},{"location":"user-guide/configuration/#example_2","title":"Example","text":"<pre><code>pgraft.batch_size = 100\npgraft.max_batch_delay = 10           # milliseconds\npgraft.compaction_threshold = 10000\n</code></pre>"},{"location":"user-guide/configuration/#security-monitoring","title":"Security &amp; Monitoring","text":"<p>Optional security and monitoring features.</p> Parameter Type Default Description <code>pgraft.auth_enabled</code> bool false Enable authentication between nodes <code>pgraft.tls_enabled</code> bool false Enable TLS for inter-node communication <code>pgraft.metrics_enabled</code> bool false Enable Prometheus metrics <code>pgraft.metrics_port</code> int 9100 Metrics server port"},{"location":"user-guide/configuration/#example_3","title":"Example","text":"<pre><code>pgraft.auth_enabled = false\npgraft.tls_enabled = false\npgraft.metrics_enabled = true\npgraft.metrics_port = 9100\n</code></pre> <p>Coming Soon</p> <p>Authentication and TLS features are planned for future releases.</p>"},{"location":"user-guide/configuration/#complete-configuration-example","title":"Complete Configuration Example","text":"<p>Here's a complete configuration for a production 3-node cluster:</p> Node 1Node 2Node 3 <pre><code># PostgreSQL settings\nport = 5432\nshared_preload_libraries = 'pgraft'\n\n# Core cluster configuration\npgraft.cluster_id = 'prod-cluster'\npgraft.node_id = 1\npgraft.address = '192.168.1.101'\npgraft.port = 7001\npgraft.data_dir = '/var/lib/postgresql/pgraft'\n\n# Consensus settings\npgraft.election_timeout = 1000\npgraft.heartbeat_interval = 100\npgraft.snapshot_interval = 10000\npgraft.max_log_entries = 1000\n\n# Performance settings\npgraft.batch_size = 100\npgraft.max_batch_delay = 10\npgraft.compaction_threshold = 10000\n\n# Monitoring\npgraft.metrics_enabled = true\npgraft.metrics_port = 9100\n</code></pre> <pre><code># PostgreSQL settings\nport = 5432\nshared_preload_libraries = 'pgraft'\n\n# Core cluster configuration\npgraft.cluster_id = 'prod-cluster'\npgraft.node_id = 2\npgraft.address = '192.168.1.102'\npgraft.port = 7002\npgraft.data_dir = '/var/lib/postgresql/pgraft'\n\n# Consensus settings (same as node 1)\npgraft.election_timeout = 1000\npgraft.heartbeat_interval = 100\npgraft.snapshot_interval = 10000\npgraft.max_log_entries = 1000\n\n# Performance settings (same as node 1)\npgraft.batch_size = 100\npgraft.max_batch_delay = 10\npgraft.compaction_threshold = 10000\n\n# Monitoring\npgraft.metrics_enabled = true\npgraft.metrics_port = 9100\n</code></pre> <pre><code># PostgreSQL settings\nport = 5432\nshared_preload_libraries = 'pgraft'\n\n# Core cluster configuration\npgraft.cluster_id = 'prod-cluster'\npgraft.node_id = 3\npgraft.address = '192.168.1.103'\npgraft.port = 7003\npgraft.data_dir = '/var/lib/postgresql/pgraft'\n\n# Consensus settings (same as node 1)\npgraft.election_timeout = 1000\npgraft.heartbeat_interval = 100\npgraft.snapshot_interval = 10000\npgraft.max_log_entries = 1000\n\n# Performance settings (same as node 1)\npgraft.batch_size = 100\npgraft.max_batch_delay = 10\npgraft.compaction_threshold = 10000\n\n# Monitoring\npgraft.metrics_enabled = true\npgraft.metrics_port = 9100\n</code></pre>"},{"location":"user-guide/configuration/#applying-configuration-changes","title":"Applying Configuration Changes","text":"<p>After modifying <code>postgresql.conf</code>:</p> <pre><code># Restart PostgreSQL\npg_ctl restart -D /path/to/data\n\n# Or reload (for parameters that support reload)\npg_ctl reload -D /path/to/data\n</code></pre> <p>Restart Required</p> <p>Most pgraft parameters require a PostgreSQL restart because the extension is loaded via <code>shared_preload_libraries</code>.</p>"},{"location":"user-guide/configuration/#verifying-configuration","title":"Verifying Configuration","text":"<p>After starting PostgreSQL, verify your configuration:</p> <pre><code>-- Check if pgraft is loaded\nSELECT * FROM pg_extension WHERE extname = 'pgraft';\n\n-- Get current cluster configuration\nSELECT * FROM pgraft_get_cluster_status();\n\n-- Check worker status\nSELECT pgraft_get_worker_state();\n</code></pre>"},{"location":"user-guide/sql-functions/","title":"SQL Functions, Tables &amp; Views Reference (pgraft)","text":"<p>This page documents all SQL functions, tables, and views available in pgraft, part of the pgElephant high-availability suite. All APIs are up to date with the latest release and reflect the current extension SQL.</p>"},{"location":"user-guide/sql-functions/#core-tables","title":"Core Tables","text":""},{"location":"user-guide/sql-functions/#pgraftkv","title":"<code>pgraft.kv</code>","text":"<p>Key-value store table (etcd-compatible, Raft-replicated)</p> Column Type Description key text Primary key value text Value for the key version bigint Version number created_at timestamptz Creation timestamp updated_at timestamptz Last update timestamp"},{"location":"user-guide/sql-functions/#pgraftapplied_entries","title":"<code>pgraft.applied_entries</code>","text":"<p>Tracks which Raft log entries have been applied to PostgreSQL.</p> Column Type Description raft_index bigint Raft log index (PK) raft_term bigint Raft term entry_type integer Entry type applied_at timestamptz When applied"},{"location":"user-guide/sql-functions/#pgraftlog_index_mapping","title":"<code>pgraft.log_index_mapping</code>","text":"<p>Maps Raft log index to PostgreSQL operation for debugging/recovery.</p> Column Type Description raft_index bigint Raft log index (PK) operation_type text Operation type target_table text Target table operation_data jsonb Operation data applied_at timestamptz When applied"},{"location":"user-guide/sql-functions/#cluster-management-functions","title":"Cluster Management Functions","text":""},{"location":"user-guide/sql-functions/#pgraft_init","title":"<code>pgraft_init()</code>","text":"<p>Initialize pgraft on the current node.</p> <p>Returns: <code>boolean</code> \u2014 <code>true</code> if successful.</p>"},{"location":"user-guide/sql-functions/#pgraft_add_nodenode_id-int-address-text-port-int","title":"<code>pgraft_add_node(node_id int, address text, port int)</code>","text":"<p>Add a node to the cluster (leader only).</p>"},{"location":"user-guide/sql-functions/#pgraft_remove_nodenode_id-int","title":"<code>pgraft_remove_node(node_id int)</code>","text":"<p>Remove a node from the cluster.</p>"},{"location":"user-guide/sql-functions/#pgraft_get_cluster_status","title":"<code>pgraft_get_cluster_status()</code>","text":"<p>Returns a table with cluster status (node_id, current_term, leader_id, state, num_nodes, etc).</p>"},{"location":"user-guide/sql-functions/#pgraft_get_nodes","title":"<code>pgraft_get_nodes()</code>","text":"<p>Returns a table of all cluster nodes (node_id, address, port, is_leader).</p>"},{"location":"user-guide/sql-functions/#pgraft_is_leader","title":"<code>pgraft_is_leader()</code>","text":"<p>Returns <code>boolean</code> \u2014 true if current node is leader.</p>"},{"location":"user-guide/sql-functions/#pgraft_get_worker_state","title":"<code>pgraft_get_worker_state()</code>","text":"<p>Returns <code>text</code> \u2014 background worker state (e.g., \"RUNNING\").</p>"},{"location":"user-guide/sql-functions/#pgraft_get_version","title":"<code>pgraft_get_version()</code>","text":"<p>Returns <code>text</code> \u2014 extension version.</p>"},{"location":"user-guide/sql-functions/#pgraft_set_debugenabled-boolean","title":"<code>pgraft_set_debug(enabled boolean)</code>","text":"<p>Enable or disable debug logging.</p>"},{"location":"user-guide/sql-functions/#pgraft_test","title":"<code>pgraft_test()</code>","text":"<p>Test function for verifying pgraft is working.</p>"},{"location":"user-guide/sql-functions/#log-replication-functions","title":"Log Replication Functions","text":""},{"location":"user-guide/sql-functions/#pgraft_log_appendterm-bigint-data-text","title":"<code>pgraft_log_append(term bigint, data text)</code>","text":"<p>Append a log entry.</p>"},{"location":"user-guide/sql-functions/#pgraft_log_commitindex-bigint","title":"<code>pgraft_log_commit(index bigint)</code>","text":"<p>Commit a log entry.</p>"},{"location":"user-guide/sql-functions/#pgraft_log_applyindex-bigint","title":"<code>pgraft_log_apply(index bigint)</code>","text":"<p>Apply a log entry to the state machine.</p>"},{"location":"user-guide/sql-functions/#pgraft_log_get_entryindex-bigint","title":"<code>pgraft_log_get_entry(index bigint)</code>","text":"<p>Get a specific log entry (returns text).</p>"},{"location":"user-guide/sql-functions/#pgraft_log_get_stats","title":"<code>pgraft_log_get_stats()</code>","text":"<p>Returns table with log statistics (log_size, last_index, commit_index, last_applied, ...).</p>"},{"location":"user-guide/sql-functions/#pgraft_log_get_replication_status","title":"<code>pgraft_log_get_replication_status()</code>","text":"<p>Returns table with replication status for each follower.</p>"},{"location":"user-guide/sql-functions/#pgraft_log_sync_with_leader","title":"<code>pgraft_log_sync_with_leader()</code>","text":"<p>Synchronize local log with the leader.</p>"},{"location":"user-guide/sql-functions/#pgraft_replicate_entryentry_data-text","title":"<code>pgraft_replicate_entry(entry_data text)</code>","text":"<p>Replicate an entry through Raft consensus.</p>"},{"location":"user-guide/sql-functions/#keyvalue-store-functions-etcd-compatible","title":"Key/Value Store Functions (etcd-compatible)","text":""},{"location":"user-guide/sql-functions/#pgraft_kv_putkey-text-value-text","title":"<code>pgraft_kv_put(key text, value text)</code>","text":"<p>Store a key/value pair. Returns <code>boolean</code>.</p>"},{"location":"user-guide/sql-functions/#pgraft_kv_getkey-text","title":"<code>pgraft_kv_get(key text)</code>","text":"<p>Retrieve value for a key. Returns <code>text</code>.</p>"},{"location":"user-guide/sql-functions/#pgraft_kv_deletekey-text","title":"<code>pgraft_kv_delete(key text)</code>","text":"<p>Delete a key. Returns <code>boolean</code>.</p>"},{"location":"user-guide/sql-functions/#pgraft_kv_existskey-text","title":"<code>pgraft_kv_exists(key text)</code>","text":"<p>Check if a key exists. Returns <code>boolean</code>.</p>"},{"location":"user-guide/sql-functions/#pgraft_kv_list_keys","title":"<code>pgraft_kv_list_keys()</code>","text":"<p>List all keys as a JSON array. Returns <code>text</code>.</p>"},{"location":"user-guide/sql-functions/#pgraft_kv_get_stats","title":"<code>pgraft_kv_get_stats()</code>","text":"<p>Returns table with key/value store statistics (num_entries, total_operations, puts, gets, deletes, ...).</p>"},{"location":"user-guide/sql-functions/#pgraft_kv_compact","title":"<code>pgraft_kv_compact()</code>","text":"<p>Remove deleted entries and optimize storage. Returns <code>boolean</code>.</p>"},{"location":"user-guide/sql-functions/#pgraft_kv_reset","title":"<code>pgraft_kv_reset()</code>","text":"<p>Clear all key/value data (use with caution!). Returns <code>boolean</code>.</p>"},{"location":"user-guide/sql-functions/#monitoring-debugging-functions","title":"Monitoring &amp; Debugging Functions","text":""},{"location":"user-guide/sql-functions/#pgraft_get_queue_status","title":"<code>pgraft_get_queue_status()</code>","text":"<p>Returns table with command queue status.</p>"},{"location":"user-guide/sql-functions/#etcd-compatible-views","title":"etcd-Compatible Views","text":"<p>The following views provide etcd-style cluster and key-value status for compatibility with etcd tools:</p> <ul> <li><code>pgraft.member_list</code> \u2014 etcdctl member list format (shows all cluster members, peer/client URLs, leader/follower status)</li> <li><code>pgraft.endpoint_status</code> \u2014 etcdctl endpoint status format (endpoint, isLeader, raftTerm, raftIndex, etc.)</li> <li><code>pgraft.endpoint_health</code> \u2014 etcdctl endpoint health format (endpoint, health, took)</li> <li><code>pgraft.cluster_health</code> \u2014 etcdctl cluster-health format (member, isLeader, isLearner, health)</li> <li><code>pgraft.cluster_info</code> \u2014 etcdctl cluster info format (clusterID, memberCount, leader, raftTerm, raftIndex, raftAppliedIndex)</li> <li><code>pgraft.kv_status</code> \u2014 etcdctl key-value status (key, value, version, create_revision, mod_revision)</li> <li><code>pgraft.endpoint_hashkv</code> \u2014 etcdctl endpoint hashkv format (endpoint, hash, hash_revision)</li> <li><code>pgraft.watch_status</code> \u2014 etcdctl watch status (watcher_id, is_active, watch_count, watch_pending)</li> <li><code>pgraft.member_details</code> \u2014 etcdctl member details (ID, Name, PeerURLs, ClientURLs, IsLeader, IsLearner)</li> <li><code>pgraft.auth_status</code> \u2014 etcdctl auth status (enabled, revision)</li> <li><code>pgraft.alarm_list</code> \u2014 etcdctl alarm list (alarm, memberID)</li> <li> <p><code>pgraft.snapshot_status</code> \u2014 etcdctl snapshot status (hash, revision, total_key, total_size, version)</p> </li> <li> <p><code>pgraft.member_list</code> \u2014 etcdctl member list format</p> </li> <li><code>pgraft.endpoint_status</code> \u2014 etcdctl endpoint status format</li> <li><code>pgraft.endpoint_health</code> \u2014 etcdctl endpoint health format</li> <li><code>pgraft.cluster_health</code> \u2014 etcdctl cluster-health format</li> <li><code>pgraft.cluster_info</code> \u2014 etcdctl cluster info format</li> <li><code>pgraft.kv_status</code> \u2014 etcdctl key-value status</li> <li><code>pgraft.endpoint_hashkv</code> \u2014 etcdctl endpoint hashkv format</li> <li><code>pgraft.watch_status</code> \u2014 etcdctl watch status</li> <li><code>pgraft.member_details</code> \u2014 etcdctl member details</li> <li><code>pgraft.auth_status</code> \u2014 etcdctl auth status</li> <li><code>pgraft.alarm_list</code> \u2014 etcdctl alarm list</li> <li><code>pgraft.snapshot_status</code> \u2014 etcdctl snapshot status</li> </ul> <p>Example: <pre><code>SELECT * FROM pgraft.member_list;\nSELECT * FROM pgraft.endpoint_status;\nSELECT * FROM pgraft.kv_status;\n</code></pre></p>"},{"location":"user-guide/sql-functions/#internal-advanced-views","title":"Internal &amp; Advanced Views","text":"<ul> <li><code>pgraft_cluster_state</code> \u2014 Core cluster state (reads from shared memory; combines cluster and worker info)</li> <li><code>pgraft_worker_status</code> \u2014 Background worker status (worker_state, is_running)</li> <li><code>pgraft_cluster_overview</code> \u2014 Cluster overview (worker + node status, leader, term, state, etc.)</li> <li><code>pgraft_nodes</code> \u2014 Node information (with cluster state)</li> <li><code>pgraft_log_status</code> \u2014 Log replication status (simplified, for quick checks)</li> <li><code>pgraft_kv_status</code> \u2014 Key/value store status (num_entries, active_entries, deleted_entries, total_operations, puts, gets, deletes, last_applied_index, status)</li> </ul>"},{"location":"user-guide/sql-functions/#usage-examples","title":"Usage Examples","text":""},{"location":"user-guide/sql-functions/#health-check","title":"Health Check","text":"<pre><code>SELECT pgraft_is_leader(), pgraft_get_term(), pgraft_get_leader(), pgraft_get_worker_state();\nSELECT * FROM pgraft_get_cluster_status();\nSELECT * FROM pgraft_get_nodes();\n</code></pre>"},{"location":"user-guide/sql-functions/#keyvalue-store","title":"Key/Value Store","text":"<pre><code>SELECT pgraft_kv_put('foo', 'bar');\nSELECT pgraft_kv_get('foo');\nSELECT pgraft_kv_delete('foo');\nSELECT * FROM pgraft_kv_status;\n</code></pre>"},{"location":"user-guide/sql-functions/#etcd-compatible-views_1","title":"etcd-Compatible Views","text":"<pre><code>SELECT * FROM pgraft.member_list;\nSELECT * FROM pgraft.endpoint_status;\nSELECT * FROM pgraft.cluster_health;\n</code></pre>"},{"location":"user-guide/sql-functions/#add-nodes-leader-only","title":"Add Nodes (Leader Only)","text":"<pre><code>DO $$\nBEGIN\n    IF NOT pgraft_is_leader() THEN\n        RAISE EXCEPTION 'Must run on leader node';\n    END IF;\n    PERFORM pgraft_add_node(2, '127.0.0.1', 7002);\n    PERFORM pgraft_add_node(3, '127.0.0.1', 7003);\nEND $$;\n</code></pre>"},{"location":"user-guide/tutorial/","title":"pgraft Tutorial: Complete Setup and Usage Guide (pgElephant Suite)","text":"<p>This tutorial will walk you through setting up a complete pgraft cluster from scratch, including installation, configuration, and advanced usage scenarios. All steps, scripts, and best practices are up to date and consistent with the unified pgElephant suite.</p>"},{"location":"user-guide/tutorial/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Prerequisites</li> <li>Installation</li> <li>Basic Cluster Setup</li> <li>Advanced Configuration</li> <li>Cluster Operations</li> <li>Monitoring and Maintenance</li> <li>Troubleshooting</li> <li>Best Practices</li> </ol>"},{"location":"user-guide/tutorial/#prerequisites","title":"Prerequisites","text":""},{"location":"user-guide/tutorial/#system-requirements","title":"System Requirements","text":"<ul> <li>Operating System: Linux, macOS, or Windows</li> <li>PostgreSQL: Version 17 or higher</li> <li>Go: Version 1.21 or higher</li> <li>Memory: Minimum 2GB RAM per node</li> <li>Disk: Minimum 10GB free space per node</li> <li>Network: Reliable network connectivity between nodes</li> </ul>"},{"location":"user-guide/tutorial/#software-dependencies","title":"Software Dependencies","text":"<pre><code># Ubuntu/Debian\nsudo apt-get update\nsudo apt-get install postgresql-17 postgresql-server-dev-17 golang-go build-essential\n\n# CentOS/RHEL\nsudo yum install postgresql17 postgresql17-devel golang gcc make\n\n# macOS\nbrew install postgresql@17 go\n</code></pre>"},{"location":"user-guide/tutorial/#installation","title":"Installation","text":""},{"location":"user-guide/tutorial/#step-1-download-and-build","title":"Step 1: Download and Build","text":"<pre><code># Clone the repository\ngit clone https://github.com/pgelephant/pgraft.git\ncd pgraft\n\n# Build the extension\nmake clean\nmake\nsudo make install\n\n# Verify installation\nmake installcheck\n</code></pre>"},{"location":"user-guide/tutorial/#step-2-verify-installation","title":"Step 2: Verify Installation","text":"<pre><code># Check if extension files are installed\nls -la /usr/local/pgsql.17/lib/pgraft*\nls -la /usr/local/pgsql.17/share/extension/pgraft*\n\n# Expected output:\n# pgraft.dylib (or .so on Linux)\n# pgraft.control\n# pgraft--1.0.sql\n</code></pre>"},{"location":"user-guide/tutorial/#basic-cluster-setup","title":"Basic Cluster Setup","text":""},{"location":"user-guide/tutorial/#step-1-prepare-postgresql-instances","title":"Step 1: Prepare PostgreSQL Instances","text":"<p>Create three PostgreSQL instances for our cluster:</p> <pre><code># Create data directories\nmkdir -p /data/node1 /data/node2 /data/node3\n\n# Initialize databases\n/usr/local/pgsql.17/bin/initdb -D /data/node1\n/usr/local/pgsql.17/bin/initdb -D /data/node2\n/usr/local/pgsql.17/bin/initdb -D /data/node3\n</code></pre>"},{"location":"user-guide/tutorial/#step-2-configure-postgresql","title":"Step 2: Configure PostgreSQL","text":"<p>Node 1 Configuration (<code>/data/node1/postgresql.conf</code>):</p> <pre><code># Network settings\nlisten_addresses = '*'\nport = 5433\n\n# Load pgraft extension\nshared_preload_libraries = 'pgraft'\n\n# pgraft configuration\npgraft.node_id = 1\npgraft.address = '127.0.0.1'\npgraft.port = 5433\npgraft.cluster_name = 'tutorial_cluster'\n\n# Logging for debugging\nlog_min_messages = info\nlog_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '\nlog_checkpoints = on\nlog_connections = on\nlog_disconnections = on\nlog_lock_waits = on\n</code></pre> <p>Node 2 Configuration (<code>/data/node2/postgresql.conf</code>):</p> <pre><code># Network settings\nlisten_addresses = '*'\nport = 5434\n\n# Load pgraft extension\nshared_preload_libraries = 'pgraft'\n\n# pgraft configuration\npgraft.node_id = 2\npgraft.address = '127.0.0.1'\npgraft.port = 5434\npgraft.cluster_name = 'tutorial_cluster'\n\n# Logging for debugging\nlog_min_messages = info\nlog_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '\nlog_checkpoints = on\nlog_connections = on\nlog_disconnections = on\nlog_lock_waits = on\n</code></pre> <p>Node 3 Configuration (<code>/data/node3/postgresql.conf</code>):</p> <pre><code># Network settings\nlisten_addresses = '*'\nport = 5435\n\n# Load pgraft extension\nshared_preload_libraries = 'pgraft'\n\n# pgraft configuration\npgraft.node_id = 3\npgraft.address = '127.0.0.1'\npgraft.port = 5435\npgraft.cluster_name = 'tutorial_cluster'\n\n# Logging for debugging\nlog_min_messages = info\nlog_line_prefix = '%t [%p]: [%l-1] user=%u,db=%d,app=%a,client=%h '\nlog_checkpoints = on\nlog_connections = on\nlog_disconnections = on\nlog_lock_waits = on\n</code></pre>"},{"location":"user-guide/tutorial/#step-3-start-postgresql-instances","title":"Step 3: Start PostgreSQL Instances","text":"<pre><code># Start all three nodes\n/usr/local/pgsql.17/bin/pg_ctl -D /data/node1 -l /data/node1/logfile start\n/usr/local/pgsql.17/bin/pg_ctl -D /data/node2 -l /data/node2/logfile start\n/usr/local/pgsql.17/bin/pg_ctl -D /data/node3 -l /data/node3/logfile start\n\n# Verify they're running\nps aux | grep postgres\n</code></pre>"},{"location":"user-guide/tutorial/#step-4-initialize-the-cluster","title":"Step 4: Initialize the Cluster","text":"<p>Connect to each node and initialize pgraft:</p> <pre><code># Connect to Node 1\npsql -h 127.0.0.1 -p 5433 -U postgres\n\n# Create the extension\nCREATE EXTENSION IF NOT EXISTS pgraft;\n\n# Initialize the first node\nSELECT pgraft_init();\n\n# Check the status\nSELECT pgraft_get_worker_state();\nSELECT * FROM pgraft_get_cluster_status();\n\n# Exit\n\\q\n</code></pre> <pre><code># Connect to Node 2\npsql -h 127.0.0.1 -p 5434 -U postgres\n\n# Create the extension\nCREATE EXTENSION IF NOT EXISTS pgraft;\n\n# Initialize the node\nSELECT pgraft_init();\n\n# Exit\n\\q\n</code></pre> <pre><code># Connect to Node 3\npsql -h 127.0.0.1 -p 5435 -U postgres\n\n# Create the extension\nCREATE EXTENSION IF NOT EXISTS pgraft;\n\n# Initialize the node\nSELECT pgraft_init();\n\n# Exit\n\\q\n</code></pre>"},{"location":"user-guide/tutorial/#step-5-form-the-cluster","title":"Step 5: Form the Cluster","text":"<p>Connect to the first node and add the other nodes:</p> <pre><code># Connect to Node 1 (should be the initial leader)\npsql -h 127.0.0.1 -p 5433 -U postgres\n\n# Add Node 2 to the cluster\nSELECT pgraft_add_node(2, '127.0.0.1', 5434);\n\n# Add Node 3 to the cluster\nSELECT pgraft_add_node(3, '127.0.0.1', 5435);\n\n# Verify cluster formation\nSELECT * FROM pgraft_get_nodes();\nSELECT * FROM pgraft_get_cluster_status();\nSELECT pgraft_is_leader();\n\n# Exit\n\\q\n</code></pre>"},{"location":"user-guide/tutorial/#step-6-verify-cluster-health","title":"Step 6: Verify Cluster Health","text":"<p>Check each node to ensure they're properly connected:</p> <pre><code># Check Node 1\npsql -h 127.0.0.1 -p 5433 -U postgres -c \"SELECT pgraft_is_leader(), pgraft_get_term(), pgraft_get_leader();\"\n\n# Check Node 2\npsql -h 127.0.0.1 -p 5434 -U postgres -c \"SELECT pgraft_is_leader(), pgraft_get_term(), pgraft_get_leader();\"\n\n# Check Node 3\npsql -h 127.0.0.1 -p 5435 -U postgres -c \"SELECT pgraft_is_leader(), pgraft_get_term(), pgraft_get_leader();\"\n</code></pre> <p>Expected output should show: - One node as leader (<code>pgraft_is_leader()</code> returns <code>true</code>) - Same term number on all nodes - Same leader ID on all nodes</p>"},{"location":"user-guide/tutorial/#advanced-configuration","title":"Advanced Configuration","text":""},{"location":"user-guide/tutorial/#performance-tuning","title":"Performance Tuning","text":"<p>Optimize for High Throughput:</p> <pre><code># In postgresql.conf\npgraft.heartbeat_interval = 500  # Faster heartbeats\npgraft.election_timeout = 3000   # Faster elections\npgraft.worker_interval = 100     # More frequent processing\n\n# PostgreSQL settings\nshared_buffers = 256MB\neffective_cache_size = 1GB\nwork_mem = 4MB\nmaintenance_work_mem = 64MB\n</code></pre> <p>Optimize for Low Latency:</p> <pre><code># In postgresql.conf\npgraft.heartbeat_interval = 1000  # Standard heartbeats\npgraft.election_timeout = 5000    # Standard elections\npgraft.worker_interval = 50       # Very frequent processing\n\n# PostgreSQL settings\nsynchronous_commit = on\nfsync = on\nwal_sync_method = fdatasync\n</code></pre>"},{"location":"user-guide/tutorial/#security-configuration","title":"Security Configuration","text":"<p>Enable SSL/TLS:</p> <pre><code># In postgresql.conf\nssl = on\nssl_cert_file = 'server.crt'\nssl_key_file = 'server.key'\nssl_ca_file = 'ca.crt'\n\n# pgraft will automatically use SSL for inter-node communication\n</code></pre> <p>Network Security:</p> <pre><code># Configure firewall (example for iptables)\nsudo iptables -A INPUT -p tcp --dport 5433 -s 127.0.0.1 -j ACCEPT\nsudo iptables -A INPUT -p tcp --dport 5434 -s 127.0.0.1 -j ACCEPT\nsudo iptables -A INPUT -p tcp --dport 5435 -s 127.0.0.1 -j ACCEPT\nsudo iptables -A INPUT -p tcp --dport 5433 -j DROP\nsudo iptables -A INPUT -p tcp --dport 5434 -j DROP\nsudo iptables -A INPUT -p tcp --dport 5435 -j DROP\n</code></pre>"},{"location":"user-guide/tutorial/#cluster-operations","title":"Cluster Operations","text":""},{"location":"user-guide/tutorial/#adding-a-new-node","title":"Adding a New Node","text":"<ol> <li> <p>Prepare the new node: <pre><code># Create data directory\nmkdir -p /data/node4\n\n# Initialize database\n/usr/local/pgsql.17/bin/initdb -D /data/node4\n\n# Configure postgresql.conf\n# (similar to other nodes but with node_id=4, port=5436)\n</code></pre></p> </li> <li> <p>Start the new node: <pre><code>/usr/local/pgsql.17/bin/pg_ctl -D /data/node4 -l /data/node4/logfile start\n</code></pre></p> </li> <li> <p>Add to cluster: <pre><code>-- Connect to any existing node\npsql -h 127.0.0.1 -p 5433 -U postgres\n\n-- Add the new node\nSELECT pgraft_add_node(4, '127.0.0.1', 5436);\n\n-- Verify\nSELECT * FROM pgraft_get_nodes();\n</code></pre></p> </li> </ol>"},{"location":"user-guide/tutorial/#removing-a-node","title":"Removing a Node","text":"<pre><code>-- Connect to any node\npsql -h 127.0.0.1 -p 5433 -U postgres\n\n-- Remove the node\nSELECT pgraft_remove_node(4);\n\n-- Verify\nSELECT * FROM pgraft_get_nodes();\n</code></pre>"},{"location":"user-guide/tutorial/#leader-election-testing","title":"Leader Election Testing","text":"<p>Test automatic leader election by stopping the current leader:</p> <pre><code># Find the current leader\npsql -h 127.0.0.1 -p 5433 -U postgres -c \"SELECT pgraft_is_leader(), pgraft_get_leader();\"\n\n# Stop the leader (replace with actual port)\n/usr/local/pgsql.17/bin/pg_ctl -D /data/node1 stop\n\n# Wait a few seconds, then check remaining nodes\npsql -h 127.0.0.1 -p 5434 -U postgres -c \"SELECT pgraft_is_leader(), pgraft_get_term();\"\npsql -h 127.0.0.1 -p 5435 -U postgres -c \"SELECT pgraft_is_leader(), pgraft_get_term();\"\n\n# One should now be the leader with a higher term\n\n# Restart the stopped node\n/usr/local/pgsql.17/bin/pg_ctl -D /data/node1 -l /data/node1/logfile start\n\n# It will automatically rejoin as a follower\n</code></pre>"},{"location":"user-guide/tutorial/#log-replication-testing","title":"Log Replication Testing","text":"<p>Test log replication by performing operations:</p> <pre><code>-- Connect to the leader\npsql -h 127.0.0.1 -p 5433 -U postgres\n\n-- Create a test table\nCREATE TABLE test_data (id SERIAL PRIMARY KEY, data TEXT, created_at TIMESTAMP DEFAULT NOW());\n\n-- Insert some data\nINSERT INTO test_data (data) VALUES ('Test entry 1'), ('Test entry 2'), ('Test entry 3');\n\n-- Check that data is replicated to followers\n-- (Connect to followers and verify the table exists)\n</code></pre>"},{"location":"user-guide/tutorial/#monitoring-and-maintenance","title":"Monitoring and Maintenance","text":""},{"location":"user-guide/tutorial/#health-monitoring-script","title":"Health Monitoring Script","text":"<p>Create a monitoring script:</p> <pre><code>#!/bin/bash\n# monitor_cluster.sh\n\nNODES=(5433 5434 5435)\nCLUSTER_NAME=\"tutorial_cluster\"\n\necho \"=== pgraft Cluster Health Check ===\"\necho \"Cluster: $CLUSTER_NAME\"\necho \"Timestamp: $(date)\"\necho \"\"\n\nfor port in \"${NODES[@]}\"; do\n    echo \"--- Node on port $port ---\"\n\n    # Check if PostgreSQL is running\n    if pg_isready -h 127.0.0.1 -p $port &gt; /dev/null 2&gt;&amp;1; then\n        echo \"PostgreSQL: \u2713 Running\"\n\n        # Check pgraft status\n        STATUS=$(psql -h 127.0.0.1 -p $port -U postgres -t -c \"\n            SELECT \n                CASE WHEN pgraft_is_leader() THEN 'LEADER' ELSE 'FOLLOWER' END,\n                pgraft_get_term(),\n                pgraft_get_leader()\n        \" 2&gt;/dev/null)\n\n        if [ $? -eq 0 ]; then\n            echo \"pgraft: \u2713 $STATUS\"\n        else\n            echo \"pgraft: \u2717 Not responding\"\n        fi\n    else\n        echo \"PostgreSQL: \u2717 Not running\"\n    fi\n    echo \"\"\ndone\n\n# Check cluster consistency\necho \"--- Cluster Consistency ---\"\nLEADERS=$(for port in \"${NODES[@]}\"; do\n    if pg_isready -h 127.0.0.1 -p $port &gt; /dev/null 2&gt;&amp;1; then\n        psql -h 127.0.0.1 -p $port -U postgres -t -c \"SELECT pgraft_is_leader()::text\" 2&gt;/dev/null\n    fi\ndone | grep -c true)\n\nif [ \"$LEADERS\" -eq 1 ]; then\n    echo \"Leadership: \u2713 Single leader detected\"\nelif [ \"$LEADERS\" -gt 1 ]; then\n    echo \"Leadership: \u2717 Multiple leaders detected (split-brain)\"\nelse\n    echo \"Leadership: \u2717 No leader detected\"\nfi\n</code></pre> <p>Make it executable and run:</p> <pre><code>chmod +x monitor_cluster.sh\n./monitor_cluster.sh\n</code></pre>"},{"location":"user-guide/tutorial/#automated-backup-with-pgraft","title":"Automated Backup with pgraft","text":"<p>Create a backup script that coordinates with the cluster:</p> <pre><code>#!/bin/bash\n# backup_cluster.sh\n\nBACKUP_DIR=\"/backups/pgraft\"\nDATE=$(date +%Y%m%d_%H%M%S)\nCLUSTER_NAME=\"tutorial_cluster\"\n\n# Create backup directory\nmkdir -p $BACKUP_DIR\n\n# Find the current leader\nLEADER_PORT=$(for port in 5433 5434 5435; do\n    if psql -h 127.0.0.1 -p $port -U postgres -t -c \"SELECT pgraft_is_leader()\" 2&gt;/dev/null | grep -q true; then\n        echo $port\n        break\n    fi\ndone)\n\nif [ -z \"$LEADER_PORT\" ]; then\n    echo \"Error: No leader found\"\n    exit 1\nfi\n\necho \"Backing up from leader on port $LEADER_PORT\"\n\n# Perform backup\npg_dump -h 127.0.0.1 -p $LEADER_PORT -U postgres \\\n    --format=custom \\\n    --compress=9 \\\n    --file=\"$BACKUP_DIR/backup_${CLUSTER_NAME}_${DATE}.dump\" \\\n    --verbose\n\n# Verify backup\nif [ $? -eq 0 ]; then\n    echo \"Backup completed successfully: backup_${CLUSTER_NAME}_${DATE}.dump\"\n\n    # Clean up old backups (keep last 7 days)\n    find $BACKUP_DIR -name \"backup_${CLUSTER_NAME}_*.dump\" -mtime +7 -delete\nelse\n    echo \"Backup failed\"\n    exit 1\nfi\n</code></pre>"},{"location":"user-guide/tutorial/#performance-monitoring","title":"Performance Monitoring","text":"<p>Create a performance monitoring script:</p> <pre><code>#!/bin/bash\n# perf_monitor.sh\n\necho \"=== pgraft Performance Metrics ===\"\necho \"Timestamp: $(date)\"\necho \"\"\n\nfor port in 5433 5434 5435; do\n    if pg_isready -h 127.0.0.1 -p $port &gt; /dev/null 2&gt;&amp;1; then\n        echo \"--- Node on port $port ---\"\n\n        # Get cluster status\n        psql -h 127.0.0.1 -p $port -U postgres -c \"\n            SELECT \n                node_id,\n                current_term,\n                leader_id,\n                state,\n                num_nodes,\n                messages_processed,\n                heartbeats_sent,\n                elections_triggered\n            FROM pgraft_get_cluster_status();\n        \" 2&gt;/dev/null\n\n        # Get log statistics\n        psql -h 127.0.0.1 -p $port -U postgres -c \"\n            SELECT \n                log_size,\n                last_index,\n                commit_index,\n                last_applied,\n                replicated,\n                committed,\n                applied,\n                errors\n            FROM pgraft_log_get_stats();\n        \" 2&gt;/dev/null\n\n        echo \"\"\n    fi\ndone\n</code></pre>"},{"location":"user-guide/tutorial/#troubleshooting","title":"Troubleshooting","text":""},{"location":"user-guide/tutorial/#common-issues-and-solutions","title":"Common Issues and Solutions","text":""},{"location":"user-guide/tutorial/#1-extension-not-loading","title":"1. Extension Not Loading","text":"<p>Symptoms: <pre><code>ERROR: extension \"pgraft\" is not available\n</code></pre></p> <p>Solutions: <pre><code># Check if extension is installed\nls -la /usr/local/pgsql.17/lib/pgraft*\n\n# Rebuild and reinstall\ncd /path/to/pgraft\nmake clean\nmake\nsudo make install\n\n# Check shared_preload_libraries\npsql -c \"SHOW shared_preload_libraries;\"\n</code></pre></p>"},{"location":"user-guide/tutorial/#2-worker-not-starting","title":"2. Worker Not Starting","text":"<p>Symptoms: <pre><code>SELECT pgraft_get_worker_state();\n-- Returns: \"STOPPED\"\n</code></pre></p> <p>Solutions: <pre><code># Check PostgreSQL logs\ntail -f /data/node1/logfile\n\n# Restart PostgreSQL\n/usr/local/pgsql.17/bin/pg_ctl -D /data/node1 restart\n\n# Check if pgraft is in shared_preload_libraries\ngrep shared_preload_libraries /data/node1/postgresql.conf\n</code></pre></p>"},{"location":"user-guide/tutorial/#3-network-connectivity-issues","title":"3. Network Connectivity Issues","text":"<p>Symptoms: <pre><code>pgraft: WARNING - Failed to connect to peer 2 at 127.0.0.1:5434\n</code></pre></p> <p>Solutions: <pre><code># Test network connectivity\ntelnet 127.0.0.1 5434\n\n# Check firewall\nsudo iptables -L\n\n# Verify port configuration\nnetstat -tlnp | grep 543\n</code></pre></p>"},{"location":"user-guide/tutorial/#4-split-brain-scenario","title":"4. Split-Brain Scenario","text":"<p>Symptoms: <pre><code>-- Multiple nodes think they're leader\nSELECT pgraft_is_leader() FROM (SELECT 5433 as port UNION SELECT 5434 UNION SELECT 5435) ports;\n-- Returns multiple true values\n</code></pre></p> <p>Solutions: <pre><code># Stop all nodes\n/usr/local/pgsql.17/bin/pg_ctl -D /data/node1 stop\n/usr/local/pgsql.17/bin/pg_ctl -D /data/node2 stop\n/usr/local/pgsql.17/bin/pg_ctl -D /data/node3 stop\n\n# Wait 30 seconds\n\n# Start nodes one by one with delays\n/usr/local/pgsql.17/bin/pg_ctl -D /data/node1 -l /data/node1/logfile start\nsleep 10\n/usr/local/pgsql.17/bin/pg_ctl -D /data/node2 -l /data/node2/logfile start\nsleep 10\n/usr/local/pgsql.17/bin/pg_ctl -D /data/node3 -l /data/node3/logfile start\n</code></pre></p>"},{"location":"user-guide/tutorial/#debug-mode","title":"Debug Mode","text":"<p>Enable debug mode for troubleshooting:</p> <pre><code>-- Enable debug logging\nSELECT pgraft_set_debug(true);\n\n-- Perform operations and check logs\nSELECT pgraft_get_worker_state();\nSELECT * FROM pgraft_get_queue_status();\n\n-- Disable debug logging\nSELECT pgraft_set_debug(false);\n</code></pre>"},{"location":"user-guide/tutorial/#log-analysis","title":"Log Analysis","text":"<p>Key log patterns to look for:</p> <pre><code># Successful operations\ngrep \"pgraft: INFO\" /data/node*/logfile\n\n# Warnings\ngrep \"pgraft: WARNING\" /data/node*/logfile\n\n# Errors\ngrep \"pgraft: ERROR\" /data/node*/logfile\n\n# Leader elections\ngrep \"election\\|leader\" /data/node*/logfile\n</code></pre>"},{"location":"user-guide/tutorial/#best-practices","title":"Best Practices","text":""},{"location":"user-guide/tutorial/#1-cluster-design","title":"1. Cluster Design","text":"<ul> <li>Odd Number of Nodes: Use 3, 5, or 7 nodes for optimal fault tolerance</li> <li>Geographic Distribution: Place nodes in different availability zones</li> <li>Network Latency: Keep inter-node latency under 100ms</li> <li>Resource Allocation: Ensure consistent resources across nodes</li> </ul>"},{"location":"user-guide/tutorial/#2-configuration-management","title":"2. Configuration Management","text":"<ul> <li>Consistent Configuration: Use identical settings across all nodes</li> <li>Version Control: Track configuration changes</li> <li>Documentation: Document all custom settings</li> <li>Testing: Test configuration changes in staging first</li> </ul>"},{"location":"user-guide/tutorial/#3-monitoring-and-alerting","title":"3. Monitoring and Alerting","text":"<ul> <li>Health Checks: Implement automated health monitoring</li> <li>Performance Metrics: Track key performance indicators</li> <li>Alert Thresholds: Set appropriate alert levels</li> <li>Response Procedures: Define incident response procedures</li> </ul>"},{"location":"user-guide/tutorial/#4-backup-and-recovery","title":"4. Backup and Recovery","text":"<ul> <li>Regular Backups: Schedule automated backups</li> <li>Backup Testing: Regularly test backup restoration</li> <li>Point-in-Time Recovery: Implement PITR capabilities</li> <li>Disaster Recovery: Plan for complete cluster failure</li> </ul>"},{"location":"user-guide/tutorial/#5-security","title":"5. Security","text":"<ul> <li>Network Security: Use firewalls and VPNs</li> <li>Authentication: Implement strong authentication</li> <li>Encryption: Encrypt data in transit and at rest</li> <li>Access Control: Implement principle of least privilege</li> </ul>"},{"location":"user-guide/tutorial/#6-performance-optimization","title":"6. Performance Optimization","text":"<ul> <li>Hardware Selection: Choose appropriate hardware</li> <li>Configuration Tuning: Optimize for your workload</li> <li>Monitoring: Continuously monitor performance</li> <li>Capacity Planning: Plan for growth</li> </ul> <p>This tutorial provides a comprehensive guide to setting up and managing a pgraft cluster. For additional information, refer to the main documentation and architecture guides.</p>"}]}